{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD 1 : logger 추가\n",
    "# TBD 2: flask github 참고, method, class, 파일의 맨 윗단 마다 pydoc 형식으로 달기\n",
    "# TBD 3: 축약어를 자제할것 (특히 변수)\n",
    "\n",
    "# -------------------------\n",
    "#   To-do\n",
    "# -------------------------\n",
    "# 1. add logger\n",
    "# 2. make image drawer overlay mask on image\n",
    "# 3. make iterable\n",
    "# 4. make verbose turn on and off\n",
    "# 5. write pydoc\n",
    "\n",
    "# tensorflow Module\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "import segmentation_models as sm\n",
    "\n",
    "# python basic Module\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import progressbar\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "from pickle import dump, load\n",
    "\n",
    "# math, image, plot Module\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt  # TBD\n",
    "\n",
    "# email Module\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.header import Header\n",
    "\n",
    "from data_loader.medical_segmentation_data_loader_v1 import DataLoader\n",
    "\n",
    "from gan_module.model import build_generator, build_discriminator\n",
    "from gan_module.draw_images import ImageDrawer\n",
    "from gan_module.custom_loss import f1_loss_for_training, f1_score, dice_loss_for_training\n",
    "\n",
    "# set GPU memory growth allocation\n",
    "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for device in gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "\n",
    "\"\"\"\n",
    "if you don't have nvidia-gpu, try plaidml! but it will works tensorflow 1.x.x\n",
    "# pip install -U plaidml-keras\n",
    "# plaidml-setup\n",
    "\"\"\"\n",
    "# use_plaidml = False\n",
    "# if use_plaidml :\n",
    "#     import plaidml.keras\n",
    "#     plaidml.keras.install_backend()\n",
    "#     os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "class Pix2PixSegmentation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_power=32,\n",
    "        discriminator_power=32,\n",
    "        generator_learning_rate=1e-4,\n",
    "        discriminator_learning_rate=1e-4,\n",
    "        find_error=False,\n",
    "        temp_weights_path=\".\",\n",
    "        draw_images=True,\n",
    "        on_memory=True,\n",
    "        test=False\n",
    "    ):\n",
    "        # smtp info\n",
    "        self.smtp_host = \"smtp.gmail.com\"\n",
    "        self.smtp_port = 465\n",
    "        self.smtp_id = \"rpa.manager0001@gmail.com\"\n",
    "        self.smtp_password = \"!rpa.admin!23\"\n",
    "        self.smtp_to_addr = \"tobeor3009@gmail.com\"\n",
    "\n",
    "        # Input shape\n",
    "        self.img_rows = 512\n",
    "        self.img_cols = 512\n",
    "        self.input_channels = 3\n",
    "        self.output_channels = 1\n",
    "        self.input_img_shape = (\n",
    "            self.img_rows, self.img_cols, self.input_channels)\n",
    "        self.output_img_shape = (\n",
    "            self.img_rows, self.img_cols, self.output_channels)\n",
    "        # set parameter\n",
    "        self.start_epoch = None\n",
    "        self.history = {\"generator_loss\": [], \"f1_score_train\": [], \"f1_score_valid\": []}\n",
    "        self.f1_loss_ratio = 16\n",
    "        self.huber_loss_ratio = 64\n",
    "        self.find_error = find_error\n",
    "        self.find_error_epoch = 30\n",
    "        self.error_list = []\n",
    "        self.temp_weights_path = temp_weights_path\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = \"tumor\"\n",
    "        self.data_loader = DataLoader(\n",
    "            dataset_name=self.dataset_name,\n",
    "            img_res=(self.img_rows, self.img_cols),\n",
    "            on_memory=on_memory, test=test\n",
    "        )\n",
    "        self.train_loaded_data, self.valid_loaded_data = self.data_loader.load_all()\n",
    "        if test:\n",
    "            self.train_loaded_data_len = 20\n",
    "            self.valid_loaded_data_len = 20\n",
    "        else:\n",
    "            self.train_loaded_data_len = self.data_loader.train_data_length\n",
    "            self.valid_loaded_data_len = self.data_loader.valid_data_length\n",
    "\n",
    "        self.train_loaded_data_index = np.arange(self.train_loaded_data_len)\n",
    "        self.valid_loaded_data_index = np.arange(self.valid_loaded_data_len)\n",
    "\n",
    "        # Configure Image Drawer\n",
    "        self.draw_images = draw_images\n",
    "        self.image_drawer = ImageDrawer(\n",
    "            dataset_name=self.dataset_name, data_loader=self.data_loader\n",
    "        )\n",
    "        # training parameters\n",
    "        self.learning_schedule = [\n",
    "            50,\n",
    "            100,\n",
    "            150,\n",
    "            200,\n",
    "            250,\n",
    "            300,\n",
    "            350,\n",
    "            400,\n",
    "            450,\n",
    "            500,\n",
    "            550\n",
    "        ]\n",
    "        self.discriminator_acc_previous = 0.5\n",
    "        self.discriminator_acces = np.array(\n",
    "            [0.5 for _ in range(self.train_loaded_data_len)])\n",
    "        self.discriminator_acces_previous = self.discriminator_acces.copy()\n",
    "        self.generator_losses = np.array(\n",
    "            [1 for _ in range(self.train_loaded_data_len)], dtype=np.float32)\n",
    "        self.generator_losses_previous = self.generator_losses.copy()\n",
    "        self.generator_loss_min = 100\n",
    "        self.generator_loss_previous = 100\n",
    "        self.generator_loss_max_previous = 1000\n",
    "        self.generator_loss_max_min = 1000\n",
    "        self.generator_loss_min_min = 1000\n",
    "        self.weight_save_stack = False\n",
    "        self.training_end_stack = 0\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = int(self.img_rows / 2 ** 2)\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.generator_power = generator_power\n",
    "        self.discriminator_power = discriminator_power\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        self.discriminator_learning_rate = discriminator_learning_rate\n",
    "        generator_optimizer = Nadam(self.generator_learning_rate)\n",
    "        discriminator_optimizer = Nadam(self.discriminator_learning_rate)\n",
    "\n",
    "        # layer Component\n",
    "        self.kernel_initializer = RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = build_generator(\n",
    "            input_img_shape=self.input_img_shape,\n",
    "            output_channels=self.output_channels,\n",
    "            generator_power=self.generator_power,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "        )\n",
    "        self.generator.compile(\n",
    "            loss=tf.keras.losses.Huber(),\n",
    "            optimizer=generator_optimizer,\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator(\n",
    "            input_img_shape=self.input_img_shape,\n",
    "            output_img_shape=self.output_img_shape,\n",
    "            discriminator_power=self.discriminator_power,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "        )\n",
    "        # self.discriminator = self.build_discriminator()\n",
    "        # 'mse' or tf.keras.losses.Huber() tf.keras.losses.LogCosh()\n",
    "        self.discriminator.compile(\n",
    "            loss=tf.keras.losses.LogCosh(),\n",
    "            optimizer=discriminator_optimizer,\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        # -------------------------\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        original_img = Input(shape=self.input_img_shape)\n",
    "        masked_img = Input(shape=self.output_img_shape)\n",
    "        # generate image from original_img for target masked_img\n",
    "        model_masked_img = self.generator(original_img)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        model_validity = self.discriminator([original_img, model_masked_img])\n",
    "        # give score by\n",
    "        # 1. how generator trick discriminator\n",
    "        # 2. how generator's image same as real photo in pixel\n",
    "        # 3. if you want change loss, see doc https://keras.io/api/losses/\n",
    "        # 4. 'mse', 'mae', tf.keras.losses.LogCosh(),  tf.keras.losses.Huber()\n",
    "        self.combined = Model(\n",
    "            inputs=[original_img, masked_img],\n",
    "            outputs=[model_validity, model_masked_img, model_masked_img],\n",
    "        )\n",
    "        self.combined.compile(\n",
    "            loss=[\n",
    "                tf.keras.losses.LogCosh(),\n",
    "                sm.losses.BinaryFocalLoss(),\n",
    "                dice_loss_for_training\n",
    "            ],\n",
    "            loss_weights=[2, self.huber_loss_ratio, self.f1_loss_ratio],\n",
    "            optimizer=generator_optimizer\n",
    "        )\n",
    "\n",
    "    def train(self, epochs, batch_size=1, sample_interval=50, epoch_shuffle_term=10):\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Adversarial loss ground truths\n",
    "        self.training_end_stack = 0\n",
    "        self.batch_size = batch_size\n",
    "        valid_patch = np.ones((self.batch_size,) +\n",
    "                              self.disc_patch, dtype=np.float32)\n",
    "        fake_patch = np.zeros((self.batch_size,) +\n",
    "                              self.disc_patch, dtype=np.float32)\n",
    "        if self.start_epoch is None:\n",
    "            self.start_epoch = 0\n",
    "        for epoch in range(self.start_epoch, epochs):\n",
    "            bar = progressbar.ProgressBar(maxval=self.train_loaded_data_len).start()            \n",
    "            batch_i = 0\n",
    "            \n",
    "            discriminator_losses = []\n",
    "            generator_loss_max_in_epoch = 0\n",
    "            generator_loss_min_in_epoch = 1000\n",
    "            generator_current_learning_rate = self.learning_rate_scheduler(\n",
    "                self.generator_learning_rate,\n",
    "                epoch,\n",
    "            )\n",
    "            discriminator_current_learning_rate = self.learning_rate_scheduler(\n",
    "                self.discriminator_learning_rate,\n",
    "                epoch,\n",
    "            )\n",
    "            ratio = 0.25\n",
    "            \n",
    "            generator_loss_median = np.quantile(self.generator_losses_previous, ratio)\n",
    "            print(f\"current_generator_loss_median : {generator_loss_median}\")\n",
    "                       \n",
    "            keras_backend.set_value(\n",
    "                self.discriminator.optimizer.learning_rate,\n",
    "                discriminator_current_learning_rate,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.generator.optimizer.learning_rate, generator_current_learning_rate * 2\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.combined.optimizer.learning_rate, generator_current_learning_rate\n",
    "            )\n",
    "            # shffle data maybe\n",
    "            if epoch % epoch_shuffle_term == 0 and not isinstance(self.train_loaded_data, types.GeneratorType):\n",
    "                np.random.shuffle(self.train_loaded_data_index)\n",
    "                \n",
    "            if (self.discriminator_acc_previous < 0.8 and epoch % epoch_shuffle_term) or self.discriminator_acc_previous < 0.6:\n",
    "                discriminator_learning = True\n",
    "                print(\"discriminator_learning is True\")\n",
    "            else:\n",
    "                discriminator_learning = False\n",
    "                print(\"discriminator_learning is False\")\n",
    "            \n",
    "            \n",
    "            while batch_i + self.batch_size <= self.train_loaded_data_len:\n",
    "                bar.update(batch_i)\n",
    "                \n",
    "                batch_index = self.train_loaded_data_index[batch_i: batch_i +\n",
    "                                                         self.batch_size]\n",
    "                \n",
    "                original_img = self.train_loaded_data[0][batch_index]\n",
    "                masked_img = self.train_loaded_data[1][batch_index]\n",
    "                \n",
    "                model_masked_img = self.generator.predict_on_batch(\n",
    "                    original_img)\n",
    "\n",
    "                # forTest\n",
    "                self.masked_img = masked_img\n",
    "                self.original_img = original_img\n",
    "                self.model_masked_img = model_masked_img\n",
    "                self.valid_path = valid_patch\n",
    "                self.fake_patch = fake_patch\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # Train Discriminator for valid image if it failed to detect fake image\n",
    "                generator_loss_previous = np.mean(\n",
    "                    self.generator_losses_previous[batch_index])\n",
    "                \n",
    "                if discriminator_learning:\n",
    "                    self.discriminator.train_on_batch(\n",
    "                        [original_img, masked_img], valid_patch)\n",
    "                    \n",
    "                batch_discriminator_acc_previous = np.mean(\n",
    "                    self.discriminator_acces_previous[batch_index])\n",
    "                \n",
    "                # Train generator for image detected by discriminator\n",
    "                if (batch_discriminator_acc_previous > 0.5 and \n",
    "                    epoch > 1 and \n",
    "                    epoch < 20 and\n",
    "                    generator_loss_previous > generator_loss_median) :\n",
    "                    self.generator.train_on_batch(\n",
    "                        original_img, masked_img)\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "\n",
    "                generator_loss = self.combined.train_on_batch(\n",
    "                    [original_img, masked_img],\n",
    "                    [valid_patch, masked_img, masked_img],\n",
    "                )\n",
    "                # train discriminator for fake image if it failed to detect fake image\n",
    "                if batch_discriminator_acc_previous <= 0.5 or epoch == 0:\n",
    "                    discriminator_loss = self.discriminator.train_on_batch(\n",
    "                        [original_img, model_masked_img], fake_patch)\n",
    "                else:\n",
    "                    discriminator_loss = self.discriminator.test_on_batch(\n",
    "                        [original_img, model_masked_img], fake_patch)\n",
    "\n",
    "                self.discriminator_acces[batch_index] = discriminator_loss[1]\n",
    "                self.generator_losses[batch_index] = generator_loss[0]\n",
    "                elapsed_time = datetime.now() - start_time\n",
    "                if batch_i % sample_interval == 0:\n",
    "                    # Plot the progress\n",
    "                    print(\n",
    "                        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\"\n",
    "                        % (\n",
    "                            epoch,\n",
    "                            epochs,\n",
    "                            batch_i,\n",
    "                            self.train_loaded_data_len,\n",
    "                            discriminator_loss[0],\n",
    "                            100 * discriminator_loss[1],\n",
    "                            generator_loss[0],\n",
    "                            elapsed_time,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                if batch_i % sample_interval == 0 and self.draw_images:\n",
    "                    self.image_drawer.sample_images(\n",
    "                        self.generator, epoch, batch_i)\n",
    "\n",
    "                discriminator_losses.append(discriminator_loss[0])\n",
    "                # loss 가 가장 높은 이미지를 저장 및 max_in_epoch 갱신\n",
    "                if generator_loss[0] > generator_loss_max_in_epoch:\n",
    "                    model_masked_img = self.generator.predict_on_batch(\n",
    "                        original_img)\n",
    "                    if self.draw_images:\n",
    "                        self.image_drawer.draw_worst_and_best(\n",
    "                            original_img,\n",
    "                            model_masked_img,\n",
    "                            masked_img,\n",
    "                            epoch,\n",
    "                            worst=True,\n",
    "                        )\n",
    "                    generator_loss_max_in_epoch = generator_loss[0]\n",
    "                # loss 가 가장 낮은 이미지를 저장 및 max_in_epoch 갱신\n",
    "                if generator_loss_min_in_epoch > generator_loss[0]:\n",
    "                    model_masked_img = self.generator.predict_on_batch(\n",
    "                        original_img)\n",
    "                    if self.draw_images:\n",
    "                        self.image_drawer.draw_worst_and_best(\n",
    "                            original_img,\n",
    "                            model_masked_img,\n",
    "                            masked_img,\n",
    "                            epoch,\n",
    "                            worst=False,\n",
    "                        )\n",
    "                    generator_loss_min_in_epoch = generator_loss[0]\n",
    "\n",
    "                # 한 배치 끝\n",
    "                batch_i += self.batch_size\n",
    "            # training batch 사이클 끝\n",
    "            print(f\"discriminator_acces : {np.mean(self.discriminator_acces)}\")\n",
    "            print(\n",
    "                f\"Mean generator_loss : {np.mean(self.generator_losses)}\")\n",
    "            print(f\"Max generator_loss : {np.max(self.generator_losses)}\")\n",
    "            print(f\"Min generator_loss : {np.min(self.generator_losses)}\")\n",
    "            print(\n",
    "                f\"generator loss decrease : {self.generator_loss_min - np.mean(self.generator_losses)}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"generator loss decrease ratio : ({np.mean(self.generator_losses) / self.generator_loss_min})\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Max generator loss decrease : {self.generator_loss_max_previous - np.max(self.generator_losses)}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"current lowest generator loss : {self.generator_loss_min}\")\n",
    "            print(\n",
    "                f\"current Learning_rate = {generator_current_learning_rate}\")\n",
    "            # rollback if loss not converge\n",
    "            if np.mean(self.generator_losses) / self.generator_loss_min < 1.1:\n",
    "                if self.generator_loss_min > np.mean(self.generator_losses):\n",
    "                    self.generator_loss_min = np.mean(self.generator_losses)\n",
    "                    self.generator_loss_max_min = generator_loss_max_in_epoch\n",
    "                    self.generator_loss_min_min = generator_loss_min_in_epoch\n",
    "                    self.weight_save_stack = True\n",
    "                    self.save_study_info()\n",
    "                    print(\"save weights\")\n",
    "                #compute f1_score\n",
    "                train_f1_loss_list = []\n",
    "                train_f1_score_list = []\n",
    "                train_predict_mini_batch_size = 1\n",
    "                for index in range(0, self.train_loaded_data_len, train_predict_mini_batch_size):\n",
    "\n",
    "                    train_masked_img = self.train_loaded_data[1][index:index +\n",
    "                                                                 train_predict_mini_batch_size]\n",
    "                    train_model_masked_img = self.generator.predict_on_batch(\n",
    "                        self.train_loaded_data[0][index:index + train_predict_mini_batch_size])\n",
    "\n",
    "                    train_f1_loss = f1_loss_for_training(\n",
    "                        train_masked_img, np.squeeze(train_model_masked_img))\n",
    "                    train_f1_score = f1_score(\n",
    "                        train_masked_img, np.squeeze(train_model_masked_img))\n",
    "                    train_f1_loss_list.append(train_f1_loss)\n",
    "                    train_f1_score_list.append(train_f1_score)\n",
    "                print(\n",
    "                    f\"train_f1_loss : {np.mean(train_f1_loss_list) * self.f1_loss_ratio}\")\n",
    "                print(f\"train_f1_score : {1 - np.mean(train_f1_loss_list)}\")\n",
    "                print(f\"train_f1_rounded_score : {np.mean(train_f1_score_list)}\")\n",
    "\n",
    "                valid_f1_loss_list = []\n",
    "                valid_f1_score_list = []\n",
    "                valid_predict_mini_batch_size = 1\n",
    "                for index in range(0, self.valid_loaded_data_len, valid_predict_mini_batch_size):\n",
    "\n",
    "                    valid_masked_img = self.valid_loaded_data[1][index:index +\n",
    "                                                                 valid_predict_mini_batch_size]\n",
    "                    valid_model_masked_img = self.generator.predict_on_batch(\n",
    "                        self.valid_loaded_data[0][index:index + valid_predict_mini_batch_size])\n",
    "\n",
    "                    valid_f1_loss = f1_loss_for_training(\n",
    "                        valid_masked_img, np.squeeze(valid_model_masked_img))\n",
    "                    valid_f1_score = f1_score(\n",
    "                        valid_masked_img, np.squeeze(valid_model_masked_img))\n",
    "                    valid_f1_loss_list.append(valid_f1_loss)\n",
    "                    valid_f1_score_list.append(valid_f1_score)\n",
    "                print(\n",
    "                    f\"valid_f1_loss : {np.mean(valid_f1_loss_list) * self.f1_loss_ratio}\")\n",
    "                print(f\"valid_f1_score : {1 - np.mean(valid_f1_loss_list)}\")\n",
    "                print(f\"valid_f1_rounded_score : {np.mean(valid_f1_score_list)}\")\n",
    "            else:\n",
    "                print(\"loss decrease. skip compute f1_score\")\n",
    "                self.load_best_weights()\n",
    "\n",
    "            # previous generator_loss 갱신\n",
    "            self.generator_loss_previous = np.mean(self.generator_losses)\n",
    "            self.generator_loss_max_previous = generator_loss_max_in_epoch\n",
    "\n",
    "            if epoch >= 10 and self.weight_save_stack:\n",
    "                copy(\n",
    "                    \"generator.h5\",\n",
    "                    \"./generator_weights/generator_\"\n",
    "                    + str(round(self.generator_loss_min, 5))\n",
    "                    + \"_\"\n",
    "                    + str(round(self.generator_loss_max_min, 5))\n",
    "                    + \".h5\",\n",
    "                )\n",
    "                self.weight_save_stack = False\n",
    "\n",
    "            self.discriminator_acc_previous = np.mean(self.discriminator_acces)\n",
    "            self.discriminator_acces_previous = self.discriminator_acces.copy()\n",
    "            self.generator_losses_previous = self.generator_losses.copy()\n",
    "            # TBD: add epoch bigger than history length\n",
    "#             if len(self.history[\"generator_loss\"]) == epoch:\n",
    "#                 self.history[\"generator_loss\"].append(\n",
    "#                     np.mean(self.generator_losses))\n",
    "#                 self.history[\"f1_score_train\"].append(\n",
    "#                     np.mean(self.train_f1_score_list))\n",
    "#                 self.history[\"f1_score_valid\"].append(\n",
    "#                     np.mean(self.valid_f1_score_list))\n",
    "#             elif len(self.history[\"generator_loss\"]) < epoch:\n",
    "#                 self.history[\"generator_loss\"][epoch] = np.mean(\n",
    "#                     self.generator_losses)\n",
    "#                 self.history[\"f1_score_train\"][epoch] = np.mean(\n",
    "#                     train_f1_score_list)\n",
    "#                 self.history[\"f1_score_valid\"][epoch] = np.mean(\n",
    "#                     valid_f1_score_list)\n",
    "    def learning_rate_scheduler(self, learning_rate, epoch):\n",
    "        # poly_lr\n",
    "        exponent = 0.9\n",
    "        max_epoch = 575\n",
    "        new_learning_rate = learning_rate * (1 - epoch / max_epoch)**exponent\n",
    "\n",
    "        return new_learning_rate\n",
    "\n",
    "    def get_info_folderPath(self):\n",
    "        return (\n",
    "            str(round(self.generator_loss_min, 5))\n",
    "            + \"_\"\n",
    "            + str(round(self.generator_loss_max_min, 5))\n",
    "        )\n",
    "\n",
    "    def save_study_info(self, path=None):\n",
    "\n",
    "        if path == None:\n",
    "            path = self.temp_weights_path\n",
    "\n",
    "        generator_weigth_path = os.path.join(path, \"generator.h5\")\n",
    "        discriminator_weigth_path = os.path.join(path, \"discriminator.h5\")\n",
    "        combined_weigth_path = os.path.join(path, \"combined.h5\")\n",
    "\n",
    "        self.generator.save_weights(generator_weigth_path)\n",
    "        self.discriminator.save_weights(discriminator_weigth_path)\n",
    "        self.combined.save_weights(combined_weigth_path)\n",
    "\n",
    "        study_info = {}\n",
    "        study_info[\"start_epoch\"] = self.start_epoch\n",
    "        study_info[\"generator_loss_min\"] = self.generator_loss_min\n",
    "        study_info[\"generator_loss_max_min\"] = self.generator_loss_max_min\n",
    "        study_info[\"generator_loss_min_min\"] = self.generator_loss_min_min\n",
    "        study_info[\"generator_losses_previous\"] = self.generator_losses_previous\n",
    "        study_info[\"discriminator_acces\"] = self.discriminator_acces\n",
    "        study_info[\"history\"] = self.history\n",
    "        study_info[\"train_loaded_data_index\"] = self.train_loaded_data_index\n",
    "        file = open(path + \"/study_info.pkl\", \"wb\")\n",
    "        dump(study_info, file)\n",
    "        file.close()\n",
    "\n",
    "    def load_study_info(self):\n",
    "\n",
    "        self.generator.load_weights(\"generator.h5\")\n",
    "        self.discriminator.load_weights(\"discriminator.h5\")\n",
    "        self.combined.load_weights(\"combined.h5\")\n",
    "\n",
    "        if os.path.isfile(\"study_info.pkl\"):\n",
    "            file = open(\"study_info.pkl\", \"rb\")\n",
    "            study_info = load(file)\n",
    "            file.close()\n",
    "            self.start_epoch = study_info[\"start_epoch\"]\n",
    "            self.generator_loss_min = study_info[\"generator_loss_min\"]\n",
    "            self.generator_loss_max_min = study_info[\"generator_loss_max_min\"]\n",
    "            self.generator_loss_min_min = study_info[\"generator_loss_min_min\"]\n",
    "            self.generator_losses_previous = study_info[\"generator_losses_previous\"]\n",
    "            self.discriminator_acces = study_info[\"discriminator_acces\"]\n",
    "            self.history = study_info[\"history\"]\n",
    "            self.train_loaded_data_index = study_info[\"train_loaded_data_index\"] \n",
    "        else:\n",
    "            print(\"No info pkl file!\")\n",
    "\n",
    "    def load_best_weights(self):\n",
    "        self.generator.load_weights(self.temp_weights_path + \"/generator.h5\")\n",
    "        self.discriminator.load_weights(\n",
    "            self.temp_weights_path + \"/discriminator.h5\")\n",
    "        self.combined.load_weights(self.temp_weights_path + \"/combined.h5\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_lr = 1e-3\n",
    "discriminator_lr = 1e-4\n",
    "batch_size = 10\n",
    "g_lr = generator_lr * batch_size\n",
    "d_lr = discriminator_lr * batch_size\n",
    "gan = Pix2PixSegmentation(generator_power=4, discriminator_power=4, generator_learning_rate=g_lr, discriminator_learning_rate=d_lr,\n",
    "                          test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_generator_loss_median : 1.0\n",
      "discriminator_learning is True\n",
      "[Epoch 0/575] [Batch 0/6200] [D loss: 0.187494, acc:  26%] [G loss: 32.489243] time: 0:00:14.140961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/575] [Batch 3100/6200] [D loss: 0.123670, acc:  41%] [G loss: 18.639917] time: 0:04:10.046226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.3739344928916844\n",
      "Mean generator_loss : 19.722179412841797\n",
      "Max generator_loss : 37.53890609741211\n",
      "Min generator_loss : 15.17371654510498\n",
      "generator loss decrease : 80.2778205871582\n",
      "generator loss decrease ratio : (0.19722179412841798)\n",
      "Max generator loss decrease : 962.4610939025879\n",
      "current lowest generator loss : 100\n",
      "current Learning_rate = 0.01\n",
      "save weights\n",
      "train_f1_loss : 13.07392406463623\n",
      "train_f1_score : 0.1828797459602356\n",
      "train_f1_rounded_score : 0.2582857608795166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 13.432496070861816\n",
      "valid_f1_score : 0.16046899557113647\n",
      "valid_f1_rounded_score : 0.26145774126052856\n",
      "current_generator_loss_median : 18.49822425842285\n",
      "discriminator_learning is True\n",
      "[Epoch 1/575] [Batch 0/6200] [D loss: 0.120977, acc:  58%] [G loss: 18.030672] time: 0:10:40.839913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/575] [Batch 3100/6200] [D loss: 0.152301, acc:   8%] [G loss: 15.264763] time: 0:14:32.750396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.25406423224707425\n",
      "Mean generator_loss : 16.779293060302734\n",
      "Max generator_loss : 22.005199432373047\n",
      "Min generator_loss : 13.718571662902832\n",
      "generator loss decrease : 2.9428863525390625\n",
      "generator loss decrease ratio : (0.8507829308509827)\n",
      "Max generator loss decrease : 15.533706665039062\n",
      "current lowest generator loss : 19.722179412841797\n",
      "current Learning_rate = 0.009984346464159641\n",
      "save weights\n",
      "train_f1_loss : 12.895927429199219\n",
      "train_f1_score : 0.19400453567504883\n",
      "train_f1_rounded_score : 0.323555588722229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 13.062210083007812\n",
      "valid_f1_score : 0.18361186981201172\n",
      "valid_f1_rounded_score : 0.4198073744773865\n",
      "current_generator_loss_median : 15.823863983154297\n",
      "discriminator_learning is True\n",
      "[Epoch 2/575] [Batch 0/6200] [D loss: 0.203336, acc:   5%] [G loss: 15.847067] time: 0:21:05.711703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.                       |\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-73abfbf0db1f>\", line 6, in <module>\n",
      "    gan.train(epochs=575, batch_size=batch_size, sample_interval=3100)\n",
      "  File \"<ipython-input-4-769d48d7de45>\", line 335, in train\n",
      "    generator_loss = self.combined.train_on_batch(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1698, in train_on_batch\n",
      "    self.reset_metrics()\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1637, in reset_metrics\n",
      "    m.reset_states()\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\metrics.py\", line 247, in reset_states\n",
      "    K.batch_set_value([(v, 0) for v in self.variables])\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 201, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3576, in batch_set_value\n",
      "    x.assign(np.asarray(value, dtype=dtype(x)))\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\", line 859, in assign\n",
      "    assign_op = gen_resource_variable_ops.assign_variable_op(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\", line 142, in assign_variable_op\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1465, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\tokenize.py\", line 392, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-73abfbf0db1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m575\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-769d48d7de45>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, sample_interval, epoch_shuffle_term)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m                 generator_loss = self.combined.train_on_batch(\n\u001b[0m\u001b[0;32m    336\u001b[0m                     \u001b[1;33m[\u001b[0m\u001b[0moriginal_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1698\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1699\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1636\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1637\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3575\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3576\u001b[1;33m       \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3577\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m    858\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0m\u001b[0;32m    860\u001b[0m           self.handle, value_tensor, name=name)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, name)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"AssignVariableOp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2045\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2047\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#gan.find_error = True\n",
    "#gan.find_error_epoch = 5\n",
    "#gan.load_study_info()\n",
    "#gan.load_study_info()\n",
    "gan.start_epoch = 0\n",
    "gan.train(epochs=575, batch_size=batch_size, sample_interval=3100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_generator_loss_median : 1.0\n",
      "discriminator_learning is True\n",
      "[Epoch 0/575] [Batch 0/6200] [D loss: 0.192542, acc:  34%] [G loss: 35.593498] time: 0:00:15.636787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/575] [Batch 3100/6200] [D loss: 0.127238, acc:  95%] [G loss: 19.044613] time: 0:04:11.519256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.8540087398622305\n",
      "Mean generator_loss : 19.739973068237305\n",
      "Max generator_loss : 35.59349822998047\n",
      "Min generator_loss : 14.8356294631958\n",
      "generator loss decrease : 80.2600269317627\n",
      "generator loss decrease ratio : (0.19739973068237304)\n",
      "Max generator loss decrease : 964.4065017700195\n",
      "current lowest generator loss : 100\n",
      "current Learning_rate = 0.01\n",
      "save weights\n",
      "train_f1_loss : 12.714962005615234\n",
      "train_f1_score : 0.20531487464904785\n",
      "train_f1_rounded_score : 0.4767947196960449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 13.072277069091797\n",
      "valid_f1_score : 0.1829826831817627\n",
      "valid_f1_rounded_score : 0.5394037961959839\n",
      "current_generator_loss_median : 18.517194747924805\n",
      "discriminator_learning is False\n",
      "[Epoch 1/575] [Batch 0/6200] [D loss: 0.127271, acc:  97%] [G loss: 18.393978] time: 0:10:43.043007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/575] [Batch 3100/6200] [D loss: 0.128559, acc:  60%] [G loss: 16.446007] time: 0:13:54.043540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.6259088823872228\n",
      "Mean generator_loss : 17.086488723754883\n",
      "Max generator_loss : 22.040729522705078\n",
      "Min generator_loss : 13.835392951965332\n",
      "generator loss decrease : 2.653484344482422\n",
      "generator loss decrease ratio : (0.8655781149864197)\n",
      "Max generator loss decrease : 13.55276870727539\n",
      "current lowest generator loss : 19.739973068237305\n",
      "current Learning_rate = 0.009984346464159641\n",
      "save weights\n",
      "train_f1_loss : 12.151691436767578\n",
      "train_f1_score : 0.24051928520202637\n",
      "train_f1_rounded_score : 0.5733034014701843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 12.492862701416016\n",
      "valid_f1_score : 0.21919608116149902\n",
      "valid_f1_rounded_score : 0.5992465615272522\n",
      "current_generator_loss_median : 16.125316619873047\n",
      "discriminator_learning is True\n",
      "[Epoch 2/575] [Batch 0/6200] [D loss: 0.120197, acc:  97%] [G loss: 16.222260] time: 0:19:47.556539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2/575] [Batch 3100/6200] [D loss: 0.264398, acc:   0%] [G loss: 14.793714] time: 0:24:33.081743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.18072002819414168\n",
      "Mean generator_loss : 15.469441413879395\n",
      "Max generator_loss : 20.23581886291504\n",
      "Min generator_loss : 13.165887832641602\n",
      "generator loss decrease : 1.6170473098754883\n",
      "generator loss decrease ratio : (0.9053610563278198)\n",
      "Max generator loss decrease : 1.804910659790039\n",
      "current lowest generator loss : 17.086488723754883\n",
      "current Learning_rate = 0.00996869020098343\n",
      "save weights\n",
      "train_f1_loss : 12.0138521194458\n",
      "train_f1_score : 0.24913424253463745\n",
      "train_f1_rounded_score : 0.5574193596839905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 12.280369758605957\n",
      "valid_f1_score : 0.23247689008712769\n",
      "valid_f1_rounded_score : 0.5855486989021301\n",
      "current_generator_loss_median : 14.592416763305664\n",
      "discriminator_learning is True\n",
      "[Epoch 3/575] [Batch 0/6200] [D loss: 0.345947, acc:   0%] [G loss: 14.792796] time: 0:31:55.300309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3/575] [Batch 3100/6200] [D loss: 0.134055, acc:  95%] [G loss: 13.963217] time: 0:36:22.514963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.7424818271410106\n",
      "Mean generator_loss : 14.588184356689453\n",
      "Max generator_loss : 19.089473724365234\n",
      "Min generator_loss : 12.369847297668457\n",
      "generator loss decrease : 0.8812570571899414\n",
      "generator loss decrease ratio : (0.9430323839187622)\n",
      "Max generator loss decrease : 1.1463451385498047\n",
      "current lowest generator loss : 15.469441413879395\n",
      "current Learning_rate = 0.009953031205235184\n",
      "save weights\n",
      "train_f1_loss : 12.062532424926758\n",
      "train_f1_score : 0.24609172344207764\n",
      "train_f1_rounded_score : 0.500853955745697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 12.196304321289062\n",
      "valid_f1_score : 0.2377309799194336\n",
      "valid_f1_rounded_score : 0.5632370114326477\n",
      "current_generator_loss_median : 13.795125246047974\n",
      "discriminator_learning is True\n",
      "[Epoch 4/575] [Batch 0/6200] [D loss: 0.132732, acc:  95%] [G loss: 14.060048] time: 0:42:54.029262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4/575] [Batch 3100/6200] [D loss: 0.326384, acc:   0%] [G loss: 13.190707] time: 0:47:29.521021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.2352205437571698\n",
      "Mean generator_loss : 13.960282325744629\n",
      "Max generator_loss : 18.47345542907715\n",
      "Min generator_loss : 11.731115341186523\n",
      "generator loss decrease : 0.6279020309448242\n",
      "generator loss decrease ratio : (0.9569581747055054)\n",
      "Max generator loss decrease : 0.6160182952880859\n",
      "current lowest generator loss : 14.588184356689453\n",
      "current Learning_rate = 0.00993736947165949\n",
      "save weights\n",
      "train_f1_loss : 12.46976089477539\n",
      "train_f1_score : 0.22063994407653809\n",
      "train_f1_rounded_score : 0.2608603239059448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 12.598726272583008\n",
      "valid_f1_score : 0.212579607963562\n",
      "valid_f1_rounded_score : 0.28736838698387146\n",
      "current_generator_loss_median : 13.211256980895996\n",
      "discriminator_learning is True\n",
      "[Epoch 5/575] [Batch 0/6200] [D loss: 0.389963, acc:   0%] [G loss: 13.446268] time: 0:54:58.412791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/575] [Batch 3100/6200] [D loss: 0.130877, acc:  95%] [G loss: 12.890475] time: 0:59:28.157333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.7281834362683097\n",
      "Mean generator_loss : 13.621274948120117\n",
      "Max generator_loss : 18.040130615234375\n",
      "Min generator_loss : 11.419119834899902\n",
      "generator loss decrease : 0.3390073776245117\n",
      "generator loss decrease ratio : (0.9757162928581238)\n",
      "Max generator loss decrease : 0.43332481384277344\n",
      "current lowest generator loss : 13.960282325744629\n",
      "current Learning_rate = 0.00992170499498161\n",
      "save weights\n",
      "train_f1_loss : 11.437931060791016\n",
      "train_f1_score : 0.2851293087005615\n",
      "train_f1_rounded_score : 0.5431244969367981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.344185829162598\n",
      "valid_f1_score : 0.29098838567733765\n",
      "valid_f1_rounded_score : 0.6226824522018433\n",
      "current_generator_loss_median : 12.83533501625061\n",
      "discriminator_learning is True\n",
      "[Epoch 6/575] [Batch 0/6200] [D loss: 0.128322, acc:  96%] [G loss: 13.177015] time: 1:05:57.441131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/575] [Batch 3100/6200] [D loss: 0.332828, acc:   0%] [G loss: 12.394059] time: 1:10:30.084675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.31112514349557946\n",
      "Mean generator_loss : 13.247443199157715\n",
      "Max generator_loss : 17.50586700439453\n",
      "Min generator_loss : 10.742605209350586\n",
      "generator loss decrease : 0.37383174896240234\n",
      "generator loss decrease ratio : (0.9725552797317505)\n",
      "Max generator loss decrease : 0.5342636108398438\n",
      "current lowest generator loss : 13.621274948120117\n",
      "current Learning_rate = 0.009906037769907363\n",
      "save weights\n",
      "train_f1_loss : 11.21377182006836\n",
      "train_f1_score : 0.29913926124572754\n",
      "train_f1_rounded_score : 0.58778977394104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.372549057006836\n",
      "valid_f1_score : 0.28921568393707275\n",
      "valid_f1_rounded_score : 0.6062325239181519\n",
      "current_generator_loss_median : 12.437298774719238\n",
      "discriminator_learning is True\n",
      "[Epoch 7/575] [Batch 0/6200] [D loss: 0.288804, acc:  13%] [G loss: 12.691450] time: 1:18:01.941073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/575] [Batch 3100/6200] [D loss: 0.127447, acc:  96%] [G loss: 12.139677] time: 1:22:27.204611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.6586928934234544\n",
      "Mean generator_loss : 12.896819114685059\n",
      "Max generator_loss : 16.73448371887207\n",
      "Min generator_loss : 10.329992294311523\n",
      "generator loss decrease : 0.35062408447265625\n",
      "generator loss decrease ratio : (0.9735326766967773)\n",
      "Max generator loss decrease : 0.7713832855224609\n",
      "current lowest generator loss : 13.247443199157715\n",
      "current Learning_rate = 0.009890367791123037\n",
      "save weights\n",
      "train_f1_loss : 11.009604454040527\n",
      "train_f1_score : 0.31189972162246704\n",
      "train_f1_rounded_score : 0.6074554920196533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.020869255065918\n",
      "valid_f1_score : 0.3111956715583801\n",
      "valid_f1_rounded_score : 0.6352718472480774\n",
      "current_generator_loss_median : 12.052607774734497\n",
      "discriminator_learning is True\n",
      "[Epoch 8/575] [Batch 0/6200] [D loss: 0.123987, acc:  96%] [G loss: 12.396527] time: 1:29:08.463768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/575] [Batch 3100/6200] [D loss: 0.358910, acc:   0%] [G loss: 11.741535] time: 1:33:34.765179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.3125997737053599\n",
      "Mean generator_loss : 12.598321914672852\n",
      "Max generator_loss : 16.962203979492188\n",
      "Min generator_loss : 9.910368919372559\n",
      "generator loss decrease : 0.29849720001220703\n",
      "generator loss decrease ratio : (0.9768549799919128)\n",
      "Max generator loss decrease : -0.2277202606201172\n",
      "current lowest generator loss : 12.896819114685059\n",
      "current Learning_rate = 0.009874695053295267\n",
      "save weights\n",
      "train_f1_loss : 10.881927490234375\n",
      "train_f1_score : 0.31987953186035156\n",
      "train_f1_rounded_score : 0.5938026309013367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.065118789672852\n",
      "valid_f1_score : 0.3084300756454468\n",
      "valid_f1_rounded_score : 0.6087657809257507\n",
      "current_generator_loss_median : 11.724409580230713\n",
      "discriminator_learning is True\n",
      "[Epoch 9/575] [Batch 0/6200] [D loss: 0.355171, acc:   0%] [G loss: 11.979297] time: 1:41:00.173812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/575] [Batch 3100/6200] [D loss: 0.119635, acc:  96%] [G loss: 11.563916] time: 1:45:32.326089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.6789647658064708\n",
      "Mean generator_loss : 12.388459205627441\n",
      "Max generator_loss : 16.534645080566406\n",
      "Min generator_loss : 9.528053283691406\n",
      "generator loss decrease : 0.20986270904541016\n",
      "generator loss decrease ratio : (0.9833419919013977)\n",
      "Max generator loss decrease : 0.42755889892578125\n",
      "current lowest generator loss : 12.598321914672852\n",
      "current Learning_rate = 0.00985901955107093\n",
      "save weights\n",
      "train_f1_loss : 10.348981857299805\n",
      "train_f1_score : 0.3531886339187622\n",
      "train_f1_rounded_score : 0.6226089000701904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 10.362201690673828\n",
      "valid_f1_score : 0.35236239433288574\n",
      "valid_f1_rounded_score : 0.6293190717697144\n",
      "current_generator_loss_median : 11.530350685119629\n",
      "discriminator_learning is False\n",
      "[Epoch 10/575] [Batch 0/6200] [D loss: 0.115422, acc:  96%] [G loss: 10.667790] time: 1:52:26.267077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/575] [Batch 3100/6200] [D loss: 0.110524, acc:  96%] [G loss: 12.065356] time: 1:57:30.570925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609198706765328\n",
      "Mean generator_loss : 12.286880493164062\n",
      "Max generator_loss : 16.39931869506836\n",
      "Min generator_loss : 9.733909606933594\n",
      "generator loss decrease : 0.1015787124633789\n",
      "generator loss decrease ratio : (0.9918005466461182)\n",
      "Max generator loss decrease : 0.13532638549804688\n",
      "current lowest generator loss : 12.388459205627441\n",
      "current Learning_rate = 0.00984334127907705\n",
      "save weights\n",
      "train_f1_loss : 11.676736831665039\n",
      "train_f1_score : 0.27020394802093506\n",
      "train_f1_rounded_score : 0.5079058408737183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.880631446838379\n",
      "valid_f1_score : 0.2574605345726013\n",
      "valid_f1_rounded_score : 0.5262599587440491\n",
      "current_generator_loss_median : 11.433988809585571\n",
      "discriminator_learning is False\n",
      "[Epoch 11/575] [Batch 0/6200] [D loss: 0.105687, acc:  96%] [G loss: 10.631285] time: 2:05:25.117880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/575] [Batch 3100/6200] [D loss: 0.105527, acc:  96%] [G loss: 12.003176] time: 2:10:01.573268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609022488517146\n",
      "Mean generator_loss : 12.021363258361816\n",
      "Max generator_loss : 16.28241729736328\n",
      "Min generator_loss : 9.328859329223633\n",
      "generator loss decrease : 0.2655172348022461\n",
      "generator loss decrease ratio : (0.9783901572227478)\n",
      "Max generator loss decrease : 0.11690139770507812\n",
      "current lowest generator loss : 12.286880493164062\n",
      "current Learning_rate = 0.009827660231920667\n",
      "save weights\n",
      "train_f1_loss : 10.284441947937012\n",
      "train_f1_score : 0.35722237825393677\n",
      "train_f1_rounded_score : 0.6086355447769165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 10.177216529846191\n",
      "valid_f1_score : 0.36392396688461304\n",
      "valid_f1_rounded_score : 0.6344282031059265\n",
      "current_generator_loss_median : 11.181044340133667\n",
      "discriminator_learning is False\n",
      "[Epoch 12/575] [Batch 0/6200] [D loss: 0.105612, acc:  96%] [G loss: 10.417776] time: 2:17:08.305835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/575] [Batch 3100/6200] [D loss: 0.105504, acc:  96%] [G loss: 11.929442] time: 2:21:42.761759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9608771351075942\n",
      "Mean generator_loss : 11.758564949035645\n",
      "Max generator_loss : 15.5977144241333\n",
      "Min generator_loss : 8.974586486816406\n",
      "generator loss decrease : 0.2627983093261719\n",
      "generator loss decrease ratio : (0.9781390428543091)\n",
      "Max generator loss decrease : 0.6847028732299805\n",
      "current lowest generator loss : 12.021363258361816\n",
      "current Learning_rate = 0.009811976404188748\n",
      "save weights\n",
      "train_f1_loss : 9.76965618133545\n",
      "train_f1_score : 0.3893964886665344\n",
      "train_f1_rounded_score : 0.610016942024231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.506338119506836\n",
      "valid_f1_score : 0.40585386753082275\n",
      "valid_f1_rounded_score : 0.6331712007522583\n",
      "current_generator_loss_median : 10.91774868965149\n",
      "discriminator_learning is False\n",
      "[Epoch 13/575] [Batch 0/6200] [D loss: 0.105559, acc:  96%] [G loss: 10.148932] time: 2:28:49.090770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13/575] [Batch 3100/6200] [D loss: 0.105523, acc:  96%] [G loss: 11.848240] time: 2:33:22.017305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9608459480347172\n",
      "Mean generator_loss : 11.500055313110352\n",
      "Max generator_loss : 15.4254789352417\n",
      "Min generator_loss : 8.648134231567383\n",
      "generator loss decrease : 0.25850963592529297\n",
      "generator loss decrease ratio : (0.9780151844024658)\n",
      "Max generator loss decrease : 0.17223548889160156\n",
      "current lowest generator loss : 11.758564949035645\n",
      "current Learning_rate = 0.009796289790448063\n",
      "save weights\n",
      "train_f1_loss : 9.820521354675293\n",
      "train_f1_score : 0.3862174153327942\n",
      "train_f1_rounded_score : 0.6138647198677063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.739069938659668\n",
      "valid_f1_score : 0.39130812883377075\n",
      "valid_f1_rounded_score : 0.6296412348747253\n",
      "current_generator_loss_median : 10.657617568969727\n",
      "discriminator_learning is False\n",
      "[Epoch 14/575] [Batch 0/6200] [D loss: 0.105501, acc:  96%] [G loss: 9.801542] time: 2:40:27.554930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14/575] [Batch 3100/6200] [D loss: 0.105543, acc:  96%] [G loss: 11.907017] time: 2:45:00.105420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9607838784494708\n",
      "Mean generator_loss : 11.258598327636719\n",
      "Max generator_loss : 15.708452224731445\n",
      "Min generator_loss : 8.389464378356934\n",
      "generator loss decrease : 0.2414569854736328\n",
      "generator loss decrease ratio : (0.9790038466453552)\n",
      "Max generator loss decrease : -0.2829732894897461\n",
      "current lowest generator loss : 11.500055313110352\n",
      "current Learning_rate = 0.009780600385245078\n",
      "save weights\n",
      "train_f1_loss : 10.060863494873047\n",
      "train_f1_score : 0.37119603157043457\n",
      "train_f1_rounded_score : 0.5579056143760681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.906316757202148\n",
      "valid_f1_score : 0.3808552026748657\n",
      "valid_f1_rounded_score : 0.5849497318267822\n",
      "current_generator_loss_median : 10.433145523071289\n",
      "discriminator_learning is False\n",
      "[Epoch 15/575] [Batch 0/6200] [D loss: 0.105476, acc:  96%] [G loss: 9.521544] time: 2:52:03.791311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15/575] [Batch 3100/6200] [D loss: 0.105549, acc:  96%] [G loss: 11.762527] time: 2:56:36.763825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9607255799155081\n",
      "Mean generator_loss : 11.03856086730957\n",
      "Max generator_loss : 15.792337417602539\n",
      "Min generator_loss : 8.214095115661621\n",
      "generator loss decrease : 0.22003746032714844\n",
      "generator loss decrease ratio : (0.9804560542106628)\n",
      "Max generator loss decrease : -0.08388519287109375\n",
      "current lowest generator loss : 11.258598327636719\n",
      "current Learning_rate = 0.009764908183105844\n",
      "save weights\n",
      "train_f1_loss : 9.633041381835938\n",
      "train_f1_score : 0.3979349136352539\n",
      "train_f1_rounded_score : 0.5980508327484131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.590248107910156\n",
      "valid_f1_score : 0.40060949325561523\n",
      "valid_f1_rounded_score : 0.6091182231903076\n",
      "current_generator_loss_median : 10.211337327957153\n",
      "discriminator_learning is False\n",
      "[Epoch 16/575] [Batch 0/6200] [D loss: 0.105468, acc:  96%] [G loss: 9.324062] time: 3:03:44.213457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16/575] [Batch 3100/6200] [D loss: 0.105579, acc:  96%] [G loss: 11.775255] time: 3:08:26.330678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9606473094032657\n",
      "Mean generator_loss : 10.838601112365723\n",
      "Max generator_loss : 16.29466438293457\n",
      "Min generator_loss : 7.9653754234313965\n",
      "generator loss decrease : 0.19995975494384766\n",
      "generator loss decrease ratio : (0.9818853139877319)\n",
      "Max generator loss decrease : -0.5023269653320312\n",
      "current lowest generator loss : 11.03856086730957\n",
      "current Learning_rate = 0.009749213178535884\n",
      "save weights\n",
      "train_f1_loss : 9.14075756072998\n",
      "train_f1_score : 0.4287026524543762\n",
      "train_f1_rounded_score : 0.6221588253974915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.0714111328125\n",
      "valid_f1_score : 0.43303680419921875\n",
      "valid_f1_rounded_score : 0.6307414174079895\n",
      "current_generator_loss_median : 10.007690906524658\n",
      "discriminator_learning is False\n",
      "[Epoch 17/575] [Batch 0/6200] [D loss: 0.105443, acc:  96%] [G loss: 9.030164] time: 3:15:42.333349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17/575] [Batch 3100/6200] [D loss: 0.105541, acc:  96%] [G loss: 11.689476] time: 3:20:17.888090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9606063662036772\n",
      "Mean generator_loss : 10.648874282836914\n",
      "Max generator_loss : 16.624069213867188\n",
      "Min generator_loss : 7.904540061950684\n",
      "generator loss decrease : 0.1897268295288086\n",
      "generator loss decrease ratio : (0.9824952483177185)\n",
      "Max generator loss decrease : -0.3294048309326172\n",
      "current lowest generator loss : 10.838601112365723\n",
      "current Learning_rate = 0.009733515366020074\n",
      "save weights\n",
      "train_f1_loss : 9.044095993041992\n",
      "train_f1_score : 0.4347440004348755\n",
      "train_f1_rounded_score : 0.6148363351821899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.993866920471191\n",
      "valid_f1_score : 0.43788331747055054\n",
      "valid_f1_rounded_score : 0.6345416903495789\n",
      "current_generator_loss_median : 9.827648162841797\n",
      "discriminator_learning is False\n",
      "[Epoch 18/575] [Batch 0/6200] [D loss: 0.105464, acc:  96%] [G loss: 8.774920] time: 3:27:27.442977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/575] [Batch 3100/6200] [D loss: 0.105605, acc:  96%] [G loss: 11.614001] time: 3:32:01.541495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9605045139789581\n",
      "Mean generator_loss : 10.49825668334961\n",
      "Max generator_loss : 16.412996292114258\n",
      "Min generator_loss : 7.860781669616699\n",
      "generator loss decrease : 0.1506175994873047\n",
      "generator loss decrease ratio : (0.9858559966087341)\n",
      "Max generator loss decrease : 0.2110729217529297\n",
      "current lowest generator loss : 10.648874282836914\n",
      "current Learning_rate = 0.009717814740022538\n",
      "save weights\n",
      "train_f1_loss : 9.220962524414062\n",
      "train_f1_score : 0.4236898422241211\n",
      "train_f1_rounded_score : 0.5677906274795532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.11070442199707\n",
      "valid_f1_score : 0.4305809736251831\n",
      "valid_f1_rounded_score : 0.5946314334869385\n",
      "current_generator_loss_median : 9.620253324508667\n",
      "discriminator_learning is False\n",
      "[Epoch 19/575] [Batch 0/6200] [D loss: 0.105477, acc:  96%] [G loss: 8.662565] time: 3:39:10.204843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19/575] [Batch 3100/6200] [D loss: 0.105535, acc:  96%] [G loss: 11.556224] time: 3:43:42.058733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9604638082365836\n",
      "Mean generator_loss : 10.339436531066895\n",
      "Max generator_loss : 16.859954833984375\n",
      "Min generator_loss : 7.615914344787598\n",
      "generator loss decrease : 0.15882015228271484\n",
      "generator loss decrease ratio : (0.9848717451095581)\n",
      "Max generator loss decrease : -0.4469585418701172\n",
      "current lowest generator loss : 10.49825668334961\n",
      "current Learning_rate = 0.009702111294986522\n",
      "save weights\n",
      "train_f1_loss : 9.224974632263184\n",
      "train_f1_score : 0.423439085483551\n",
      "train_f1_rounded_score : 0.527025580406189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.977685928344727\n",
      "valid_f1_score : 0.4388946294784546\n",
      "valid_f1_rounded_score : 0.5675110816955566\n",
      "current_generator_loss_median : 9.474699020385742\n",
      "discriminator_learning is False\n",
      "[Epoch 20/575] [Batch 0/6200] [D loss: 0.105832, acc:  95%] [G loss: 10.097616] time: 3:50:52.098784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20/575] [Batch 3100/6200] [D loss: 0.101331, acc:  96%] [G loss: 11.022683] time: 3:56:07.331447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9608793313464811\n",
      "Mean generator_loss : 10.274628639221191\n",
      "Max generator_loss : 14.872693061828613\n",
      "Min generator_loss : 6.974387168884277\n",
      "generator loss decrease : 0.06480789184570312\n",
      "generator loss decrease ratio : (0.9937319755554199)\n",
      "Max generator loss decrease : 1.9872617721557617\n",
      "current lowest generator loss : 10.339436531066895\n",
      "current Learning_rate = 0.009686405025334285\n",
      "save weights\n",
      "train_f1_loss : 8.462211608886719\n",
      "train_f1_score : 0.4711117744445801\n",
      "train_f1_rounded_score : 0.5472568273544312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.944848537445068\n",
      "valid_f1_score : 0.5034469664096832\n",
      "valid_f1_rounded_score : 0.609294056892395\n",
      "current_generator_loss_median : 9.46610713005066\n",
      "discriminator_learning is False\n",
      "[Epoch 21/575] [Batch 0/6200] [D loss: 0.097289, acc:  96%] [G loss: 9.620733] time: 4:03:57.565222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21/575] [Batch 3100/6200] [D loss: 0.097332, acc:  96%] [G loss: 10.589856] time: 4:08:31.448847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609324314901906\n",
      "Mean generator_loss : 10.145651817321777\n",
      "Max generator_loss : 14.983393669128418\n",
      "Min generator_loss : 6.995883941650391\n",
      "generator loss decrease : 0.12897682189941406\n",
      "generator loss decrease ratio : (0.9874470829963684)\n",
      "Max generator loss decrease : -0.11070060729980469\n",
      "current lowest generator loss : 10.274628639221191\n",
      "current Learning_rate = 0.009670695925466977\n",
      "save weights\n",
      "train_f1_loss : 7.999335289001465\n",
      "train_f1_score : 0.5000415444374084\n",
      "train_f1_rounded_score : 0.5624125599861145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.504243850708008\n",
      "valid_f1_score : 0.5309847593307495\n",
      "valid_f1_rounded_score : 0.6136124730110168\n",
      "current_generator_loss_median : 9.355292797088623\n",
      "discriminator_learning is False\n",
      "[Epoch 22/575] [Batch 0/6200] [D loss: 0.097258, acc:  96%] [G loss: 9.468264] time: 4:15:42.495917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22/575] [Batch 3100/6200] [D loss: 0.097320, acc:  96%] [G loss: 10.693081] time: 4:20:19.929917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609319886853618\n",
      "Mean generator_loss : 10.033562660217285\n",
      "Max generator_loss : 15.022852897644043\n",
      "Min generator_loss : 6.762822151184082\n",
      "generator loss decrease : 0.11208915710449219\n",
      "generator loss decrease ratio : (0.9889519810676575)\n",
      "Max generator loss decrease : -0.039459228515625\n",
      "current lowest generator loss : 10.145651817321777\n",
      "current Learning_rate = 0.009654983989764524\n",
      "save weights\n",
      "train_f1_loss : 9.032066345214844\n",
      "train_f1_score : 0.43549585342407227\n",
      "train_f1_rounded_score : 0.44702672958374023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.420753479003906\n",
      "valid_f1_score : 0.47370290756225586\n",
      "valid_f1_rounded_score : 0.5178098678588867\n",
      "current_generator_loss_median : 9.26142168045044\n",
      "discriminator_learning is False\n",
      "[Epoch 23/575] [Batch 0/6200] [D loss: 0.097270, acc:  96%] [G loss: 9.442860] time: 4:27:28.559618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23/575] [Batch 3100/6200] [D loss: 0.097312, acc:  96%] [G loss: 10.532987] time: 4:32:03.453346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609316250008921\n",
      "Mean generator_loss : 9.942632675170898\n",
      "Max generator_loss : 14.921895027160645\n",
      "Min generator_loss : 6.7061967849731445\n",
      "generator loss decrease : 0.09092998504638672\n",
      "generator loss decrease ratio : (0.9909374117851257)\n",
      "Max generator loss decrease : 0.10095787048339844\n",
      "current lowest generator loss : 10.033562660217285\n",
      "current Learning_rate = 0.009639269212585509\n",
      "save weights\n",
      "train_f1_loss : 9.911843299865723\n",
      "train_f1_score : 0.38050979375839233\n",
      "train_f1_rounded_score : 0.3539886176586151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.278883934020996\n",
      "valid_f1_score : 0.42006975412368774\n",
      "valid_f1_rounded_score : 0.4220826327800751\n",
      "current_generator_loss_median : 9.143404483795166\n",
      "discriminator_learning is False\n",
      "[Epoch 24/575] [Batch 0/6200] [D loss: 0.097262, acc:  96%] [G loss: 9.431947] time: 4:39:11.783941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/575] [Batch 3100/6200] [D loss: 0.097318, acc:  96%] [G loss: 10.617337] time: 4:43:45.008928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609304144497841\n",
      "Mean generator_loss : 9.861084938049316\n",
      "Max generator_loss : 14.84862995147705\n",
      "Min generator_loss : 6.641371726989746\n",
      "generator loss decrease : 0.08154773712158203\n",
      "generator loss decrease ratio : (0.9917981624603271)\n",
      "Max generator loss decrease : 0.07326507568359375\n",
      "current lowest generator loss : 9.942632675170898\n",
      "current Learning_rate = 0.00962355158826705\n",
      "save weights\n",
      "train_f1_loss : 9.060737609863281\n",
      "train_f1_score : 0.4337038993835449\n",
      "train_f1_rounded_score : 0.4277803301811218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.403826713562012\n",
      "valid_f1_score : 0.47476083040237427\n",
      "valid_f1_rounded_score : 0.4981312155723572\n",
      "current_generator_loss_median : 9.015666961669922\n",
      "discriminator_learning is False\n",
      "[Epoch 25/575] [Batch 0/6200] [D loss: 0.097264, acc:  96%] [G loss: 9.283360] time: 4:50:53.993607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25/575] [Batch 3100/6200] [D loss: 0.097314, acc:  96%] [G loss: 10.793499] time: 4:55:29.000271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609305622116212\n",
      "Mean generator_loss : 9.793990135192871\n",
      "Max generator_loss : 14.650487899780273\n",
      "Min generator_loss : 6.625418186187744\n",
      "generator loss decrease : 0.06709480285644531\n",
      "generator loss decrease ratio : (0.9931960105895996)\n",
      "Max generator loss decrease : 0.19814205169677734\n",
      "current lowest generator loss : 9.861084938049316\n",
      "current Learning_rate = 0.009607831111124681\n",
      "save weights\n",
      "train_f1_loss : 8.459908485412598\n",
      "train_f1_score : 0.47125571966171265\n",
      "train_f1_rounded_score : 0.4881625771522522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.637972831726074\n",
      "valid_f1_score : 0.5226266980171204\n",
      "valid_f1_rounded_score : 0.5701517462730408\n",
      "current_generator_loss_median : 8.983609676361084\n",
      "discriminator_learning is False\n",
      "[Epoch 26/575] [Batch 0/6200] [D loss: 0.097261, acc:  96%] [G loss: 9.348687] time: 5:02:36.260867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26/575] [Batch 3100/6200] [D loss: 0.097340, acc:  96%] [G loss: 10.553640] time: 5:07:10.751489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609300103879744\n",
      "Mean generator_loss : 9.723335266113281\n",
      "Max generator_loss : 15.019731521606445\n",
      "Min generator_loss : 6.555781364440918\n",
      "generator loss decrease : 0.07065486907958984\n",
      "generator loss decrease ratio : (0.9927858710289001)\n",
      "Max generator loss decrease : -0.3692436218261719\n",
      "current lowest generator loss : 9.793990135192871\n",
      "current Learning_rate = 0.009592107775452227\n",
      "save weights\n",
      "train_f1_loss : 7.6092987060546875\n",
      "train_f1_score : 0.524418830871582\n",
      "train_f1_rounded_score : 0.5704426169395447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.1300506591796875\n",
      "valid_f1_score : 0.5543718338012695\n",
      "valid_f1_rounded_score : 0.6251779794692993\n",
      "current_generator_loss_median : 8.89606499671936\n",
      "discriminator_learning is False\n",
      "[Epoch 27/575] [Batch 0/6200] [D loss: 0.097262, acc:  96%] [G loss: 9.275658] time: 5:14:18.170549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27/575] [Batch 3100/6200] [D loss: 0.097309, acc:  96%] [G loss: 10.236639] time: 5:18:54.222355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609297057313304\n",
      "Mean generator_loss : 9.653261184692383\n",
      "Max generator_loss : 14.663446426391602\n",
      "Min generator_loss : 6.627133846282959\n",
      "generator loss decrease : 0.07007408142089844\n",
      "generator loss decrease ratio : (0.9927932024002075)\n",
      "Max generator loss decrease : 0.35628509521484375\n",
      "current lowest generator loss : 9.723335266113281\n",
      "current Learning_rate = 0.00957638157552169\n",
      "save weights\n",
      "train_f1_loss : 7.5261101722717285\n",
      "train_f1_score : 0.529618114233017\n",
      "train_f1_rounded_score : 0.5690261125564575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.228232383728027\n",
      "valid_f1_score : 0.5482354760169983\n",
      "valid_f1_rounded_score : 0.6119206547737122\n",
      "current_generator_loss_median : 8.83939266204834\n",
      "discriminator_learning is False\n",
      "[Epoch 28/575] [Batch 0/6200] [D loss: 0.097258, acc:  96%] [G loss: 9.289200] time: 5:26:03.688147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28/575] [Batch 3100/6200] [D loss: 0.097307, acc:  96%] [G loss: 10.492771] time: 5:30:40.768123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609298827186707\n",
      "Mean generator_loss : 9.611318588256836\n",
      "Max generator_loss : 14.833498001098633\n",
      "Min generator_loss : 6.593247890472412\n",
      "generator loss decrease : 0.041942596435546875\n",
      "generator loss decrease ratio : (0.9956550598144531)\n",
      "Max generator loss decrease : -0.17005157470703125\n",
      "current lowest generator loss : 9.653261184692383\n",
      "current Learning_rate = 0.009560652505583111\n",
      "save weights\n",
      "train_f1_loss : 8.2905912399292\n",
      "train_f1_score : 0.48183804750442505\n",
      "train_f1_rounded_score : 0.4871080219745636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.629103183746338\n",
      "valid_f1_score : 0.5231810510158539\n",
      "valid_f1_rounded_score : 0.5549865961074829\n",
      "current_generator_loss_median : 8.815597534179688\n",
      "discriminator_learning is False\n",
      "[Epoch 29/575] [Batch 0/6200] [D loss: 0.097257, acc:  96%] [G loss: 9.365679] time: 5:37:47.869276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29/575] [Batch 3100/6200] [D loss: 0.097306, acc:  96%] [G loss: 10.440543] time: 5:42:23.215545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609285733392162\n",
      "Mean generator_loss : 9.554929733276367\n",
      "Max generator_loss : 14.682653427124023\n",
      "Min generator_loss : 6.608072757720947\n",
      "generator loss decrease : 0.05638885498046875\n",
      "generator loss decrease ratio : (0.9941330552101135)\n",
      "Max generator loss decrease : 0.15084457397460938\n",
      "current lowest generator loss : 9.611318588256836\n",
      "current Learning_rate = 0.009544920559864464\n",
      "save weights\n",
      "train_f1_loss : 8.682272911071777\n",
      "train_f1_score : 0.4573579430580139\n",
      "train_f1_rounded_score : 0.4593515396118164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.246087074279785\n",
      "valid_f1_score : 0.4846195578575134\n",
      "valid_f1_rounded_score : 0.5143750905990601\n",
      "current_generator_loss_median : 8.743117332458496\n",
      "discriminator_learning is False\n",
      "[Epoch 30/575] [Batch 0/6200] [D loss: 0.097255, acc:  96%] [G loss: 8.610476] time: 5:49:29.048318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/575] [Batch 3100/6200] [D loss: 0.093353, acc:  96%] [G loss: 8.226096] time: 5:54:44.195689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609219674141176\n",
      "Mean generator_loss : 9.562565803527832\n",
      "Max generator_loss : 16.986526489257812\n",
      "Min generator_loss : 6.866732597351074\n",
      "generator loss decrease : -0.007636070251464844\n",
      "generator loss decrease ratio : (1.0007991790771484)\n",
      "Max generator loss decrease : -2.303873062133789\n",
      "current lowest generator loss : 9.554929733276367\n",
      "current Learning_rate = 0.009529185732571511\n",
      "train_f1_loss : 8.179941177368164\n",
      "train_f1_score : 0.48875367641448975\n",
      "train_f1_rounded_score : 0.6060298681259155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.334223747253418\n",
      "valid_f1_score : 0.4791110157966614\n",
      "valid_f1_rounded_score : 0.619610607624054\n",
      "current_generator_loss_median : 8.838557958602905\n",
      "discriminator_learning is False\n",
      "[Epoch 31/575] [Batch 0/6200] [D loss: 0.089833, acc:  96%] [G loss: 8.859292] time: 6:02:35.271898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31/575] [Batch 3100/6200] [D loss: 0.089825, acc:  96%] [G loss: 8.187092] time: 6:07:10.438342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.960937106705481\n",
      "Mean generator_loss : 9.500368118286133\n",
      "Max generator_loss : 16.95766258239746\n",
      "Min generator_loss : 7.122793674468994\n",
      "generator loss decrease : 0.054561614990234375\n",
      "generator loss decrease ratio : (0.9942896962165833)\n",
      "Max generator loss decrease : 0.028863906860351562\n",
      "current lowest generator loss : 9.554929733276367\n",
      "current Learning_rate = 0.009513448017887694\n",
      "save weights\n",
      "train_f1_loss : 7.597598075866699\n",
      "train_f1_score : 0.5251501202583313\n",
      "train_f1_rounded_score : 0.5923671722412109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.784616470336914\n",
      "valid_f1_score : 0.5134614706039429\n",
      "valid_f1_rounded_score : 0.6033226847648621\n",
      "current_generator_loss_median : 8.765861749649048\n",
      "discriminator_learning is False\n",
      "[Epoch 32/575] [Batch 0/6200] [D loss: 0.089832, acc:  96%] [G loss: 8.802965] time: 6:14:20.764048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32/575] [Batch 3100/6200] [D loss: 0.089828, acc:  96%] [G loss: 8.482747] time: 6:18:58.645144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609371558312447\n",
      "Mean generator_loss : 9.446484565734863\n",
      "Max generator_loss : 16.904268264770508\n",
      "Min generator_loss : 6.875662326812744\n",
      "generator loss decrease : 0.05388355255126953\n",
      "generator loss decrease ratio : (0.9943282604217529)\n",
      "Max generator loss decrease : 0.053394317626953125\n",
      "current lowest generator loss : 9.500368118286133\n",
      "current Learning_rate = 0.009497707409973995\n",
      "save weights\n",
      "train_f1_loss : 8.722993850708008\n",
      "train_f1_score : 0.4548128843307495\n",
      "train_f1_rounded_score : 0.622284471988678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.612908363342285\n",
      "valid_f1_score : 0.4616932272911072\n",
      "valid_f1_rounded_score : 0.6302501559257507\n",
      "current_generator_loss_median : 8.676716327667236\n",
      "discriminator_learning is False\n",
      "[Epoch 33/575] [Batch 0/6200] [D loss: 0.089826, acc:  96%] [G loss: 8.783582] time: 6:26:11.111557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33/575] [Batch 3100/6200] [D loss: 0.089827, acc:  96%] [G loss: 8.155730] time: 6:30:48.367994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609371363155303\n",
      "Mean generator_loss : 9.407550811767578\n",
      "Max generator_loss : 16.844358444213867\n",
      "Min generator_loss : 7.109543800354004\n",
      "generator loss decrease : 0.038933753967285156\n",
      "generator loss decrease ratio : (0.9958785176277161)\n",
      "Max generator loss decrease : 0.059909820556640625\n",
      "current lowest generator loss : 9.446484565734863\n",
      "current Learning_rate = 0.00948196390296881\n",
      "save weights\n",
      "train_f1_loss : 8.678932189941406\n",
      "train_f1_score : 0.4575667381286621\n",
      "train_f1_rounded_score : 0.6210967898368835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.889537811279297\n",
      "valid_f1_score : 0.44440388679504395\n",
      "valid_f1_rounded_score : 0.6162866353988647\n",
      "current_generator_loss_median : 8.673466444015503\n",
      "discriminator_learning is False\n",
      "[Epoch 34/575] [Batch 0/6200] [D loss: 0.089831, acc:  96%] [G loss: 8.471514] time: 6:37:56.740469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34/575] [Batch 3100/6200] [D loss: 0.089827, acc:  96%] [G loss: 7.999377] time: 6:42:31.819992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609371363155303\n",
      "Mean generator_loss : 9.379889488220215\n",
      "Max generator_loss : 16.890819549560547\n",
      "Min generator_loss : 6.76822566986084\n",
      "generator loss decrease : 0.02766132354736328\n",
      "generator loss decrease ratio : (0.9970596432685852)\n",
      "Max generator loss decrease : -0.04646110534667969\n",
      "current lowest generator loss : 9.407550811767578\n",
      "current Learning_rate = 0.009466217490987828\n",
      "save weights\n",
      "train_f1_loss : 7.998968124389648\n",
      "train_f1_score : 0.500064492225647\n",
      "train_f1_rounded_score : 0.6128482818603516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.110664367675781\n",
      "valid_f1_score : 0.49308347702026367\n",
      "valid_f1_rounded_score : 0.6267923712730408\n",
      "current_generator_loss_median : 8.632652759552002\n",
      "discriminator_learning is False\n",
      "[Epoch 35/575] [Batch 0/6200] [D loss: 0.089831, acc:  96%] [G loss: 8.824621] time: 6:49:41.628465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35/575] [Batch 3100/6200] [D loss: 0.089823, acc:  96%] [G loss: 8.260651] time: 6:54:21.933274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370968995555\n",
      "Mean generator_loss : 9.333544731140137\n",
      "Max generator_loss : 17.00368309020996\n",
      "Min generator_loss : 7.156191349029541\n",
      "generator loss decrease : 0.046344757080078125\n",
      "generator loss decrease ratio : (0.9950591325759888)\n",
      "Max generator loss decrease : -0.11286354064941406\n",
      "current lowest generator loss : 9.379889488220215\n",
      "current Learning_rate = 0.00945046816812389\n",
      "save weights\n",
      "train_f1_loss : 7.701595306396484\n",
      "train_f1_score : 0.5186502933502197\n",
      "train_f1_rounded_score : 0.5740067958831787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.659518241882324\n",
      "valid_f1_score : 0.5212801098823547\n",
      "valid_f1_rounded_score : 0.603728711605072\n",
      "current_generator_loss_median : 8.58686089515686\n",
      "discriminator_learning is False\n",
      "[Epoch 36/575] [Batch 0/6200] [D loss: 0.089833, acc:  96%] [G loss: 8.401205] time: 7:01:31.423063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/575] [Batch 3100/6200] [D loss: 0.089826, acc:  96%] [G loss: 7.979599] time: 7:06:05.474124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609371068016175\n",
      "Mean generator_loss : 9.298775672912598\n",
      "Max generator_loss : 16.684268951416016\n",
      "Min generator_loss : 7.10205602645874\n",
      "generator loss decrease : 0.03476905822753906\n",
      "generator loss decrease ratio : (0.9962748289108276)\n",
      "Max generator loss decrease : 0.3194141387939453\n",
      "current lowest generator loss : 9.333544731140137\n",
      "current Learning_rate = 0.009434715928446863\n",
      "save weights\n",
      "train_f1_loss : 7.6557159423828125\n",
      "train_f1_score : 0.5215177536010742\n",
      "train_f1_rounded_score : 0.5847123265266418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.600808143615723\n",
      "valid_f1_score : 0.5249494910240173\n",
      "valid_f1_rounded_score : 0.6107621788978577\n",
      "current_generator_loss_median : 8.554609298706055\n",
      "discriminator_learning is False\n",
      "[Epoch 37/575] [Batch 0/6200] [D loss: 0.089834, acc:  96%] [G loss: 8.554092] time: 7:13:17.936372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 37/575] [Batch 3100/6200] [D loss: 0.089826, acc:  96%] [G loss: 8.090999] time: 7:17:56.317885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370475815189\n",
      "Mean generator_loss : 9.263752937316895\n",
      "Max generator_loss : 16.711177825927734\n",
      "Min generator_loss : 6.9915947914123535\n",
      "generator loss decrease : 0.035022735595703125\n",
      "generator loss decrease ratio : (0.9962336421012878)\n",
      "Max generator loss decrease : -0.02690887451171875\n",
      "current lowest generator loss : 9.298775672912598\n",
      "current Learning_rate = 0.009418960766003508\n",
      "save weights\n",
      "train_f1_loss : 7.932079315185547\n",
      "train_f1_score : 0.5042450428009033\n",
      "train_f1_rounded_score : 0.6202079653739929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.948369026184082\n",
      "valid_f1_score : 0.5032269358634949\n",
      "valid_f1_rounded_score : 0.6327562928199768\n",
      "current_generator_loss_median : 8.494362115859985\n",
      "discriminator_learning is False\n",
      "[Epoch 38/575] [Batch 0/6200] [D loss: 0.089832, acc:  96%] [G loss: 8.495904] time: 7:25:07.687528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 38/575] [Batch 3100/6200] [D loss: 0.089827, acc:  96%] [G loss: 7.915077] time: 7:29:44.748925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370870936301\n",
      "Mean generator_loss : 9.227761268615723\n",
      "Max generator_loss : 16.83222007751465\n",
      "Min generator_loss : 7.023122310638428\n",
      "generator loss decrease : 0.035991668701171875\n",
      "generator loss decrease ratio : (0.9961147904396057)\n",
      "Max generator loss decrease : -0.12104225158691406\n",
      "current lowest generator loss : 9.263752937316895\n",
      "current Learning_rate = 0.009403202674817347\n",
      "save weights\n",
      "train_f1_loss : 7.958358287811279\n",
      "train_f1_score : 0.502602607011795\n",
      "train_f1_rounded_score : 0.6255501508712769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.068378448486328\n",
      "valid_f1_score : 0.4957263469696045\n",
      "valid_f1_rounded_score : 0.6418935060501099\n",
      "current_generator_loss_median : 8.484873294830322\n",
      "discriminator_learning is False\n",
      "[Epoch 39/575] [Batch 0/6200] [D loss: 0.089832, acc:  96%] [G loss: 8.453606] time: 7:36:52.448778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 39/575] [Batch 3100/6200] [D loss: 0.089824, acc:  96%] [G loss: 8.168756] time: 7:41:28.644435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370476776554\n",
      "Mean generator_loss : 9.234999656677246\n",
      "Max generator_loss : 16.613325119018555\n",
      "Min generator_loss : 7.103425025939941\n",
      "generator loss decrease : -0.0072383880615234375\n",
      "generator loss decrease ratio : (1.0007843971252441)\n",
      "Max generator loss decrease : 0.21889495849609375\n",
      "current lowest generator loss : 9.227761268615723\n",
      "current Learning_rate = 0.009387441648888528\n",
      "train_f1_loss : 7.778840065002441\n",
      "train_f1_score : 0.5138224959373474\n",
      "train_f1_rounded_score : 0.5464056730270386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.819582462310791\n",
      "valid_f1_score : 0.5112760961055756\n",
      "valid_f1_rounded_score : 0.5720957517623901\n",
      "current_generator_loss_median : 8.483981847763062\n",
      "discriminator_learning is False\n",
      "[Epoch 40/575] [Batch 0/6200] [D loss: 0.089661, acc:  96%] [G loss: 10.890744] time: 7:48:37.138833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 40/575] [Batch 3100/6200] [D loss: 0.086205, acc:  96%] [G loss: 10.373895] time: 7:53:54.308723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609277751176588\n",
      "Mean generator_loss : 9.38411808013916\n",
      "Max generator_loss : 14.440742492675781\n",
      "Min generator_loss : 6.086556911468506\n",
      "generator loss decrease : -0.1563568115234375\n",
      "generator loss decrease ratio : (1.016944169998169)\n",
      "Max generator loss decrease : 2.1725826263427734\n",
      "current lowest generator loss : 9.227761268615723\n",
      "current Learning_rate = 0.009371677682193687\n",
      "train_f1_loss : 8.309107780456543\n",
      "train_f1_score : 0.48068076372146606\n",
      "train_f1_rounded_score : 0.5477042198181152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.375168800354004\n",
      "valid_f1_score : 0.47655194997787476\n",
      "valid_f1_rounded_score : 0.5682817697525024\n",
      "current_generator_loss_median : 8.624644756317139\n",
      "discriminator_learning is False\n",
      "[Epoch 41/575] [Batch 0/6200] [D loss: 0.082924, acc:  96%] [G loss: 10.732329] time: 8:01:48.918368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/575] [Batch 3100/6200] [D loss: 0.082938, acc:  96%] [G loss: 10.429616] time: 8:06:21.275466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609366733220316\n",
      "Mean generator_loss : 9.334466934204102\n",
      "Max generator_loss : 14.066668510437012\n",
      "Min generator_loss : 6.010962009429932\n",
      "generator loss decrease : -0.1067056655883789\n",
      "generator loss decrease ratio : (1.0115635395050049)\n",
      "Max generator loss decrease : 0.37407398223876953\n",
      "current lowest generator loss : 9.227761268615723\n",
      "current Learning_rate = 0.009355910768685822\n",
      "train_f1_loss : 8.19338607788086\n",
      "train_f1_score : 0.4879133701324463\n",
      "train_f1_rounded_score : 0.5129345059394836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.238738059997559\n",
      "valid_f1_score : 0.4850788712501526\n",
      "valid_f1_rounded_score : 0.5362542867660522\n",
      "current_generator_loss_median : 8.578139066696167\n",
      "discriminator_learning is False\n",
      "[Epoch 42/575] [Batch 0/6200] [D loss: 0.082923, acc:  96%] [G loss: 10.523393] time: 8:13:31.352226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 42/575] [Batch 3100/6200] [D loss: 0.082938, acc:  96%] [G loss: 9.988881] time: 8:18:07.128883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609365845880201\n",
      "Mean generator_loss : 9.2786865234375\n",
      "Max generator_loss : 13.863687515258789\n",
      "Min generator_loss : 6.03467321395874\n",
      "generator loss decrease : -0.050925254821777344\n",
      "generator loss decrease ratio : (1.0055186748504639)\n",
      "Max generator loss decrease : 0.20298099517822266\n",
      "current lowest generator loss : 9.227761268615723\n",
      "current Learning_rate = 0.009340140902294139\n",
      "train_f1_loss : 8.131417274475098\n",
      "train_f1_score : 0.4917864203453064\n",
      "train_f1_rounded_score : 0.553935706615448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.229228019714355\n",
      "valid_f1_score : 0.4856732487678528\n",
      "valid_f1_rounded_score : 0.5776194930076599\n",
      "current_generator_loss_median : 8.51578688621521\n",
      "discriminator_learning is False\n",
      "[Epoch 43/575] [Batch 0/6200] [D loss: 0.082923, acc:  96%] [G loss: 10.563859] time: 8:25:17.503234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 43/575] [Batch 3100/6200] [D loss: 0.082936, acc:  96%] [G loss: 10.197602] time: 8:29:53.713061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609366535179077\n",
      "Mean generator_loss : 9.256887435913086\n",
      "Max generator_loss : 13.657801628112793\n",
      "Min generator_loss : 5.996219158172607\n",
      "generator loss decrease : -0.02912616729736328\n",
      "generator loss decrease ratio : (1.003156304359436)\n",
      "Max generator loss decrease : 0.2058858871459961\n",
      "current lowest generator loss : 9.227761268615723\n",
      "current Learning_rate = 0.009324368076923929\n",
      "train_f1_loss : 8.308128356933594\n",
      "train_f1_score : 0.4807419776916504\n",
      "train_f1_rounded_score : 0.5292186737060547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.414778709411621\n",
      "valid_f1_score : 0.4740763306617737\n",
      "valid_f1_rounded_score : 0.5428314208984375\n",
      "current_generator_loss_median : 8.47352647781372\n",
      "discriminator_learning is False\n",
      "[Epoch 44/575] [Batch 0/6200] [D loss: 0.082924, acc:  96%] [G loss: 10.670720] time: 8:37:03.654837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 44/575] [Batch 3100/6200] [D loss: 0.082938, acc:  96%] [G loss: 10.051031] time: 8:41:34.827506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609366241001314\n",
      "Mean generator_loss : 9.223711967468262\n",
      "Max generator_loss : 14.609295845031738\n",
      "Min generator_loss : 6.387415885925293\n",
      "generator loss decrease : 0.0040493011474609375\n",
      "generator loss decrease ratio : (0.9995611906051636)\n",
      "Max generator loss decrease : -0.9514942169189453\n",
      "current lowest generator loss : 9.227761268615723\n",
      "current Learning_rate = 0.009308592286456422\n",
      "save weights\n",
      "train_f1_loss : 8.42240047454834\n",
      "train_f1_score : 0.47359997034072876\n",
      "train_f1_rounded_score : 0.48560193181037903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.38830852508545\n",
      "valid_f1_score : 0.4757307171821594\n",
      "valid_f1_rounded_score : 0.5244570374488831\n",
      "current_generator_loss_median : 8.461356401443481\n",
      "discriminator_learning is False\n",
      "[Epoch 45/575] [Batch 0/6200] [D loss: 0.082924, acc:  96%] [G loss: 10.650830] time: 8:48:45.400205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 45/575] [Batch 3100/6200] [D loss: 0.082938, acc:  96%] [G loss: 10.163009] time: 8:53:19.976450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609366240039948\n",
      "Mean generator_loss : 9.180695533752441\n",
      "Max generator_loss : 13.519373893737793\n",
      "Min generator_loss : 6.000779628753662\n",
      "generator loss decrease : 0.04301643371582031\n",
      "generator loss decrease ratio : (0.9953362941741943)\n",
      "Max generator loss decrease : 1.0899219512939453\n",
      "current lowest generator loss : 9.223711967468262\n",
      "current Learning_rate = 0.009292813524748644\n",
      "save weights\n",
      "train_f1_loss : 8.009727478027344\n",
      "train_f1_score : 0.499392032623291\n",
      "train_f1_rounded_score : 0.605211079120636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.111485481262207\n",
      "valid_f1_score : 0.49303215742111206\n",
      "valid_f1_rounded_score : 0.6256881952285767\n",
      "current_generator_loss_median : 8.422453880310059\n",
      "discriminator_learning is False\n",
      "[Epoch 46/575] [Batch 0/6200] [D loss: 0.082922, acc:  96%] [G loss: 10.455646] time: 9:00:30.045574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 46/575] [Batch 3100/6200] [D loss: 0.082937, acc:  96%] [G loss: 10.231855] time: 9:05:01.504941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609366339060568\n",
      "Mean generator_loss : 9.16063117980957\n",
      "Max generator_loss : 13.454465866088867\n",
      "Min generator_loss : 6.112114906311035\n",
      "generator loss decrease : 0.020064353942871094\n",
      "generator loss decrease ratio : (0.9978144764900208)\n",
      "Max generator loss decrease : 0.06490802764892578\n",
      "current lowest generator loss : 9.180695533752441\n",
      "current Learning_rate = 0.009277031785633282\n",
      "save weights\n",
      "train_f1_loss : 7.648131370544434\n",
      "train_f1_score : 0.5219917893409729\n",
      "train_f1_rounded_score : 0.5924827456474304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.693142890930176\n",
      "valid_f1_score : 0.519178569316864\n",
      "valid_f1_rounded_score : 0.607857346534729\n",
      "current_generator_loss_median : 8.383270263671875\n",
      "discriminator_learning is False\n",
      "[Epoch 47/575] [Batch 0/6200] [D loss: 0.082922, acc:  96%] [G loss: 10.638253] time: 9:12:12.758094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/575] [Batch 3100/6200] [D loss: 0.082937, acc:  96%] [G loss: 10.213598] time: 9:16:46.884373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.960936673225895\n",
      "Mean generator_loss : 9.158720970153809\n",
      "Max generator_loss : 13.49516487121582\n",
      "Min generator_loss : 6.0979695320129395\n",
      "generator loss decrease : 0.0019102096557617188\n",
      "generator loss decrease ratio : (0.9997915029525757)\n",
      "Max generator loss decrease : -0.040699005126953125\n",
      "current lowest generator loss : 9.16063117980957\n",
      "current Learning_rate = 0.009261247062918537\n",
      "save weights\n",
      "train_f1_loss : 7.65259313583374\n",
      "train_f1_score : 0.5217129290103912\n",
      "train_f1_rounded_score : 0.59998619556427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.668740272521973\n",
      "valid_f1_score : 0.5207037329673767\n",
      "valid_f1_rounded_score : 0.6179112195968628\n",
      "current_generator_loss_median : 8.393815279006958\n",
      "discriminator_learning is False\n",
      "[Epoch 48/575] [Batch 0/6200] [D loss: 0.082923, acc:  96%] [G loss: 10.609755] time: 9:24:03.433355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 48/575] [Batch 3100/6200] [D loss: 0.082935, acc:  96%] [G loss: 9.736144] time: 9:28:41.916275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.960936604392144\n",
      "Mean generator_loss : 9.11600399017334\n",
      "Max generator_loss : 13.482661247253418\n",
      "Min generator_loss : 6.090426921844482\n",
      "generator loss decrease : 0.04271697998046875\n",
      "generator loss decrease ratio : (0.9953359365463257)\n",
      "Max generator loss decrease : 0.012503623962402344\n",
      "current lowest generator loss : 9.158720970153809\n",
      "current Learning_rate = 0.009245459350387978\n",
      "save weights\n",
      "train_f1_loss : 7.432213306427002\n",
      "train_f1_score : 0.5354866683483124\n",
      "train_f1_rounded_score : 0.5789802074432373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.350432872772217\n",
      "valid_f1_score : 0.5405979454517365\n",
      "valid_f1_rounded_score : 0.6052139401435852\n",
      "current_generator_loss_median : 8.332624197006226\n",
      "discriminator_learning is False\n",
      "[Epoch 49/575] [Batch 0/6200] [D loss: 0.082922, acc:  96%] [G loss: 10.583047] time: 9:36:06.118492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 49/575] [Batch 3100/6200] [D loss: 0.082936, acc:  96%] [G loss: 10.021044] time: 9:40:41.550279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.960936604392144\n",
      "Mean generator_loss : 9.098392486572266\n",
      "Max generator_loss : 13.073135375976562\n",
      "Min generator_loss : 6.012342929840088\n",
      "generator loss decrease : 0.01761150360107422\n",
      "generator loss decrease ratio : (0.99806809425354)\n",
      "Max generator loss decrease : 0.40952587127685547\n",
      "current lowest generator loss : 9.11600399017334\n",
      "current Learning_rate = 0.00922966864180041\n",
      "save weights\n",
      "train_f1_loss : 7.52443790435791\n",
      "train_f1_score : 0.5297226309776306\n",
      "train_f1_rounded_score : 0.5761160254478455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.4271111488342285\n",
      "valid_f1_score : 0.5358055531978607\n",
      "valid_f1_rounded_score : 0.6022225022315979\n",
      "current_generator_loss_median : 8.352756261825562\n",
      "discriminator_learning is False\n",
      "[Epoch 50/575] [Batch 0/6200] [D loss: 0.082882, acc:  96%] [G loss: 8.491761] time: 9:48:10.709278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 50/575] [Batch 3100/6200] [D loss: 0.079750, acc:  96%] [G loss: 8.566476] time: 9:53:34.012279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609305898028035\n",
      "Mean generator_loss : 9.154383659362793\n",
      "Max generator_loss : 14.29204273223877\n",
      "Min generator_loss : 6.7221269607543945\n",
      "generator loss decrease : -0.055991172790527344\n",
      "generator loss decrease ratio : (1.00615394115448)\n",
      "Max generator loss decrease : -1.218907356262207\n",
      "current lowest generator loss : 9.098392486572266\n",
      "current Learning_rate = 0.009213874930889704\n",
      "train_f1_loss : 7.121834754943848\n",
      "train_f1_score : 0.5548853278160095\n",
      "train_f1_rounded_score : 0.6055329442024231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.141423225402832\n",
      "valid_f1_score : 0.553661048412323\n",
      "valid_f1_rounded_score : 0.6208555102348328\n",
      "current_generator_loss_median : 8.430485010147095\n",
      "discriminator_learning is False\n",
      "[Epoch 51/575] [Batch 0/6200] [D loss: 0.076784, acc:  96%] [G loss: 9.248947] time: 10:01:31.609651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 51/575] [Batch 3100/6200] [D loss: 0.076796, acc:  96%] [G loss: 8.294476] time: 10:06:10.688151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370965150095\n",
      "Mean generator_loss : 9.131292343139648\n",
      "Max generator_loss : 14.272100448608398\n",
      "Min generator_loss : 6.7001214027404785\n",
      "generator loss decrease : -0.03289985656738281\n",
      "generator loss decrease ratio : (1.0036159753799438)\n",
      "Max generator loss decrease : 0.019942283630371094\n",
      "current lowest generator loss : 9.098392486572266\n",
      "current Learning_rate = 0.009198078211364674\n",
      "train_f1_loss : 7.677193641662598\n",
      "train_f1_score : 0.5201753973960876\n",
      "train_f1_rounded_score : 0.5472819805145264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.375073432922363\n",
      "valid_f1_score : 0.5390579104423523\n",
      "valid_f1_rounded_score : 0.5977857708930969\n",
      "current_generator_loss_median : 8.385534048080444\n",
      "discriminator_learning is False\n",
      "[Epoch 52/575] [Batch 0/6200] [D loss: 0.076780, acc:  96%] [G loss: 8.959245] time: 10:13:25.290653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 52/575] [Batch 3100/6200] [D loss: 0.076783, acc:  96%] [G loss: 8.165290] time: 10:18:03.024153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609369390433834\n",
      "Mean generator_loss : 9.09583568572998\n",
      "Max generator_loss : 14.268499374389648\n",
      "Min generator_loss : 6.614719390869141\n",
      "generator loss decrease : 0.0025568008422851562\n",
      "generator loss decrease ratio : (0.999718964099884)\n",
      "Max generator loss decrease : 0.00360107421875\n",
      "current lowest generator loss : 9.098392486572266\n",
      "current Learning_rate = 0.009182278476908919\n",
      "save weights\n",
      "train_f1_loss : 7.474765777587891\n",
      "train_f1_score : 0.5328271389007568\n",
      "train_f1_rounded_score : 0.5704687833786011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.382763862609863\n",
      "valid_f1_score : 0.5385772585868835\n",
      "valid_f1_rounded_score : 0.5972680449485779\n",
      "current_generator_loss_median : 8.341651916503906\n",
      "discriminator_learning is False\n",
      "[Epoch 53/575] [Batch 0/6200] [D loss: 0.076781, acc:  96%] [G loss: 8.966844] time: 10:25:16.896653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 53/575] [Batch 3100/6200] [D loss: 0.076784, acc:  96%] [G loss: 8.192014] time: 10:29:59.207162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370670010967\n",
      "Mean generator_loss : 9.081055641174316\n",
      "Max generator_loss : 14.394511222839355\n",
      "Min generator_loss : 6.727869987487793\n",
      "generator loss decrease : 0.014780044555664062\n",
      "generator loss decrease ratio : (0.9983750581741333)\n",
      "Max generator loss decrease : -0.12601184844970703\n",
      "current lowest generator loss : 9.09583568572998\n",
      "current Learning_rate = 0.009166475721180666\n",
      "save weights\n",
      "train_f1_loss : 7.9834980964660645\n",
      "train_f1_score : 0.501031368970871\n",
      "train_f1_rounded_score : 0.5098668336868286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.711992263793945\n",
      "valid_f1_score : 0.5180004835128784\n",
      "valid_f1_rounded_score : 0.5626253485679626\n",
      "current_generator_loss_median : 8.346137285232544\n",
      "discriminator_learning is False\n",
      "[Epoch 54/575] [Batch 0/6200] [D loss: 0.076778, acc:  96%] [G loss: 8.772823] time: 10:37:13.545652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/575] [Batch 3100/6200] [D loss: 0.076792, acc:  96%] [G loss: 7.972391] time: 10:41:54.263152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609369489454453\n",
      "Mean generator_loss : 9.040938377380371\n",
      "Max generator_loss : 14.17852783203125\n",
      "Min generator_loss : 6.489593505859375\n",
      "generator loss decrease : 0.04011726379394531\n",
      "generator loss decrease ratio : (0.9955823421478271)\n",
      "Max generator loss decrease : 0.21598339080810547\n",
      "current lowest generator loss : 9.081055641174316\n",
      "current Learning_rate = 0.009150669937812633\n",
      "save weights\n",
      "train_f1_loss : 7.1527419090271\n",
      "train_f1_score : 0.5529536306858063\n",
      "train_f1_rounded_score : 0.6351235508918762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.215755939483643\n",
      "valid_f1_score : 0.5490152537822723\n",
      "valid_f1_rounded_score : 0.6414176225662231\n",
      "current_generator_loss_median : 8.336559295654297\n",
      "discriminator_learning is False\n",
      "[Epoch 55/575] [Batch 0/6200] [D loss: 0.076787, acc:  96%] [G loss: 8.696780] time: 10:49:11.861970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 55/575] [Batch 3100/6200] [D loss: 0.076795, acc:  96%] [G loss: 7.926646] time: 10:53:54.477968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609369979750726\n",
      "Mean generator_loss : 9.047164916992188\n",
      "Max generator_loss : 13.975488662719727\n",
      "Min generator_loss : 6.749525547027588\n",
      "generator loss decrease : -0.006226539611816406\n",
      "generator loss decrease ratio : (1.0006886720657349)\n",
      "Max generator loss decrease : 0.20303916931152344\n",
      "current lowest generator loss : 9.040938377380371\n",
      "current Learning_rate = 0.00913486112041187\n",
      "train_f1_loss : 7.344395160675049\n",
      "train_f1_score : 0.5409753024578094\n",
      "train_f1_rounded_score : 0.5736229419708252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.310085296630859\n",
      "valid_f1_score : 0.5431196689605713\n",
      "valid_f1_rounded_score : 0.604559600353241\n",
      "current_generator_loss_median : 8.329023122787476\n",
      "discriminator_learning is False\n",
      "[Epoch 56/575] [Batch 0/6200] [D loss: 0.076780, acc:  96%] [G loss: 8.454569] time: 11:01:07.850688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 56/575] [Batch 3100/6200] [D loss: 0.076787, acc:  96%] [G loss: 7.678721] time: 11:05:45.429686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370867090841\n",
      "Mean generator_loss : 8.999537467956543\n",
      "Max generator_loss : 14.141565322875977\n",
      "Min generator_loss : 6.414842128753662\n",
      "generator loss decrease : 0.041400909423828125\n",
      "generator loss decrease ratio : (0.9954207539558411)\n",
      "Max generator loss decrease : -0.16607666015625\n",
      "current lowest generator loss : 9.040938377380371\n",
      "current Learning_rate = 0.009119049262559607\n",
      "save weights\n",
      "train_f1_loss : 7.060717582702637\n",
      "train_f1_score : 0.5587051510810852\n",
      "train_f1_rounded_score : 0.5863873362541199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 6.9095377922058105\n",
      "valid_f1_score : 0.5681538879871368\n",
      "valid_f1_rounded_score : 0.6184060573577881\n",
      "current_generator_loss_median : 8.260786771774292\n",
      "discriminator_learning is False\n",
      "[Epoch 57/575] [Batch 0/6200] [D loss: 0.076782, acc:  96%] [G loss: 8.831722] time: 11:13:00.168962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 57/575] [Batch 3100/6200] [D loss: 0.076782, acc:  96%] [G loss: 8.115549] time: 11:17:37.950461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609369586552343\n",
      "Mean generator_loss : 8.998307228088379\n",
      "Max generator_loss : 14.278604507446289\n",
      "Min generator_loss : 6.631711006164551\n",
      "generator loss decrease : 0.0012302398681640625\n",
      "generator loss decrease ratio : (0.99986332654953)\n",
      "Max generator loss decrease : -0.1370391845703125\n",
      "current lowest generator loss : 8.999537467956543\n",
      "current Learning_rate = 0.009103234357811095\n",
      "save weights\n",
      "train_f1_loss : 7.177285671234131\n",
      "train_f1_score : 0.5514196455478668\n",
      "train_f1_rounded_score : 0.5919913053512573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.135511875152588\n",
      "valid_f1_score : 0.5540305078029633\n",
      "valid_f1_rounded_score : 0.6185649037361145\n",
      "current_generator_loss_median : 8.277942895889282\n",
      "discriminator_learning is False\n",
      "[Epoch 58/575] [Batch 0/6200] [D loss: 0.076783, acc:  96%] [G loss: 8.990028] time: 11:24:51.280362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 58/575] [Batch 3100/6200] [D loss: 0.076784, acc:  96%] [G loss: 8.260118] time: 11:29:30.772096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370768070221\n",
      "Mean generator_loss : 8.975248336791992\n",
      "Max generator_loss : 14.394254684448242\n",
      "Min generator_loss : 6.621933937072754\n",
      "generator loss decrease : 0.02305889129638672\n",
      "generator loss decrease ratio : (0.9974374175071716)\n",
      "Max generator loss decrease : -0.11565017700195312\n",
      "current lowest generator loss : 8.998307228088379\n",
      "current Learning_rate = 0.00908741639969546\n",
      "save weights\n",
      "train_f1_loss : 7.7501349449157715\n",
      "train_f1_score : 0.5156165659427643\n",
      "train_f1_rounded_score : 0.5372419357299805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.770592212677002\n",
      "valid_f1_score : 0.5143379867076874\n",
      "valid_f1_rounded_score : 0.5561563968658447\n",
      "current_generator_loss_median : 8.260416030883789\n",
      "discriminator_learning is False\n",
      "[Epoch 59/575] [Batch 0/6200] [D loss: 0.076780, acc:  96%] [G loss: 9.289341] time: 11:36:42.747596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 59/575] [Batch 3100/6200] [D loss: 0.076787, acc:  96%] [G loss: 8.056041] time: 11:41:20.714596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609369880730106\n",
      "Mean generator_loss : 8.985809326171875\n",
      "Max generator_loss : 14.315508842468262\n",
      "Min generator_loss : 6.507449150085449\n",
      "generator loss decrease : -0.010560989379882812\n",
      "generator loss decrease ratio : (1.0011767148971558)\n",
      "Max generator loss decrease : 0.07874584197998047\n",
      "current lowest generator loss : 8.975248336791992\n",
      "current Learning_rate = 0.009071595381715538\n",
      "train_f1_loss : 7.784519672393799\n",
      "train_f1_score : 0.5134675204753876\n",
      "train_f1_rounded_score : 0.5896323323249817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.7102556228637695\n",
      "valid_f1_score : 0.5181090235710144\n",
      "valid_f1_rounded_score : 0.6142899394035339\n",
      "current_generator_loss_median : 8.278303861618042\n",
      "discriminator_learning is False\n",
      "[Epoch 60/575] [Batch 0/6200] [D loss: 0.076770, acc:  96%] [G loss: 10.870063] time: 11:48:34.288596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/575] [Batch 3100/6200] [D loss: 0.073904, acc:  96%] [G loss: 7.647724] time: 11:53:51.723596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609337898992723\n",
      "Mean generator_loss : 9.083199501037598\n",
      "Max generator_loss : 12.81110954284668\n",
      "Min generator_loss : 6.462553977966309\n",
      "generator loss decrease : -0.10795116424560547\n",
      "generator loss decrease ratio : (1.012027621269226)\n",
      "Max generator loss decrease : 1.504399299621582\n",
      "current lowest generator loss : 8.975248336791992\n",
      "current Learning_rate = 0.009055771297347725\n",
      "train_f1_loss : 8.610533714294434\n",
      "train_f1_score : 0.4618416428565979\n",
      "train_f1_rounded_score : 0.44658464193344116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.739425659179688\n",
      "valid_f1_score : 0.45378589630126953\n",
      "valid_f1_rounded_score : 0.4605664610862732\n",
      "current_generator_loss_median : 8.277576208114624\n",
      "discriminator_learning is False\n",
      "[Epoch 61/575] [Batch 0/6200] [D loss: 0.071181, acc:  96%] [G loss: 10.603709] time: 12:01:52.370596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 61/575] [Batch 3100/6200] [D loss: 0.071240, acc:  96%] [G loss: 7.765227] time: 12:06:30.541596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609368801116943\n",
      "Mean generator_loss : 9.02995491027832\n",
      "Max generator_loss : 13.259984016418457\n",
      "Min generator_loss : 6.405526638031006\n",
      "generator loss decrease : -0.054706573486328125\n",
      "generator loss decrease ratio : (1.006095290184021)\n",
      "Max generator loss decrease : -0.44887447357177734\n",
      "current lowest generator loss : 8.975248336791992\n",
      "current Learning_rate = 0.00903994414004181\n",
      "train_f1_loss : 10.554616928100586\n",
      "train_f1_score : 0.3403364419937134\n",
      "train_f1_rounded_score : 0.30548369884490967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.7708740234375\n",
      "valid_f1_score : 0.38932037353515625\n",
      "valid_f1_rounded_score : 0.3785654604434967\n",
      "current_generator_loss_median : 8.268599510192871\n",
      "discriminator_learning is False\n",
      "[Epoch 62/575] [Batch 0/6200] [D loss: 0.071164, acc:  96%] [G loss: 10.537740] time: 12:13:48.957638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 62/575] [Batch 3100/6200] [D loss: 0.071246, acc:  96%] [G loss: 7.516234] time: 12:18:23.722285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609368604998435\n",
      "Mean generator_loss : 8.988241195678711\n",
      "Max generator_loss : 13.56878662109375\n",
      "Min generator_loss : 6.404437065124512\n",
      "generator loss decrease : -0.01299285888671875\n",
      "generator loss decrease ratio : (1.0014476776123047)\n",
      "Max generator loss decrease : -0.30880260467529297\n",
      "current lowest generator loss : 8.975248336791992\n",
      "current Learning_rate = 0.009024113903220816\n",
      "train_f1_loss : 7.778637409210205\n",
      "train_f1_score : 0.5138351619243622\n",
      "train_f1_rounded_score : 0.5336830615997314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.628411293029785\n",
      "valid_f1_score : 0.5232242941856384\n",
      "valid_f1_rounded_score : 0.5679144263267517\n",
      "current_generator_loss_median : 8.192452669143677\n",
      "discriminator_learning is False\n",
      "[Epoch 63/575] [Batch 0/6200] [D loss: 0.071183, acc:  96%] [G loss: 10.358928] time: 12:25:35.655784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 63/575] [Batch 3100/6200] [D loss: 0.071245, acc:  96%] [G loss: 7.450041] time: 12:30:08.683284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370278735314\n",
      "Mean generator_loss : 8.972697257995605\n",
      "Max generator_loss : 13.581171035766602\n",
      "Min generator_loss : 6.521500587463379\n",
      "generator loss decrease : 0.0025510787963867188\n",
      "generator loss decrease ratio : (0.9997157454490662)\n",
      "Max generator loss decrease : -0.012384414672851562\n",
      "current lowest generator loss : 8.975248336791992\n",
      "current Learning_rate = 0.009008280580280845\n",
      "save weights\n",
      "train_f1_loss : 7.425899505615234\n",
      "train_f1_score : 0.5358812808990479\n",
      "train_f1_rounded_score : 0.5619177222251892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.590317249298096\n",
      "valid_f1_score : 0.525605171918869\n",
      "valid_f1_rounded_score : 0.5641928911209106\n",
      "current_generator_loss_median : 8.16139268875122\n",
      "discriminator_learning is False\n",
      "[Epoch 64/575] [Batch 0/6200] [D loss: 0.071183, acc:  96%] [G loss: 10.597733] time: 12:37:23.763784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 64/575] [Batch 3100/6200] [D loss: 0.071239, acc:  96%] [G loss: 7.590739] time: 12:42:00.978784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609370572913077\n",
      "Mean generator_loss : 8.954572677612305\n",
      "Max generator_loss : 12.875094413757324\n",
      "Min generator_loss : 6.565757751464844\n",
      "generator loss decrease : 0.01812458038330078\n",
      "generator loss decrease ratio : (0.9979800581932068)\n",
      "Max generator loss decrease : 0.7060766220092773\n",
      "current lowest generator loss : 8.972697257995605\n",
      "current Learning_rate = 0.008992444164590906\n",
      "save weights\n",
      "train_f1_loss : 7.719045639038086\n",
      "train_f1_score : 0.5175596475601196\n",
      "train_f1_rounded_score : 0.5228825211524963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 7.6917724609375\n",
      "valid_f1_score : 0.5192642211914062\n",
      "valid_f1_rounded_score : 0.5488387942314148\n",
      "current_generator_loss_median : 8.1928129196167\n",
      "discriminator_learning is False\n",
      "[Epoch 65/575] [Batch 0/6200] [D loss: 0.071180, acc:  96%] [G loss: 10.093026] time: 12:49:17.728285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65/575] [Batch 3100/6200] [D loss: 0.071250, acc:  96%] [G loss: 7.560356] time: 12:53:50.425284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.960937027777395\n",
      "Mean generator_loss : 8.942569732666016\n",
      "Max generator_loss : 13.427606582641602\n",
      "Min generator_loss : 6.350016117095947\n",
      "generator loss decrease : 0.012002944946289062\n",
      "generator loss decrease ratio : (0.9986595511436462)\n",
      "Max generator loss decrease : -0.5525121688842773\n",
      "current lowest generator loss : 8.954572677612305\n",
      "current Learning_rate = 0.008976604649492754\n",
      "save weights\n",
      "train_f1_loss : 8.506868362426758\n",
      "train_f1_score : 0.46832072734832764\n",
      "train_f1_rounded_score : 0.46087655425071716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 8.476560592651367\n",
      "valid_f1_score : 0.47021496295928955\n",
      "valid_f1_rounded_score : 0.49696722626686096\n",
      "current_generator_loss_median : 8.193210363388062\n",
      "discriminator_learning is False\n",
      "[Epoch 66/575] [Batch 0/6200] [D loss: 0.071180, acc:  96%] [G loss: 10.420142] time: 13:01:07.308785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 66/575] [Batch 3100/6200] [D loss: 0.071262, acc:  96%] [G loss: 7.448743] time: 13:05:43.400284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.9609368801116943\n",
      "Mean generator_loss : 8.927451133728027\n",
      "Max generator_loss : 12.605867385864258\n",
      "Min generator_loss : 6.539391994476318\n",
      "generator loss decrease : 0.015118598937988281\n",
      "generator loss decrease ratio : (0.9983093738555908)\n",
      "Max generator loss decrease : 0.8217391967773438\n",
      "current lowest generator loss : 8.942569732666016\n",
      "current Learning_rate = 0.008960762028300732\n",
      "save weights\n",
      "train_f1_loss : 9.680624961853027\n",
      "train_f1_score : 0.3949609398841858\n",
      "train_f1_rounded_score : 0.36503690481185913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 9.787391662597656\n",
      "valid_f1_score : 0.3882880210876465\n",
      "valid_f1_rounded_score : 0.38218826055526733\n",
      "current_generator_loss_median : 8.166941404342651\n",
      "discriminator_learning is False\n",
      "[Epoch 67/575] [Batch 0/6200] [D loss: 0.071172, acc:  96%] [G loss: 9.878385] time: 13:13:05.672289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.                       |\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-73abfbf0db1f>\", line 6, in <module>\n",
      "    gan.train(epochs=575, batch_size=batch_size, sample_interval=3100)\n",
      "  File \"<ipython-input-1-faf2df80b3d8>\", line 331, in train\n",
      "    generator_loss = self.combined.train_on_batch(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1691, in train_on_batch\n",
      "    iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\", line 1534, in single_batch_iterator\n",
      "    return iter(dataset)\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 415, in __iter__\n",
      "    return iterator_ops.OwnedIterator(self)\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 696, in __init__\n",
      "    self._create_iterator(dataset)\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\", line 702, in _create_iterator\n",
      "    dataset = dataset._apply_options()\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 386, in _apply_options\n",
      "    dataset = _OptimizeDataset(dataset, graph_rewrites,\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 4396, in __init__\n",
      "    variant_tensor = gen_dataset_ops.optimize_dataset(\n",
      "  File \"C:\\Users\\gr300\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 3944, in optimize_dataset\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\gr300\\anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-73abfbf0db1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m575\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-faf2df80b3d8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, sample_interval, epoch_shuffle_term)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 generator_loss = self.combined.train_on_batch(\n\u001b[0m\u001b[0;32m    332\u001b[0m                     \u001b[1;33m[\u001b[0m\u001b[0moriginal_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_img\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1690\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1691\u001b[1;33m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[0m\u001b[0;32m   1692\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[1;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1533\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_distribute_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1534\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, components, element_spec, job_token)\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         dataset = _OptimizeDataset(dataset, graph_rewrites,\n\u001b[0m\u001b[0;32m    387\u001b[0m                                    graph_rewrite_configs)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, optimizations, optimization_configs)\u001b[0m\n\u001b[0;32m   4395\u001b[0m         optimizations, dtype=dtypes.string, name=\"optimizations\")\n\u001b[1;32m-> 4396\u001b[1;33m     variant_tensor = gen_dataset_ops.optimize_dataset(\n\u001b[0m\u001b[0;32m   4397\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset\u001b[1;34m(input_dataset, optimizations, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[0;32m   3943\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3944\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   3945\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OptimizeDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2045\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2046\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2047\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1434\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1436\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1191\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#gan.find_error = True\n",
    "#gan.find_error_epoch = 5\n",
    "#gan.load_study_info()\n",
    "#gan.load_study_info()\n",
    "gan.start_epoch = 0\n",
    "gan.train(epochs=575, batch_size=batch_size, sample_interval=3100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_generator_loss_median : 13.20044493675232\n",
      "discriminator_learning is True\n",
      "[Epoch 5/575] [Batch 0/6200] [D loss: 0.123203, acc:  88%] [G loss: 16.688765] time: 0:00:17.875881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5/575] [Batch 3100/6200] [D loss: 0.135997, acc:  22%] [G loss: 12.500026] time: 0:04:14.702376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.6007949733686062\n",
      "Mean generator_loss : 13.601099967956543\n",
      "Max generator_loss : 22.40525245666504\n",
      "Min generator_loss : 9.019099235534668\n",
      "generator loss decrease : -0.06017589569091797\n",
      "generator loss decrease ratio : (1.0044440031051636)\n",
      "Max generator loss decrease : 977.594747543335\n",
      "current lowest generator loss : 13.540924072265625\n",
      "current Learning_rate = 0.00992170499498161\n",
      "train_f1_loss : 12.09400463104248\n",
      "train_f1_score : 0.24412471055984497\n",
      "train_f1_rounded_score : 0.4313807189464569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 12.781795501708984\n",
      "valid_f1_score : 0.20113778114318848\n",
      "valid_f1_rounded_score : 0.36950501799583435\n",
      "current_generator_loss_median : 11.76853895187378\n",
      "discriminator_learning is True\n",
      "[Epoch 6/575] [Batch 0/6200] [D loss: 0.160582, acc:   0%] [G loss: 16.573912] time: 0:11:59.825378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/575] [Batch 3100/6200] [D loss: 0.123661, acc:  62%] [G loss: 12.319873] time: 0:17:47.614875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.2789148632919705\n",
      "Mean generator_loss : 13.379044532775879\n",
      "Max generator_loss : 20.54705047607422\n",
      "Min generator_loss : 8.516634941101074\n",
      "generator loss decrease : 0.1618795394897461\n",
      "generator loss decrease ratio : (0.9880451560020447)\n",
      "Max generator loss decrease : 1.8582019805908203\n",
      "current lowest generator loss : 13.540924072265625\n",
      "current Learning_rate = 0.009906037769907363\n",
      "save weights\n",
      "train_f1_loss : 11.825743675231934\n",
      "train_f1_score : 0.26089102029800415\n",
      "train_f1_rounded_score : 0.4456789493560791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 12.575960159301758\n",
      "valid_f1_score : 0.21400249004364014\n",
      "valid_f1_rounded_score : 0.3832198679447174\n",
      "current_generator_loss_median : 11.448880672454834\n",
      "discriminator_learning is True\n",
      "[Epoch 7/575] [Batch 0/6200] [D loss: 0.158398, acc:   7%] [G loss: 16.330063] time: 0:26:48.693378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7/575] [Batch 3100/6200] [D loss: 0.171553, acc:   0%] [G loss: 12.242298] time: 0:31:34.094089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.3128045760001221\n",
      "Mean generator_loss : 13.294111251831055\n",
      "Max generator_loss : 19.231046676635742\n",
      "Min generator_loss : 8.148473739624023\n",
      "generator loss decrease : 0.08493328094482422\n",
      "generator loss decrease ratio : (0.9936517477035522)\n",
      "Max generator loss decrease : 1.3160037994384766\n",
      "current lowest generator loss : 13.379044532775879\n",
      "current Learning_rate = 0.009890367791123037\n",
      "save weights\n",
      "train_f1_loss : 11.39342212677002\n",
      "train_f1_score : 0.2879111170768738\n",
      "train_f1_rounded_score : 0.4798707962036133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.626075744628906\n",
      "valid_f1_score : 0.27337026596069336\n",
      "valid_f1_rounded_score : 0.48670247197151184\n",
      "current_generator_loss_median : 11.372912883758545\n",
      "discriminator_learning is True\n",
      "[Epoch 8/575] [Batch 0/6200] [D loss: 0.144232, acc:   8%] [G loss: 16.372782] time: 0:38:21.007244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8/575] [Batch 3100/6200] [D loss: 0.128865, acc:  85%] [G loss: 12.090295] time: 0:42:30.238769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.3993806891565775\n",
      "Mean generator_loss : 13.134056091308594\n",
      "Max generator_loss : 20.484691619873047\n",
      "Min generator_loss : 8.167515754699707\n",
      "generator loss decrease : 0.16005516052246094\n",
      "generator loss decrease ratio : (0.9879604578018188)\n",
      "Max generator loss decrease : -1.2536449432373047\n",
      "current lowest generator loss : 13.294111251831055\n",
      "current Learning_rate = 0.009874695053295267\n",
      "save weights\n",
      "train_f1_loss : 11.625322341918945\n",
      "train_f1_score : 0.2734173536300659\n",
      "train_f1_rounded_score : 0.5100441575050354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.819120407104492\n",
      "valid_f1_score : 0.26130497455596924\n",
      "valid_f1_rounded_score : 0.5256160497665405\n",
      "current_generator_loss_median : 11.153309106826782\n",
      "discriminator_learning is True\n",
      "[Epoch 9/575] [Batch 0/6200] [D loss: 0.127576, acc:  53%] [G loss: 16.129654] time: 0:51:22.470266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9/575] [Batch 3100/6200] [D loss: 0.230746, acc:   0%] [G loss: 12.105729] time: 0:58:30.976770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.26074461845219193\n",
      "Mean generator_loss : 13.037442207336426\n",
      "Max generator_loss : 19.292705535888672\n",
      "Min generator_loss : 8.111011505126953\n",
      "generator loss decrease : 0.09661388397216797\n",
      "generator loss decrease ratio : (0.9926440119743347)\n",
      "Max generator loss decrease : 1.191986083984375\n",
      "current lowest generator loss : 13.134056091308594\n",
      "current Learning_rate = 0.00985901955107093\n",
      "save weights\n",
      "train_f1_loss : 11.216727256774902\n",
      "train_f1_score : 0.2989545464515686\n",
      "train_f1_rounded_score : 0.5079637765884399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 11.184900283813477\n",
      "valid_f1_score : 0.3009437322616577\n",
      "valid_f1_rounded_score : 0.531782329082489\n",
      "current_generator_loss_median : 11.081676721572876\n",
      "discriminator_learning is True\n",
      "[Epoch 10/575] [Batch 0/6200] [D loss: 0.127257, acc:  37%] [G loss: 13.833704] time: 1:07:12.297269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10/575] [Batch 3100/6200] [D loss: 0.125285, acc:  97%] [G loss: 12.922071] time: 1:11:17.559266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.8650894852962547\n",
      "Mean generator_loss : 12.609732627868652\n",
      "Max generator_loss : 18.33755111694336\n",
      "Min generator_loss : 9.544391632080078\n",
      "generator loss decrease : 0.42770957946777344\n",
      "generator loss decrease ratio : (0.9671937227249146)\n",
      "Max generator loss decrease : 0.9551544189453125\n",
      "current lowest generator loss : 13.037442207336426\n",
      "current Learning_rate = 0.00984334127907705\n",
      "save weights\n",
      "train_f1_loss : 10.824238777160645\n",
      "train_f1_score : 0.3234850764274597\n",
      "train_f1_rounded_score : 0.48547738790512085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 10.55346965789795\n",
      "valid_f1_score : 0.3404081463813782\n",
      "valid_f1_rounded_score : 0.5519055724143982\n",
      "current_generator_loss_median : 11.584134101867676\n",
      "discriminator_learning is False\n",
      "[Epoch 11/575] [Batch 0/6200] [D loss: 0.122437, acc:  92%] [G loss: 11.558370] time: 1:18:07.183506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49% |###################################                                     |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11/575] [Batch 3100/6200] [D loss: 0.142673, acc:   1%] [G loss: 12.604108] time: 1:22:52.716507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% |####################################################################### |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator_acces : 0.08811011518442727\n",
      "Mean generator_loss : 12.27579116821289\n",
      "Max generator_loss : 17.51087188720703\n",
      "Min generator_loss : 9.178255081176758\n",
      "generator loss decrease : 0.3339414596557617\n",
      "generator loss decrease ratio : (0.9735171794891357)\n",
      "Max generator loss decrease : 0.8266792297363281\n",
      "current lowest generator loss : 12.609732627868652\n",
      "current Learning_rate = 0.009827660231920667\n",
      "save weights\n",
      "train_f1_loss : 10.53527545928955\n",
      "train_f1_score : 0.3415452837944031\n",
      "train_f1_rounded_score : 0.504142701625824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_f1_loss : 10.259178161621094\n",
      "valid_f1_score : 0.35880136489868164\n",
      "valid_f1_rounded_score : 0.5682680606842041\n",
      "current_generator_loss_median : 11.30786657333374\n",
      "discriminator_learning is True\n",
      "[Epoch 12/575] [Batch 0/6200] [D loss: 0.139826, acc:   6%] [G loss: 11.350702] time: 1:30:00.138506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3% |##                                                                      |\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-14b584999879>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_study_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m575\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-7fc2bee20fb5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, sample_interval, epoch_shuffle_term)\u001b[0m\n\u001b[0;32m    299\u001b[0m                 masked_img = self.train_loaded_data[1][batch_i: batch_i +\n\u001b[0;32m    300\u001b[0m                                                        self.batch_size]\n\u001b[1;32m--> 301\u001b[1;33m                 model_masked_img = self.generator.predict_on_batch(\n\u001b[0m\u001b[0;32m    302\u001b[0m                     original_img)\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1787\u001b[0m       \u001b[0mpredict_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1789\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#gan.find_error = True\n",
    "#gan.find_error_epoch = 5\n",
    "#gan.load_study_info()\n",
    "gan.load_study_info()\n",
    "gan.start_epoch = 5\n",
    "gan.train(epochs=575, batch_size=batch_size, sample_interval=3100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
