{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'img_shape': [512, 512], 'input_channels': 3, 'output_channels': 1}\n"
     ]
    }
   ],
   "source": [
    "# TBD 1 : logger 추가\n",
    "# TBD 2: flask github 참고, method, class, 파일의 맨 윗단 마다 pydoc 형식으로 달기\n",
    "# TBD 3: 축약어를 자제할것 (특히 변수)\n",
    "\n",
    "# -------------------------\n",
    "#   To-do\n",
    "# -------------------------\n",
    "# 1. add logger\n",
    "# 2. make image drawer overlay mask on image\n",
    "# 3. make iterable\n",
    "# 4. make verbose turn on and off\n",
    "# 5. write pydoc\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# tensorflow Module\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "# python basic Module\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gan_module.data_loader.medical_segmentation_data_loader import DataLoader\n",
    "\n",
    "from gan_module.model.build_model import build_generator\n",
    "from gan_module import custom_loss\n",
    "from gan_module.custom_loss import dice_loss_for_training, f1_score\n",
    "from gan_module.config import CONFIG\n",
    "\n",
    "\n",
    "custom_loss.AXIS = [1, 2]\n",
    "USE_GPU = True\n",
    "# set GPU memory growth allocation\n",
    "if USE_GPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "\n",
    "class UnetSegmentation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_power=32,\n",
    "        generator_learning_rate=1e-4,\n",
    "        on_memory=True,\n",
    "        code_test=False\n",
    "    ):\n",
    "\n",
    "        img_shape = CONFIG[\"img_shape\"]\n",
    "        input_channels = CONFIG[\"input_channels\"]\n",
    "        output_channels = CONFIG[\"output_channels\"]\n",
    "\n",
    "        input_img_shape = (*img_shape, input_channels)\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = \"tumor\"\n",
    "        self.data_loader = DataLoader(\n",
    "            dataset_name=self.dataset_name,\n",
    "            on_memory=on_memory, \n",
    "            code_test=code_test,\n",
    "            config_dict=CONFIG\n",
    "        )\n",
    "\n",
    "        self.loaded_data_index = {\n",
    "            \"train\": np.arange(self.data_loader.data_length[\"train\"]),\n",
    "            \"valid\": np.arange(self.data_loader.data_length[\"valid\"])\n",
    "        }\n",
    "\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.generator_power = generator_power\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        generator_optimizer = Nadam(self.generator_learning_rate)\n",
    "\n",
    "        # layer Component\n",
    "        self.kernel_initializer = RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = build_generator(\n",
    "            input_img_shape=input_img_shape,\n",
    "            output_channels=output_channels,\n",
    "            generator_power=self.generator_power,\n",
    "            kernel_initializer=self.kernel_initializer,\n",
    "        )\n",
    "        # loss = sm.losses.bce_dice_loss\n",
    "        self.generator.compile(\n",
    "            loss=dice_loss_for_training,\n",
    "            optimizer=generator_optimizer,\n",
    "            metrics=[f1_score],\n",
    "        )\n",
    "        self.generator.trainable = False\n",
    "        \n",
    "    def train(self, epochs, batch_size=10, start_epoch=0):\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        reduce_lr = LearningRateScheduler(self.learning_rate_scheduler)\n",
    "        save_c = ModelCheckpoint(\n",
    "            \"./U_net/weights_{epoch:02d}_{loss:.4f}.hdf5\", \n",
    "            monitor='val_loss', \n",
    "            verbose=0, \n",
    "            save_best_only=False, \n",
    "            save_weights_only=True, \n",
    "            mode='min')\n",
    "\n",
    "        reduceLROnPlat = ReduceLROnPlateau(\n",
    "              monitor=\"val_loss\",\n",
    "              factor=0.1,\n",
    "              patience=20,\n",
    "              verbose=0,\n",
    "              mode=\"auto\",\n",
    "              min_delta=0.0001,\n",
    "              cooldown=5,\n",
    "              min_lr=1e-7)\n",
    "        csv_logger = CSVLogger('./U_net/log.csv', append=False, separator=',')\n",
    "\n",
    "        self.generator.fit(\n",
    "            x=self.data_loader.loaded_data_object[\"train\"][\"input\"],\n",
    "            y=self.data_loader.loaded_data_object[\"train\"][\"output\"],\n",
    "            validation_data=list(self.data_loader.loaded_data_object[\"valid\"].values()),\n",
    "            batch_size=batch_size, epochs=epochs,\n",
    "            callbacks=[reduceLROnPlat, save_c, csv_logger],\n",
    "            initial_epoch=start_epoch\n",
    "        )\n",
    "\n",
    "        elapsed_time = datetime.now() - start_time\n",
    "        print(f\"elapsed_time : {elapsed_time}\")\n",
    "\n",
    "    def learning_rate_scheduler(self, epoch,\n",
    "                                schedule_list=None, exponent=0.2,\n",
    "                                warm_up=True, warm_up_epoch=10):\n",
    "        step = 0\n",
    "        if warm_up and epoch < warm_up_epoch:\n",
    "            new_learning_rate = self.generator_learning_rate * \\\n",
    "                ((epoch + 1) / warm_up_epoch)\n",
    "        else:\n",
    "            if schedule_list is None:\n",
    "                schedule_list = [30, 100, 175, 250, 325]\n",
    "            for step, target_epoch in enumerate(schedule_list):\n",
    "                if target_epoch > epoch:\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            new_learning_rate = self.generator_learning_rate * \\\n",
    "                (exponent**(step))\n",
    "\n",
    "        return new_learning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_lr = 1e-3\n",
    "batch_size = 4\n",
    "g_lr = generator_lr * batch_size\n",
    "gan = UnetSegmentation(generator_power=4, generator_learning_rate=g_lr, code_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/325\n",
      "1550/1550 [==============================] - 400s 258ms/step - loss: 0.7161 - f1_score: 0.4150 - val_loss: 0.0017 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/325\n",
      "1550/1550 [==============================] - 400s 258ms/step - loss: 0.5923 - f1_score: 0.5181 - val_loss: 0.0049 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/325\n",
      "1550/1550 [==============================] - 402s 259ms/step - loss: 0.4959 - f1_score: 0.5739 - val_loss: 0.0047 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/325\n",
      "1550/1550 [==============================] - 402s 259ms/step - loss: 0.4453 - f1_score: 0.5938 - val_loss: 0.0053 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/325\n",
      "1550/1550 [==============================] - 400s 258ms/step - loss: 0.4254 - f1_score: 0.5997 - val_loss: 0.0044 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/325\n",
      "1550/1550 [==============================] - 405s 261ms/step - loss: 0.4104 - f1_score: 0.6078 - val_loss: 0.0053 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/325\n",
      "1550/1550 [==============================] - 410s 265ms/step - loss: 0.4035 - f1_score: 0.6108 - val_loss: 0.0065 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/325\n",
      "1550/1550 [==============================] - 413s 266ms/step - loss: 0.3948 - f1_score: 0.6168 - val_loss: 0.0525 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/325\n",
      "1550/1550 [==============================] - 414s 267ms/step - loss: 0.3945 - f1_score: 0.6165 - val_loss: 0.0045 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/325\n",
      "1550/1550 [==============================] - 413s 267ms/step - loss: 0.3891 - f1_score: 0.6213 - val_loss: 0.0036 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/325\n",
      "1550/1550 [==============================] - 404s 260ms/step - loss: 0.3844 - f1_score: 0.6265 - val_loss: 0.0077 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/325\n",
      "1550/1550 [==============================] - 400s 258ms/step - loss: 0.3866 - f1_score: 0.6275 - val_loss: 0.0064 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/325\n",
      "1550/1550 [==============================] - 399s 258ms/step - loss: 0.3836 - f1_score: 0.6290 - val_loss: 0.0084 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3803 - f1_score: 0.6330 - val_loss: 0.0072 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/325\n",
      "1550/1550 [==============================] - 399s 258ms/step - loss: 0.3808 - f1_score: 0.6326 - val_loss: 0.0091 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/325\n",
      "1550/1550 [==============================] - 399s 258ms/step - loss: 0.3833 - f1_score: 0.6306 - val_loss: 0.0159 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3779 - f1_score: 0.6348 - val_loss: 0.0122 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3730 - f1_score: 0.6388 - val_loss: 0.0096 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3704 - f1_score: 0.6425 - val_loss: 0.0130 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/325\n",
      "1550/1550 [==============================] - 399s 258ms/step - loss: 0.3747 - f1_score: 0.6419 - val_loss: 0.0093 - val_f1_score: 0.0000e+00\n",
      "Epoch 21/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3697 - f1_score: 0.6443 - val_loss: 0.0102 - val_f1_score: 0.0000e+00\n",
      "Epoch 22/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3463 - f1_score: 0.6592 - val_loss: 0.0035 - val_f1_score: 0.0000e+00\n",
      "Epoch 23/325\n",
      "1550/1550 [==============================] - 399s 258ms/step - loss: 0.3379 - f1_score: 0.6668 - val_loss: 0.0030 - val_f1_score: 0.0000e+00\n",
      "Epoch 24/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3335 - f1_score: 0.6711 - val_loss: 0.0031 - val_f1_score: 0.0000e+00\n",
      "Epoch 25/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3334 - f1_score: 0.6716 - val_loss: 0.0035 - val_f1_score: 0.0000e+00\n",
      "Epoch 26/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3311 - f1_score: 0.6732 - val_loss: 0.0031 - val_f1_score: 0.0000e+00\n",
      "Epoch 27/325\n",
      "1550/1550 [==============================] - 400s 258ms/step - loss: 0.3288 - f1_score: 0.6759 - val_loss: 0.0033 - val_f1_score: 0.0000e+00\n",
      "Epoch 28/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3264 - f1_score: 0.6779 - val_loss: 0.0030 - val_f1_score: 0.0000e+00\n",
      "Epoch 29/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3268 - f1_score: 0.6774 - val_loss: 0.0033 - val_f1_score: 0.0000e+00\n",
      "Epoch 30/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3245 - f1_score: 0.6799 - val_loss: 0.0031 - val_f1_score: 0.0000e+00\n",
      "Epoch 31/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3231 - f1_score: 0.6812 - val_loss: 0.0031 - val_f1_score: 0.0000e+00\n",
      "Epoch 32/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3212 - f1_score: 0.6831 - val_loss: 0.0037 - val_f1_score: 0.0000e+00\n",
      "Epoch 33/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3202 - f1_score: 0.6841 - val_loss: 0.0039 - val_f1_score: 0.0000e+00\n",
      "Epoch 34/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3184 - f1_score: 0.6861 - val_loss: 0.0033 - val_f1_score: 0.0000e+00\n",
      "Epoch 35/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3183 - f1_score: 0.6861 - val_loss: 0.0030 - val_f1_score: 0.0000e+00\n",
      "Epoch 36/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3179 - f1_score: 0.6863 - val_loss: 0.0031 - val_f1_score: 0.0000e+00\n",
      "Epoch 37/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3174 - f1_score: 0.6873 - val_loss: 0.0056 - val_f1_score: 0.0000e+00\n",
      "Epoch 38/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3156 - f1_score: 0.6889 - val_loss: 0.0029 - val_f1_score: 0.0000e+00\n",
      "Epoch 39/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3147 - f1_score: 0.6897 - val_loss: 0.0032 - val_f1_score: 0.0000e+00\n",
      "Epoch 40/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3142 - f1_score: 0.6901 - val_loss: 0.0033 - val_f1_score: 0.0000e+00\n",
      "Epoch 41/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3127 - f1_score: 0.6918 - val_loss: 0.0040 - val_f1_score: 0.0000e+00\n",
      "Epoch 42/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3135 - f1_score: 0.6908 - val_loss: 0.0028 - val_f1_score: 0.0000e+00\n",
      "Epoch 43/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3132 - f1_score: 0.6910 - val_loss: 0.0028 - val_f1_score: 0.0000e+00\n",
      "Epoch 44/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3124 - f1_score: 0.6921 - val_loss: 0.0031 - val_f1_score: 0.0000e+00\n",
      "Epoch 45/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3100 - f1_score: 0.6943 - val_loss: 0.0032 - val_f1_score: 0.0000e+00\n",
      "Epoch 46/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3069 - f1_score: 0.6966 - val_loss: 0.0020 - val_f1_score: 0.0000e+00\n",
      "Epoch 47/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3047 - f1_score: 0.6982 - val_loss: 0.0018 - val_f1_score: 0.0000e+00\n",
      "Epoch 48/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3053 - f1_score: 0.6972 - val_loss: 0.0017 - val_f1_score: 0.0000e+00\n",
      "Epoch 49/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3047 - f1_score: 0.6981 - val_loss: 0.0016 - val_f1_score: 0.0000e+00\n",
      "Epoch 50/325\n",
      "1550/1550 [==============================] - 399s 257ms/step - loss: 0.3043 - f1_score: 0.6983 - val_loss: 0.0016 - val_f1_score: 0.0000e+00\n",
      "Epoch 51/325\n",
      " 681/1550 [============>.................] - ETA: 3:43 - loss: 0.3065 - f1_score: 0.6963"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-12d02b525eeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#gan.find_error = True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#gan.find_error_epoch = 5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m325\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-ac1daa117c0d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, start_epoch)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mcsv_logger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./U_net/log.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         self.generator.fit(\n\u001b[0m\u001b[0;32m    127\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloaded_data_object\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloaded_data_object\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"output\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#gan.find_error = True\n",
    "#gan.find_error_epoch = 5\n",
    "gan.train(epochs=325, batch_size=batch_size, start_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(gan.data_loader.loaded_data_object[\"valid\"].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 512, 512, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 512, 512, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from gan_module.model.build_model import build_discriminator\n",
    "\n",
    "temp = build_discriminator(\n",
    "            input_img_shape=(512,512,3),\n",
    "            output_img_shape=(512,512,1),\n",
    "            discriminator_power=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512, 512, 4)  0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 4)  148         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 4)  16          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 512, 512, 4)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 4)  148         leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 4)  16          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 512, 512, 4)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 4)  148         leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 4)  16          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 512, 512, 4)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 512, 4)  0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 512, 4)  16          add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 512, 512, 4)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 512, 512, 8)  296         leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512, 512, 8)  32          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 512, 512, 8)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 8)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 256, 256, 4)  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 8)  584         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 8)  40          average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 256, 256, 8)  32          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 8)  32          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 256, 256, 8)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 256, 256, 8)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256, 256, 8)  0           leaky_re_lu_6[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 256, 256, 8)  32          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 256, 256, 8)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 256, 256, 8)  584         leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 256, 256, 8)  32          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 256, 256, 8)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 256, 256, 8)  584         leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256, 256, 8)  32          conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 256, 256, 8)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 256, 256, 8)  0           leaky_re_lu_9[0][0]              \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256, 256, 8)  32          add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 256, 256, 8)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 256, 256, 8)  584         leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256, 256, 8)  32          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 256, 256, 8)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 8)  0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 128, 128, 8)  0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 8)  584         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 128, 128, 8)  72          average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 8)  32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128, 128, 8)  32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 128, 8)  0           leaky_re_lu_13[0][0]             \n",
      "                                                                 leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 8)  32          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 8)  584         leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 8)  32          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 128, 128, 8)  584         leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 8)  32          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 128, 8)  0           leaky_re_lu_16[0][0]             \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 8)  32          add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 128, 128, 8)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 12) 876         leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 128, 128, 12) 48          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 128, 128, 12) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 12)   0           leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 64, 64, 8)    0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 12)   1308        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 12)   108         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 64, 64, 12)   48          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 12)   48          conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 12)   0           leaky_re_lu_20[0][0]             \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 12)   48          add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 12)   1308        leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 12)   48          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 12)   1308        leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 12)   48          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 12)   0           leaky_re_lu_23[0][0]             \n",
      "                                                                 leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 64, 64, 12)   48          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 12)   1308        leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 64, 64, 12)   48          conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 64, 64, 12)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 12)   0           leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 32, 32, 12)   0           leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 12)   1308        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 12)   156         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 12)   48          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 12)   48          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 32, 32, 12)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 32, 32, 12)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, 32, 12)   0           leaky_re_lu_27[0][0]             \n",
      "                                                                 leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 12)   48          add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 32, 32, 12)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 12)   1308        leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 12)   48          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 32, 32, 12)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 12)   1308        leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 12)   48          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 32, 32, 12)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, 32, 12)   0           leaky_re_lu_30[0][0]             \n",
      "                                                                 leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 12)   48          add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 32, 32, 12)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 16)   1744        leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 32, 32, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 16)   0           leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 16, 16, 12)   0           leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 16)   2320        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 16)   208         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 16)   64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 16)   64          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 16)   0           leaky_re_lu_34[0][0]             \n",
      "                                                                 leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 16)   64          add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 16)   2320        leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 16)   64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 16)   2320        leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 16)   64          conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 16)   0           leaky_re_lu_37[0][0]             \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 16)   64          add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 16)   2320        leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 16)   64          conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 16, 16, 16)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 16)     0           leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 8, 8, 16)     0           leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 8, 8, 16)     2320        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 8, 8, 16)     272         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 16)     64          conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 16)     64          conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 8, 8, 16)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 8, 8, 16)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 16)     0           leaky_re_lu_41[0][0]             \n",
      "                                                                 leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 16)     64          add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 8, 8, 16)     0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 8, 8, 1)      145         leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 1)      4           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 8, 8, 1)      0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 8, 8, 1)      10          leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 8, 8, 1)      17          leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 1)      4           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 1)      4           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 8, 8, 1)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 8, 8, 1)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 1)      0           leaky_re_lu_45[0][0]             \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 1)      4           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 8, 8, 1)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorFlow [(None, 8, 8, 1)]    0           leaky_re_lu_46[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 31,136\n",
      "Trainable params: 30,184\n",
      "Non-trainable params: 952\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
