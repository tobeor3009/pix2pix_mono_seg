{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "{'img_shape': [512, 512], 'input_channels': 3, 'output_channels': 1}\n"
     ]
    }
   ],
   "source": [
    "# TBD 1 : logger 추가\n",
    "# TBD 2: flask github 참고, method, class, 파일의 맨 윗단 마다 pydoc 형식으로 달기\n",
    "# TBD 3: 축약어를 자제할것 (특히 변수)\n",
    "\n",
    "# -------------------------\n",
    "#   To-do\n",
    "# -------------------------\n",
    "\n",
    "# 0. add data-setter, receiver system use python queue.Queue() class\n",
    "# this will resolve i/o bottleneck\n",
    "# 1. add logger\n",
    "# 2. make image drawer overlay mask on image\n",
    "# 3. make iterable\n",
    "# 4. make verbose turn on and off\n",
    "# 5. write pydoc\n",
    "\n",
    "# python basic Module\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import progressbar\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "from pickle import dump, load\n",
    "\n",
    "# math, image, plot Module\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt  # TBD\n",
    "\n",
    "# tensorflow Module\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# keras segmentaion third-party Moudle\n",
    "import segmentation_models as sm\n",
    "\n",
    "# custom Module\n",
    "from gan_module.data_loader.medical_segmentation_data_loader import DataLoader\n",
    "from gan_module.data_loader.manage_batch import BatchQueueManager\n",
    "\n",
    "from gan_module.model.build_model import build_generator\n",
    "from gan_module.model.build_model import build_discriminator as build_discriminator\n",
    "from gan_module import custom_loss\n",
    "from gan_module.custom_loss import f1_loss_for_training, f1_score, dice_loss_for_training\n",
    "from gan_module.util.manage_learning_rate import learning_rate_scheduler\n",
    "from gan_module.util.draw_images import ImageDrawer\n",
    "from gan_module.util.logger import TrainLogger\n",
    "from gan_module.config import CONFIG\n",
    "\n",
    "custom_loss.AXIS = [1, 2, 3]\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "KERNEL_INITIALIZER = RandomNormal(mean=0.0, stddev=0.02)\n",
    "\n",
    "\n",
    "class Pix2PixSegmentation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_power=32,\n",
    "        discriminator_power=32,\n",
    "        generator_learning_rate=1e-4,\n",
    "        discriminator_learning_rate=1e-4,\n",
    "        temp_weights_path=\".\",\n",
    "        draw_images=True,\n",
    "        on_memory=True,\n",
    "        code_test=False\n",
    "    ):\n",
    "        # Input shape\n",
    "        img_shape = CONFIG[\"img_shape\"]\n",
    "        input_channels = CONFIG[\"input_channels\"]\n",
    "        output_channels = CONFIG[\"output_channels\"]\n",
    "\n",
    "        self.input_img_shape = (*img_shape, input_channels)\n",
    "        self.output_img_shape = (*img_shape, output_channels)\n",
    "        # set parameter\n",
    "        self.start_epoch = None\n",
    "        self.on_memory = on_memory\n",
    "        self.history = {\"generator_loss\": [],\n",
    "                        \"f1_loss_train\": [], \"f1_score_train\": [],\n",
    "                        \"f1_loss_valid\": [], \"f1_score_valid\": []}\n",
    "        self.temp_weights_path = temp_weights_path\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = \"tumor\"\n",
    "        self.data_loader = DataLoader(\n",
    "            dataset_name=self.dataset_name,\n",
    "            config_dict=CONFIG,\n",
    "            on_memory=self.on_memory, \n",
    "            code_test=code_test\n",
    "        )\n",
    "        \n",
    "        self.train_logger = TrainLogger()\n",
    "        \n",
    "        self.loaded_data_index = {\n",
    "            \"train\": np.arange(self.data_loader.data_length[\"train\"]),\n",
    "            \"valid\": np.arange(self.data_loader.data_length[\"valid\"])\n",
    "        }\n",
    "        \n",
    "        # Configure Image Drawer\n",
    "        self.draw_images = draw_images\n",
    "        self.image_drawer = ImageDrawer(\n",
    "            dataset_name=self.dataset_name, data_loader=self.data_loader\n",
    "        )\n",
    "        self.discriminator_loss_ratio = keras_backend.variable(2.75)\n",
    "        self.f1_loss_ratio = keras_backend.variable(97.25)\n",
    "        self.discriminator_acc_previous = 0.5\n",
    "        self.discriminator_acces = np.array(\n",
    "            [0.5 for _ in range(self.data_loader.data_length[\"train\"])])\n",
    "        self.discriminator_acces_previous = self.discriminator_acces.copy()\n",
    "        self.generator_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "        self.generator_losses_previous = self.generator_losses.copy()\n",
    "        self.generator_discriminator_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "        self.generator_f1_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "        self.generator_loss_min = 100\n",
    "        self.generator_loss_previous = 100\n",
    "        self.generator_loss_max_previous = 1000\n",
    "        self.weight_save_stack = False\n",
    "        self.training_end_stack = 0\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        patch = 2 ** 3\n",
    "        self.disc_patch = (patch, patch, 1)\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        self.discriminator_learning_rate = discriminator_learning_rate\n",
    "        generator_optimizer = Nadam(self.generator_learning_rate)\n",
    "        discriminator_optimizer = Nadam(self.discriminator_learning_rate)\n",
    "        \n",
    "        # Build the generator\n",
    "        self.generator = build_generator(\n",
    "            input_img_shape=self.input_img_shape,\n",
    "            output_channels=output_channels,\n",
    "            generator_power=generator_power,\n",
    "            kernel_initializer=KERNEL_INITIALIZER,\n",
    "        )\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator(\n",
    "            input_img_shape=self.input_img_shape,\n",
    "            output_img_shape=self.output_img_shape,\n",
    "            discriminator_power=discriminator_power,\n",
    "            kernel_initializer=KERNEL_INITIALIZER,\n",
    "        )\n",
    "        # self.discriminator = self.build_discriminator()\n",
    "        # 'mse' or tf.keras.losses.Huber() tf.keras.losses.LogCosh()\n",
    "        self.discriminator.compile(\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "            optimizer=discriminator_optimizer,\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        # -------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        # -------------------------\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        original_img = Input(shape=self.input_img_shape)\n",
    "        masked_img = Input(shape=self.output_img_shape)\n",
    "        # generate image from original_img for target masked_img\n",
    "        model_masked_img = self.generator(original_img)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        model_validity = self.discriminator([original_img, model_masked_img])\n",
    "        # give score by\n",
    "        # 1. how generator trick discriminator\n",
    "        # 2. how generator's image same as real photo in pixel\n",
    "        # 3. if you want change loss, see doc https://keras.io/api/losses/\n",
    "        # 4. 'mse', 'mae', tf.keras.losses.LogCosh(),  tf.keras.losses.Huber()\n",
    "        self.combined = Model(\n",
    "            inputs=[original_img, masked_img],\n",
    "            outputs=[model_validity, model_masked_img],\n",
    "        )\n",
    "        \n",
    "        self.combined.compile(\n",
    "            loss=[\n",
    "                tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "                dice_loss_for_training\n",
    "            ],\n",
    "            loss_weights=[2.75, 97.25],\n",
    "            optimizer=generator_optimizer,\n",
    "        )\n",
    "\n",
    "    def train(self, epochs, batch_size=1, epoch_shuffle_term=10):\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        self.training_end_stack = 0\n",
    "        self.batch_size = batch_size\n",
    "        valid_patch = np.ones(\n",
    "            (self.batch_size, *self.disc_patch), dtype=np.float32)\n",
    "        fake_patch = np.zeros(\n",
    "            (self.batch_size, *self.disc_patch), dtype=np.float32)\n",
    "        # TBD : move batch_queue_manager to __init__\n",
    "        self.batch_queue_manager = BatchQueueManager(self, batch_size, self.on_memory)\n",
    "\n",
    "        if self.start_epoch is None:\n",
    "            self.start_epoch = 0\n",
    "        for epoch in range(self.start_epoch, epochs):\n",
    "            batch_i = 0\n",
    "\n",
    "            discriminator_losses = []\n",
    "            generator_loss_max_in_epoch = 0\n",
    "            generator_loss_min_in_epoch = 1000\n",
    "            \n",
    "            # shffle data maybe\n",
    "            if epoch % epoch_shuffle_term == 0:\n",
    "                self.data_loader.shuffle_train_imgs()\n",
    "\n",
    "            if self.discriminator_acc_previous < 0.75:\n",
    "                discriminator_learning = True\n",
    "            else:\n",
    "                discriminator_learning = False\n",
    "                \n",
    "            generator_current_learning_rate = learning_rate_scheduler(\n",
    "                self.generator_learning_rate,\n",
    "                epoch,\n",
    "            )\n",
    "            discriminator_current_learning_rate = learning_rate_scheduler(\n",
    "                self.discriminator_learning_rate,\n",
    "                epoch,\n",
    "            ) * (1 - self.discriminator_acc_previous)\n",
    "            keras_backend.set_value(\n",
    "                self.discriminator.optimizer.learning_rate,\n",
    "                discriminator_current_learning_rate,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.discriminator.optimizer.learning_rate,\n",
    "                discriminator_current_learning_rate,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.discriminator_loss_ratio,\n",
    "                keras_backend.variable(0.5) + 4.5 * self.discriminator_acc_previous,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.f1_loss_ratio,\n",
    "                keras_backend.variable(99.5) - 4.5 * self.discriminator_acc_previous\n",
    "            )\n",
    "            bar = progressbar.ProgressBar(\n",
    "                maxval=self.data_loader.data_length[\"train\"]).start()\n",
    "            while batch_i + self.batch_size <= self.data_loader.data_length[\"train\"]:\n",
    "                bar.update(batch_i)\n",
    "\n",
    "                batch_index = self.loaded_data_index[\"train\"][batch_i: batch_i +\n",
    "                                                              self.batch_size]\n",
    "\n",
    "                original_img, masked_img = self.batch_queue_manager.get_batch(\n",
    "                    data_mode=\"train\")\n",
    "                model_masked_img = self.generator.predict_on_batch(\n",
    "                    original_img)\n",
    "\n",
    "                self.original_img = original_img\n",
    "                self.masked_img = masked_img\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # Train Discriminator for valid image if it failed to detect fake image\n",
    "\n",
    "                if discriminator_learning:\n",
    "                    self.discriminator.train_on_batch(\n",
    "                        [original_img, masked_img], valid_patch)\n",
    "\n",
    "                batch_discriminator_acc_previous = np.mean(\n",
    "                    self.discriminator_acces_previous[batch_index])\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                # Train the generators\n",
    "\n",
    "                generator_loss = self.combined.train_on_batch(\n",
    "                    [original_img, masked_img],\n",
    "                    [valid_patch, masked_img]\n",
    "                )\n",
    "                # train discriminator for fake image if it failed to detect fake image\n",
    "                if (batch_discriminator_acc_previous <= 0.5 or epoch == 0) and discriminator_learning:\n",
    "                    discriminator_loss = self.discriminator.train_on_batch(\n",
    "                        [original_img, model_masked_img], fake_patch)\n",
    "                else:\n",
    "                    discriminator_loss = self.discriminator.test_on_batch(\n",
    "                        [original_img, model_masked_img], fake_patch)\n",
    "\n",
    "                self.discriminator_acces[batch_index] = discriminator_loss[1]\n",
    "                self.generator_losses[batch_index] = generator_loss[0]\n",
    "                self.generator_discriminator_losses[batch_index] = generator_loss[1]\n",
    "                self.generator_f1_losses[batch_index] = generator_loss[2]\n",
    "                \n",
    "                # 한 배치 끝\n",
    "                batch_i += self.batch_size\n",
    "            \n",
    "            \n",
    "            # training batch 사이클 끝\n",
    "            \n",
    "            self.train_logger.get_log(\n",
    "                f\"{epoch}/{epochs}\",\n",
    "                np.mean(self.discriminator_acces),\n",
    "                np.mean(self.generator_losses),\n",
    "                np.max(self.generator_losses),\n",
    "                np.min(self.generator_losses),\n",
    "                f\"{self.generator_loss_min - np.mean(self.generator_losses)}({np.mean(self.generator_losses) / self.generator_loss_min})\",\n",
    "                self.generator_loss_min,\n",
    "                generator_current_learning_rate,\n",
    "                datetime.now() - start_time\n",
    "            )\n",
    "            self.image_drawer.sample_images(\n",
    "                self.generator, epoch)\n",
    "            \n",
    "            if np.mean(self.generator_losses) / self.generator_loss_min < 1.1:\n",
    "                if self.generator_loss_min > np.mean(self.generator_losses):\n",
    "                    self.generator_loss_min = np.mean(self.generator_losses)\n",
    "                    self.generator_loss_max_min = generator_loss_max_in_epoch\n",
    "                    self.generator_loss_min_min = generator_loss_min_in_epoch\n",
    "                    self.weight_save_stack = True\n",
    "                    self.save_study_info()\n",
    "                    print(\"save weights\")\n",
    "\n",
    "                valid_f1_loss_list = []\n",
    "                for index in range(0, self.data_loader.data_length[\"valid\"], self.batch_size):\n",
    "\n",
    "                    valid_source_img, valid_masked_img = self.batch_queue_manager.get_batch(\n",
    "                        data_mode=\"valid\")\n",
    "\n",
    "                    valid_model_masked_img = self.generator.predict_on_batch(\n",
    "                        valid_source_img)\n",
    "\n",
    "                    valid_f1_loss = f1_loss_for_training(\n",
    "                        valid_masked_img, valid_model_masked_img)\n",
    "                    valid_f1_loss_list.append(valid_f1_loss)\n",
    "                print(f\"discriminator_loss : {np.mean(self.generator_discriminator_losses)}\")\n",
    "                print(f\"train_f1_loss : {np.mean(self.generator_f1_losses)}\")\n",
    "                print(\n",
    "                    f\"valid_f1_loss : {np.mean(valid_f1_loss_list)}\")\n",
    "            else:\n",
    "                print(\"loss decrease.\")\n",
    "                self.load_best_weights()\n",
    "\n",
    "            # previous generator_loss 갱신\n",
    "            self.generator_loss_previous = np.mean(self.generator_losses)\n",
    "            self.generator_loss_max_previous = np.max(self.generator_losses)\n",
    "\n",
    "            if epoch >= 10 and self.weight_save_stack:\n",
    "                copy(\n",
    "                    \"generator.h5\",\n",
    "                    \"./generator_weights/generator_\"\n",
    "                    + str(round(self.generator_loss_min, 5))\n",
    "                    + \"_\"\n",
    "                    + str(round(self.generator_loss_max_min, 5))\n",
    "                    + \".h5\",\n",
    "                )\n",
    "                self.weight_save_stack = False\n",
    "\n",
    "            self.discriminator_acc_previous = np.mean(self.discriminator_acces)\n",
    "            self.discriminator_acces_previous = self.discriminator_acces.copy()\n",
    "            self.generator_losses_previous = self.generator_losses.copy()\n",
    "            # TBD: add epoch bigger than history length\n",
    "            self.history[\"generator_loss\"].append(\n",
    "                np.mean(self.generator_losses))\n",
    "            self.history[\"f1_loss_train\"].append(\n",
    "                np.mean(self.generator_f1_losses))\n",
    "            self.history[\"f1_loss_valid\"].append(\n",
    "                np.mean(valid_f1_loss_list))\n",
    "\n",
    "    def get_info_folderPath(self):\n",
    "        return (\n",
    "            str(round(self.generator_loss_min, 5))\n",
    "            + \"_\"\n",
    "            + str(round(self.generator_loss_max_min, 5))\n",
    "        )\n",
    "\n",
    "    def save_study_info(self, path=None):\n",
    "\n",
    "        if path is None:\n",
    "            path = self.temp_weights_path\n",
    "\n",
    "        generator_weigth_path = os.path.join(path, \"generator.h5\")\n",
    "        discriminator_weigth_path = os.path.join(path, \"discriminator.h5\")\n",
    "        combined_weigth_path = os.path.join(path, \"combined.h5\")\n",
    "\n",
    "        self.generator.save_weights(generator_weigth_path)\n",
    "        self.discriminator.save_weights(discriminator_weigth_path)\n",
    "        self.combined.save_weights(combined_weigth_path)\n",
    "\n",
    "        study_info = {}\n",
    "        study_info[\"start_epoch\"] = self.start_epoch\n",
    "        study_info[\"train_loaded_data_index\"] = self.loaded_data_index[\"train\"]\n",
    "        study_info[\"generator_loss_min\"] = self.generator_loss_min\n",
    "        study_info[\"generator_loss_max_min\"] = self.generator_loss_max_min\n",
    "        study_info[\"generator_loss_min_min\"] = self.generator_loss_min_min\n",
    "        study_info[\"generator_losses_previous\"] = self.generator_losses_previous\n",
    "        study_info[\"discriminator_acces\"] = self.discriminator_acces\n",
    "        study_info[\"history\"] = self.history\n",
    "        file = open(path + \"/study_info.pkl\", \"wb\")\n",
    "        dump(study_info, file)\n",
    "        file.close()\n",
    "\n",
    "    def load_study_info(self):\n",
    "\n",
    "        self.generator.load_weights(\"generator.h5\")\n",
    "        self.discriminator.load_weights(\"discriminator.h5\")\n",
    "        self.combined.load_weights(\"combined.h5\")\n",
    "\n",
    "        if os.path.isfile(\"study_info.pkl\"):\n",
    "            file = open(\"study_info.pkl\", \"rb\")\n",
    "            study_info = load(file)\n",
    "            file.close()\n",
    "            self.start_epoch = study_info[\"start_epoch\"]\n",
    "            self.loaded_data_index[\"train\"] = study_info[\"train_loaded_data_index\"]\n",
    "            self.generator_loss_min = study_info[\"generator_loss_min\"]\n",
    "            self.generator_loss_max_min = study_info[\"generator_loss_max_min\"]\n",
    "            self.generator_loss_min_min = study_info[\"generator_loss_min_min\"]\n",
    "            self.generator_losses_previous = study_info[\"generator_losses_previous\"]\n",
    "            self.discriminator_acces = study_info[\"discriminator_acces\"]\n",
    "            self.history = study_info[\"history\"]\n",
    "        else:\n",
    "            print(\"No info pkl file!\")\n",
    "\n",
    "    def load_best_weights(self):\n",
    "        self.generator.load_weights(self.temp_weights_path + \"/generator.h5\")\n",
    "        self.discriminator.load_weights(\n",
    "            self.temp_weights_path + \"/discriminator.h5\")\n",
    "        self.combined.load_weights(self.temp_weights_path + \"/combined.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_lr = 1e-3\n",
    "discriminator_lr = 5e-4\n",
    "batch_size = 4\n",
    "g_lr = generator_lr * batch_size\n",
    "d_lr = discriminator_lr * batch_size\n",
    "gan = Pix2PixSegmentation(generator_power=4, discriminator_power=4, \n",
    "                          generator_learning_rate=g_lr, discriminator_learning_rate=d_lr,\n",
    "                          on_memory=True, code_test=False, draw_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68% |#################################################                       |\r"
     ]
    }
   ],
   "source": [
    "#gan.load_study_info()\n",
    "gan.train(epochs=325, batch_size=batch_size, epoch_shuffle_term=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 512, 512, 3), dtype=float64, numpy=\n",
       "array([[[[ 0.44313729,  0.23137259,  0.67843139],\n",
       "         [ 0.4666667 ,  0.25490201,  0.68627453],\n",
       "         [ 0.53725493,  0.32549024,  0.66274512],\n",
       "         ...,\n",
       "         [ 0.98431373,  0.98431373,  0.98431373],\n",
       "         [ 0.98431373,  0.98431373,  0.98431373],\n",
       "         [ 0.98431373,  0.98431373,  0.98431373]],\n",
       "\n",
       "        [[ 0.4666667 ,  0.24705887,  0.71764708],\n",
       "         [ 0.49019611,  0.26274514,  0.7647059 ],\n",
       "         [ 0.5529412 ,  0.30980396,  0.83529413],\n",
       "         ...,\n",
       "         [ 0.98431373,  0.98431373,  0.98431373],\n",
       "         [ 0.98431373,  0.98431373,  0.98431373],\n",
       "         [ 0.98431373,  0.98431373,  0.98431373]],\n",
       "\n",
       "        [[ 0.49019611,  0.27058828,  0.74117649],\n",
       "         [ 0.51372552,  0.28627455,  0.78823531],\n",
       "         [ 0.58431375,  0.34117651,  0.8509804 ],\n",
       "         ...,\n",
       "         [ 0.98431373,  0.98431373,  0.98431373],\n",
       "         [ 0.98431373,  0.98431373,  0.98431373],\n",
       "         [ 0.98431373,  0.98431373,  0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.95294118,  0.95294118,  0.96862745],\n",
       "         [ 0.96078432,  0.96078432,  0.96078432],\n",
       "         [ 0.97647059,  0.97647059,  0.96078432],\n",
       "         ...,\n",
       "         [ 1.        ,  0.92941177,  0.99215686],\n",
       "         [ 1.        ,  0.90588236,  1.        ],\n",
       "         [ 0.99215686,  0.8509804 ,  0.96078432]],\n",
       "\n",
       "        [[ 0.97647059,  0.97647059,  0.98431373],\n",
       "         [ 0.97647059,  0.97647059,  0.96078432],\n",
       "         [ 0.99215686,  0.99215686,  0.97647059],\n",
       "         ...,\n",
       "         [ 0.99215686,  0.94509804,  0.97647059],\n",
       "         [ 1.        ,  0.92156863,  1.        ],\n",
       "         [ 1.        ,  0.85882354,  0.99215686]],\n",
       "\n",
       "        [[ 0.98431373,  0.98431373,  0.97647059],\n",
       "         [ 0.99215686,  0.99215686,  0.97647059],\n",
       "         [ 0.99215686,  0.99215686,  0.97647059],\n",
       "         ...,\n",
       "         [ 0.99215686,  0.95294118,  0.96862745],\n",
       "         [ 1.        ,  0.94509804,  0.98431373],\n",
       "         [ 1.        ,  0.89019608,  1.        ]]],\n",
       "\n",
       "\n",
       "       [[[ 0.89019608,  0.65490198,  0.84313726],\n",
       "         [ 0.83529413,  0.60000002,  0.81176472],\n",
       "         [ 0.7647059 ,  0.52941179,  0.73333335],\n",
       "         ...,\n",
       "         [ 0.20000005,  0.11372554,  0.66274512],\n",
       "         [ 0.15294123,  0.05882359,  0.60000002],\n",
       "         [ 0.19215691,  0.05098045,  0.60784316]],\n",
       "\n",
       "        [[ 0.97647059,  0.75686276,  0.92156863],\n",
       "         [ 0.93725491,  0.71764708,  0.89803922],\n",
       "         [ 0.87450981,  0.67058825,  0.8509804 ],\n",
       "         ...,\n",
       "         [ 0.17647064,  0.09019613,  0.66274512],\n",
       "         [ 0.12941182,  0.02745104,  0.58431375],\n",
       "         [ 0.17647064,  0.04313731,  0.60000002]],\n",
       "\n",
       "        [[ 1.        ,  0.80392158,  0.96078432],\n",
       "         [ 0.99215686,  0.82745099,  0.98431373],\n",
       "         [ 0.97647059,  0.81960785,  0.97647059],\n",
       "         ...,\n",
       "         [ 0.13725495,  0.04313731,  0.62352943],\n",
       "         [ 0.09803927, -0.01176471,  0.56862748],\n",
       "         [ 0.15294123,  0.02745104,  0.53725493]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.88235295,  0.64705884,  0.87450981],\n",
       "         [ 0.85882354,  0.6156863 ,  0.85882354],\n",
       "         [ 0.82745099,  0.58431375,  0.83529413],\n",
       "         ...,\n",
       "         [ 0.10588241,  0.04313731,  0.70980394],\n",
       "         [ 0.082353  ,  0.00392163,  0.77254903],\n",
       "         [ 0.05098045, -0.06666666,  0.74117649]],\n",
       "\n",
       "        [[ 0.89019608,  0.64705884,  0.89019608],\n",
       "         [ 0.86666667,  0.6156863 ,  0.86666667],\n",
       "         [ 0.84313726,  0.57647061,  0.8509804 ],\n",
       "         ...,\n",
       "         [ 0.09019613,  0.03529418,  0.72549021],\n",
       "         [ 0.12941182,  0.07450986,  0.78823531],\n",
       "         [ 0.20000005,  0.12156868,  0.7019608 ]],\n",
       "\n",
       "        [[ 0.87450981,  0.6156863 ,  0.86666667],\n",
       "         [ 0.89019608,  0.62352943,  0.88235295],\n",
       "         [ 0.87450981,  0.60784316,  0.87450981],\n",
       "         ...,\n",
       "         [ 0.11372554,  0.09019613,  0.60784316],\n",
       "         [ 0.19215691,  0.16078436,  0.63921571],\n",
       "         [ 0.27843142,  0.21568632,  0.73333335]]],\n",
       "\n",
       "\n",
       "       [[[ 0.86666667,  0.87450981,  0.96078432],\n",
       "         [ 0.8509804 ,  0.85882354,  0.96078432],\n",
       "         [ 0.8509804 ,  0.8509804 ,  0.96078432],\n",
       "         ...,\n",
       "         [ 0.99215686,  1.        ,  0.95294118],\n",
       "         [ 1.        ,  1.        ,  0.94509804],\n",
       "         [ 0.97647059,  1.        ,  0.93725491]],\n",
       "\n",
       "        [[ 0.87450981,  0.86666667,  0.93725491],\n",
       "         [ 0.85882354,  0.8509804 ,  0.92156863],\n",
       "         [ 0.8509804 ,  0.8509804 ,  0.92156863],\n",
       "         ...,\n",
       "         [ 0.99215686,  0.98431373,  0.93725491],\n",
       "         [ 1.        ,  1.        ,  0.94509804],\n",
       "         [ 0.99215686,  1.        ,  0.94509804]],\n",
       "\n",
       "        [[ 0.87450981,  0.86666667,  0.92941177],\n",
       "         [ 0.86666667,  0.85882354,  0.92156863],\n",
       "         [ 0.86666667,  0.8509804 ,  0.92941177],\n",
       "         ...,\n",
       "         [ 0.99215686,  0.96862745,  0.94509804],\n",
       "         [ 1.        ,  1.        ,  0.96078432],\n",
       "         [ 0.99215686,  0.99215686,  0.95294118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 1.        ,  0.98431373,  1.        ],\n",
       "         [ 1.        ,  0.96862745,  1.        ],\n",
       "         [ 0.98431373,  0.94509804,  0.99215686]],\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 1.        ,  0.96862745,  1.        ],\n",
       "         [ 0.99215686,  0.95294118,  1.        ],\n",
       "         [ 0.96862745,  0.92941177,  0.98431373]],\n",
       "\n",
       "        [[ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         [ 1.        ,  1.        ,  1.        ],\n",
       "         ...,\n",
       "         [ 0.99215686,  0.94509804,  1.        ],\n",
       "         [ 0.96862745,  0.92941177,  0.99215686],\n",
       "         [ 0.94509804,  0.90588236,  0.96862745]]],\n",
       "\n",
       "\n",
       "       [[[ 0.16078436,  0.07450986,  0.54509807],\n",
       "         [ 0.13725495,  0.05098045,  0.48235297],\n",
       "         [ 0.17647064,  0.06666672,  0.49019611],\n",
       "         ...,\n",
       "         [ 0.47450984,  0.26274514,  0.68627453],\n",
       "         [ 0.44313729,  0.23921573,  0.62352943],\n",
       "         [ 0.42745101,  0.21568632,  0.59215689]],\n",
       "\n",
       "        [[ 0.09019613, -0.00392157,  0.52941179],\n",
       "         [ 0.09803927,  0.00392163,  0.50588238],\n",
       "         [ 0.17647064,  0.06666672,  0.52156866],\n",
       "         ...,\n",
       "         [ 0.49803925,  0.30980396,  0.72549021],\n",
       "         [ 0.48235297,  0.27843142,  0.67843139],\n",
       "         [ 0.4666667 ,  0.25490201,  0.63921571]],\n",
       "\n",
       "        [[ 0.04313731, -0.05098039,  0.52941179],\n",
       "         [ 0.09019613, -0.01176471,  0.54509807],\n",
       "         [ 0.18431377,  0.05882359,  0.58431375],\n",
       "         ...,\n",
       "         [ 0.52156866,  0.38039219,  0.77254903],\n",
       "         [ 0.50588238,  0.38039219,  0.71764708],\n",
       "         [ 0.47450984,  0.34901965,  0.69411767]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.09019613,  0.06666672,  0.7019608 ],\n",
       "         [ 0.00392163, -0.01960784,  0.60784316],\n",
       "         [-0.02745098, -0.05882353,  0.56078434],\n",
       "         ...,\n",
       "         [ 0.45882356,  0.34901965,  0.7647059 ],\n",
       "         [ 0.49019611,  0.38823533,  0.81176472],\n",
       "         [ 0.56078434,  0.45882356,  0.89803922]],\n",
       "\n",
       "        [[ 0.28627455,  0.28627455,  0.82745099],\n",
       "         [ 0.21568632,  0.22352946,  0.75686276],\n",
       "         [ 0.13725495,  0.13725495,  0.67058825],\n",
       "         ...,\n",
       "         [ 0.48235297,  0.35686278,  0.7647059 ],\n",
       "         [ 0.50588238,  0.38823533,  0.77254903],\n",
       "         [ 0.57647061,  0.45098042,  0.82745099]],\n",
       "\n",
       "        [[ 0.47450984,  0.47450984,  0.93725491],\n",
       "         [ 0.42745101,  0.42745101,  0.89803922],\n",
       "         [ 0.30980396,  0.32549024,  0.79607844],\n",
       "         ...,\n",
       "         [ 0.49019611,  0.35686278,  0.74901962],\n",
       "         [ 0.50588238,  0.38039219,  0.74901962],\n",
       "         [ 0.56862748,  0.44313729,  0.79607844]]]])>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1259\n"
     ]
    }
   ],
   "source": [
    "gan.original_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 512, 512, 1), dtype=float64, numpy=\n",
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]],\n",
       "\n",
       "\n",
       "       [[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]],\n",
       "\n",
       "        [[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         ...,\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]])>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gan.data_loader.loaded_data_object[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.43592834472656, 0.6931471824645996, 0.3333333134651184]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_img = np.ones((1,512,512,3))\n",
    "masked_img = np.ones((1,512,512,1))\n",
    "valid_patch = np.ones((1,8,8,1))\n",
    "\n",
    "gan.combined.test_on_batch(\n",
    "    [original_img, masked_img],\n",
    "    [valid_patch, masked_img],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=97.25>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.f1_loss_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.75>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.discriminator_loss_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.43592834472656, 0.6931471824645996, 0.3333333134651184]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[34.43592834472656, 0.6931471824645996, 0.3333333134651184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.322819486260414"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6931471824645996 * 2.75 + 0.3333333134651184 * 97.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-f92eaba7459e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-f92eaba7459e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    gan.discriminator.optimizer.\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x00000288678493A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_train_function.<locals>.train_function at 0x00000288678493A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 4.586500883102417\n",
      "elapsed time : 0.29304075241088867\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "temp_source = gan.original_img\n",
    "temp_mask = gan.masked_img\n",
    "\n",
    "start_time = time.time()\n",
    "gan.generator.train_on_batch(temp_source, temp_mask)\n",
    "print(f\"elapsed time : {time.time() - start_time}\")\n",
    "\n",
    "temp_source = tf.convert_to_tensor(temp_source)\n",
    "temp_mask = tf.convert_to_tensor(temp_mask)\n",
    "\n",
    "start_time = time.time()\n",
    "gan.generator.train_on_batch(temp_source, temp_mask)\n",
    "print(f\"elapsed time : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cba4fde71471>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     batch_index = gan.train_loaded_data_index[batch_i: batch_i +\n\u001b[0;32m      6\u001b[0m                                                gan.batch_size]\n\u001b[1;32m----> 7\u001b[1;33m     original_img, masked_img = gan.data_loader.get_data(\n\u001b[0m\u001b[0;32m      8\u001b[0m         data_mode=\"train\", index=batch_index)\n",
      "\u001b[1;32m~\\Desktop\\Works\\jupyterlab\\의료데이터(pix2pix)_size_20_v0.2\\data_loader\\medical_segmentation_data_loader_v2.py\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(self, data_mode, index)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                     data_tuple = (\n\u001b[1;32m---> 88\u001b[1;33m                         self.train_loaded_data[0][index], self.train_loaded_data[1][index])\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_i = 0\n",
    "\n",
    "while batch_i + gan.batch_size <= gan.data_loader.train_data_length:\n",
    "\n",
    "    batch_index = gan.train_loaded_data_index[batch_i: batch_i +\n",
    "                                               gan.batch_size]\n",
    "    original_img, masked_img = gan.data_loader.get_data(\n",
    "        data_mode=\"train\", index=batch_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.data_loader.train_data_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterator : 260초\n",
    "# Queue Iterator : 200초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 204.91554951667786\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "ITER_NUM = 620\n",
    "batch_size = 10\n",
    "\n",
    "gan.generator.compile(\n",
    "    loss=sm.losses.BinaryFocalLoss(),\n",
    "    optimizer=Nadam(gan.generator_learning_rate),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "def batch_setter(queue):\n",
    "    batch_i = 0\n",
    "    count = 0\n",
    "    while batch_i + gan.batch_size <= gan.data_loader.train_data_length and count < ITER_NUM:\n",
    "        \n",
    "        batch_index = gan.train_loaded_data_index[batch_i: batch_i +\n",
    "                                                   gan.batch_size]        \n",
    "        \n",
    "        batch_tuple = gan.data_loader.get_data(\n",
    "        data_mode=\"train\", index=batch_index)\n",
    "\n",
    "        queue.put(batch_tuple)\n",
    "        queue.join()\n",
    "        count += 1\n",
    "    \n",
    "def batch_getter(queue):\n",
    "    \n",
    "    original_img, masked_img = queue.get()\n",
    "    tensor_original_img = tf.convert_to_tensor(original_img)\n",
    "    tensor_masked_img = tf.convert_to_tensor(masked_img)\n",
    "    queue.task_done()\n",
    "    \n",
    "    return tensor_original_img, tensor_masked_img\n",
    "    \n",
    "def batch_trainer(original_img, masked_img):\n",
    "    \n",
    "    gan.generator.train_on_batch(temp_source, temp_mask)\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "setter = threading.Thread(target=batch_setter, args=(q,),daemon=True)\n",
    "setter.start()\n",
    "start_time = time.time()\n",
    "for i in range(ITER_NUM):\n",
    "    tensor_original_img, tensor_masked_img = batch_getter(q)\n",
    "    \n",
    "    gan.generator.train_on_batch(tensor_original_img, tensor_masked_img)\n",
    "print(f\"elapsed time : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time : 260.5594081878662\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "batch_i = 0\n",
    "count = 0\n",
    "while batch_i + gan.batch_size <= gan.data_loader.train_data_length and count < ITER_NUM:\n",
    "\n",
    "    batch_index = gan.train_loaded_data_index[batch_i: batch_i +\n",
    "                                               gan.batch_size]        \n",
    "    batch_tuple = gan.data_loader.get_data(\n",
    "    data_mode=\"train\", index=batch_index)\n",
    "    \n",
    "    gan.generator.train_on_batch(*batch_tuple)\n",
    "    \n",
    "    count += 1\n",
    "print(f\"elapsed time : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "temp = tensor_masked_img\n",
    "print(type(temp))\n",
    "print(type(temp.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(temp.numpy(), tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_module.model.build_model import build_dual_discriminator\n",
    "\n",
    "temp = build_dual_discriminator(\n",
    "            input_img_shape=(512,512,3),\n",
    "            output_img_shape=(512,512,1),\n",
    "            discriminator_power=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "temp.compile(\n",
    "    loss=[\n",
    "        tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "        tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
    "    ],\n",
    "    optimizer=Nadam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d_34/Conv2D (defined at <ipython-input-3-d8b1761e412e>:7) ]] [Op:__inference_test_function_13463]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d8b1761e412e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpatch_mockup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_mockup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_mockup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpatch_mockup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_mockup\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[1;34m(self, x, y, sample_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1752\u001b[0m                                                     y, sample_weight)\n\u001b[0;32m   1753\u001b[0m       \u001b[0mtest_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1754\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 840\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node functional_1/conv2d_34/Conv2D (defined at <ipython-input-3-d8b1761e412e>:7) ]] [Op:__inference_test_function_13463]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_mockup = np.ones((1,512,512,3))\n",
    "mask_mockup = np.ones((1,512,512,1))\n",
    "patch_mockup = np.ones((1,8,8,1))\n",
    "\n",
    "temp.test_on_batch([image_mockup, mask_mockup], [patch_mockup, patch_mockup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
