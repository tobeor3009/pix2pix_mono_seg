{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You need to first `import keras` in order to use `keras_preprocessing`. For instance, you can do:\n\n```\nimport keras\nfrom keras_preprocessing import image\n```\n\nOr, preferably, this equivalent formulation:\n\n```\nfrom keras import preprocessing\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2ad748bb9f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# tensorflow Module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNoise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mreuters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\keras\\datasets\\imdb\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_word_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimdb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_remove_long_seq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;34m\"\"\"Set of tools for real-time data augmentation on image data.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_preprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_keras_submodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_keras_submodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'backend'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mkeras_utils\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_keras_submodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_preprocessing\\__init__.py\u001b[0m in \u001b[0;36mget_keras_submodule\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     22\u001b[0m             'Requested: %s' % name)\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_KERAS_BACKEND\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         raise ImportError('You need to first `import keras` '\n\u001b[0m\u001b[0;32m     25\u001b[0m                           \u001b[1;34m'in order to use `keras_preprocessing`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                           \u001b[1;34m'For instance, you can do:\\n\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: You need to first `import keras` in order to use `keras_preprocessing`. For instance, you can do:\n\n```\nimport keras\nfrom keras_preprocessing import image\n```\n\nOr, preferably, this equivalent formulation:\n\n```\nfrom keras import preprocessing\n```\n"
     ]
    }
   ],
   "source": [
    "# TBD 1 : logger 추가\n",
    "# TBD 2: flask github 참고, method, class, 파일의 맨 윗단 마다 pydoc 형식으로 달기\n",
    "# TBD 3: 축약어를 자제할것 (특히 변수)\n",
    "\n",
    "# -------------------------\n",
    "#   done\n",
    "# -------------------------\n",
    "\n",
    "# 0. add data-setter, receiver system use python queue.Queue() class\n",
    "# this will resolve i/o bottleneck\n",
    "# 3. make iterable\n",
    "\n",
    "# -------------------------\n",
    "#   In Progress\n",
    "# -------------------------\n",
    "\n",
    "# 1. add logger\n",
    "# 2. make image drawer overlay mask on image\n",
    "\n",
    "# -------------------------\n",
    "#   To be Done\n",
    "# -------------------------\n",
    "\n",
    "# 4. make verbose turn on and off\n",
    "# 5. write pydoc\n",
    "\n",
    "# python basic Module\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "import progressbar\n",
    "from datetime import datetime\n",
    "from shutil import copy\n",
    "from pickle import dump, load\n",
    "\n",
    "# math, image, plot Module\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt  # TBD\n",
    "\n",
    "# tensorflow Module\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as keras_backend\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras import losses\n",
    "\n",
    "# keras segmentaion third-party Moudle\n",
    "import segmentation_models as sm\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# custom Module\n",
    "from gan_module.data_loader.medical_segmentation_data_loader import DataLoader\n",
    "from gan_module.data_loader.manage_batch import BatchQueueManager\n",
    "\n",
    "from gan_module.model.build_model import build_generator as build_generator\n",
    "from gan_module.model.build_model import build_discriminator as build_discriminator\n",
    "from gan_module.util.custom_loss import weighted_region_loss, dice_score, combined_loss, f1_loss\n",
    "# from gan_module.util.custom_gradient import SGD_AGC\n",
    "from gan_module.util.manage_learning_rate import learning_rate_scheduler\n",
    "from gan_module.util.draw_images import ImageDrawer\n",
    "from gan_module.util.logger import TrainLogger\n",
    "from gan_module.config import CONFIG\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "    for device in gpu_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "else:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "\n",
    "class Pix2PixSegmentation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator_power=32,\n",
    "        discriminator_power=32,\n",
    "        generator_depth = None,\n",
    "        discriminator_depth = None,\n",
    "        generator_learning_rate=1e-4,\n",
    "        discriminator_learning_rate=1e-4,\n",
    "        temp_weights_path=\".\",\n",
    "        on_memory=True,\n",
    "        code_test=False\n",
    "    ):\n",
    "        # Input shape\n",
    "        img_shape = CONFIG[\"img_shape\"]\n",
    "        input_channels = CONFIG[\"input_channels\"]\n",
    "        output_channels = CONFIG[\"output_channels\"]\n",
    "\n",
    "        self.input_img_shape = (*img_shape, input_channels)\n",
    "        self.output_img_shape = (*img_shape, output_channels)\n",
    "        # set parameter\n",
    "        self.start_epoch = None\n",
    "        self.on_memory = on_memory\n",
    "        self.history = {\"generator_loss\": [],\n",
    "                        \"f1_loss_train\": [], \"f1_score_train\": [],\n",
    "                        \"f1_loss_valid\": [], \"f1_score_valid\": []}\n",
    "        self.temp_weights_path = temp_weights_path\n",
    "\n",
    "        # Configure data loader\n",
    "        self.dataset_name = \"glomerulus_0.65_512_remove_peel_split_man\"\n",
    "        self.data_loader = DataLoader(\n",
    "            dataset_name=self.dataset_name,\n",
    "            config_dict=CONFIG,\n",
    "            on_memory=self.on_memory, \n",
    "            code_test=code_test\n",
    "        )\n",
    "        \n",
    "        self.train_logger = TrainLogger()\n",
    "        \n",
    "        self.loaded_data_index = {\n",
    "            \"train\": np.arange(self.data_loader.data_length[\"train\"]),\n",
    "            \"valid\": np.arange(self.data_loader.data_length[\"valid\"])\n",
    "        }\n",
    "        \n",
    "        # Configure Image Drawer\n",
    "        self.image_drawer = ImageDrawer(\n",
    "            dataset_name=self.dataset_name, data_loader=self.data_loader\n",
    "        )\n",
    "        self.discriminator_loss_ratio = keras_backend.variable(0.1)\n",
    "        self.f1_loss_ratio = keras_backend.variable(100)\n",
    "        self.discriminator_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "        self.discriminator_acc_previous = 0.5\n",
    "        self.discriminator_acces = np.array(\n",
    "            [0.5 for _ in range(self.data_loader.data_length[\"train\"])])\n",
    "        self.discriminator_acces_previous = self.discriminator_acces.copy()\n",
    "        self.generator_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "        self.generator_losses_previous = self.generator_losses.copy()\n",
    "        self.generator_f1_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "        self.generator_loss_min = 10000\n",
    "        self.generator_loss_previous = 10000\n",
    "        self.generator_loss_max_previous = 10000\n",
    "        self.generator_valid_loss_min = 10000\n",
    "        self.total_f1_loss_min = 10000\n",
    "        self.weight_save_stack = False\n",
    "        self.training_end_stack = 0\n",
    "        # Calculate output shape of D (PatchGAN)\n",
    "        self.disc_patch = (img_shape[0] // (2 ** discriminator_depth), img_shape[1] // (2 ** discriminator_depth), 1)\n",
    "        # Number of filters in the first layer of G and D\n",
    "        self.generator_learning_rate = generator_learning_rate\n",
    "        self.discriminator_learning_rate = discriminator_learning_rate\n",
    "        self.patience_count = 0\n",
    "        \n",
    "        generator_optimizer = Nadam(self.generator_learning_rate)\n",
    "        discriminator_optimizer = Nadam(self.discriminator_learning_rate)\n",
    "#         generator_optimizer = SGD_AGC(lr=self.generator_learning_rate, momentum=0.9)\n",
    "#         discriminator_optimizer = SGD_AGC(lr=self.discriminator_learning_rate, momentum=0.9)        \n",
    "        # Build the generator\n",
    "        self.generator = build_generator(\n",
    "            input_img_shape=self.input_img_shape,\n",
    "            output_channels=output_channels,\n",
    "            generator_power=generator_power,\n",
    "            depth=generator_depth,\n",
    "        )\n",
    "        self.generator.compile(\n",
    "            loss=weighted_region_loss,\n",
    "            optimizer=generator_optimizer,\n",
    "            metrics=[dice_score],\n",
    "        )\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = build_discriminator(\n",
    "            input_img_shape=self.input_img_shape,\n",
    "            output_img_shape=self.output_img_shape,\n",
    "            discriminator_power=discriminator_power,\n",
    "            depth=discriminator_depth,\n",
    "        )\n",
    "        # 'mse' or tf.keras.losses.Huber() tf.keras.losses.LogCosh()\n",
    "        self.discriminator.compile(\n",
    "            loss=sm.losses.BinaryFocalLoss(alpha=0.25, gamma=4),\n",
    "            optimizer=discriminator_optimizer,\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # -------------------------\n",
    "        # Construct Computational\n",
    "        #   Graph of Generator\n",
    "        # -------------------------\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        original_img = Input(shape=self.input_img_shape)\n",
    "        # generate image from original_img for target masked_img\n",
    "        model_masked_img = self.generator(original_img)\n",
    "        \n",
    "    \n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        model_validity = self.discriminator([original_img, model_masked_img])\n",
    "        # give score by\n",
    "        # 1. how generator trick discriminator\n",
    "        # 2. how generator's image same as real photo in pixel\n",
    "        # 3. if you want change loss, see doc https://keras.io/api/losses/\n",
    "        # 4. 'mse', 'mae', tf.keras.losses.LogCosh(),  tf.keras.losses.Huber()\n",
    "        self.combined = Model(\n",
    "            inputs=original_img,\n",
    "            outputs=[model_validity, model_masked_img],\n",
    "        )\n",
    "        \n",
    "        self.combined.compile(\n",
    "            loss=[\n",
    "#                 tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05),\n",
    "                sm.losses.BinaryFocalLoss(alpha=0.25, gamma=4),\n",
    "                weighted_region_loss\n",
    "            ],\n",
    "            loss_weights=[0.1, 100],\n",
    "            optimizer=generator_optimizer,\n",
    "        )\n",
    "\n",
    "    def train(self, epochs, batch_size=1, epoch_shuffle_term=10):\n",
    "\n",
    "        start_time = datetime.now()\n",
    "\n",
    "        # Adversarial loss ground truths\n",
    "        self.training_end_stack = 0\n",
    "        self.batch_size = batch_size\n",
    "        valid_patch = np.ones(\n",
    "            (self.batch_size, *self.disc_patch), dtype=np.float32)\n",
    "        fake_patch = np.zeros(\n",
    "            (self.batch_size, *self.disc_patch), dtype=np.float32)\n",
    "        # TBD : move batch_queue_manager to __init__\n",
    "        self.batch_queue_manager = BatchQueueManager(self, batch_size, self.on_memory)\n",
    "        \n",
    "        if self.start_epoch is None:\n",
    "            self.start_epoch = 0\n",
    "        for epoch in range(self.start_epoch, epochs):\n",
    "            batch_i = 0\n",
    "\n",
    "            generator_loss_max_in_epoch = 0\n",
    "            generator_loss_min_in_epoch = 1000\n",
    "            generator_discriminator_losses = np.array(\n",
    "            [1 for _ in range(self.data_loader.data_length[\"train\"])], dtype=np.float32)\n",
    "            # shffle data maybe\n",
    "            if epoch % epoch_shuffle_term == 0:\n",
    "                self.data_loader.shuffle_train_imgs()\n",
    "            \n",
    "            if self.discriminator_acc_previous < 0.95:\n",
    "                discriminator_learning = True\n",
    "            else:\n",
    "                discriminator_learning = False\n",
    "            generator_1_10_quantile = np.quantile(self.generator_losses, 0.1)\n",
    "            \n",
    "            \n",
    "            generator_current_learning_rate = learning_rate_scheduler(\n",
    "                self.generator_learning_rate,\n",
    "                epoch+self.patience_count,\n",
    "                warm_up=True\n",
    "            )\n",
    "            discriminator_current_learning_rate = learning_rate_scheduler(\n",
    "                self.discriminator_learning_rate,\n",
    "                epoch+self.patience_count,\n",
    "                warm_up=True\n",
    "            ) * (1 - self.discriminator_acc_previous)\n",
    "            keras_backend.set_value(\n",
    "                self.discriminator.optimizer.learning_rate,\n",
    "                discriminator_current_learning_rate,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.discriminator.optimizer.learning_rate,\n",
    "                discriminator_current_learning_rate,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.discriminator_loss_ratio,\n",
    "                keras_backend.variable(0.01) + 0.25 * self.discriminator_acc_previous,\n",
    "            )\n",
    "            keras_backend.set_value(\n",
    "                self.f1_loss_ratio,\n",
    "                keras_backend.variable(100) - 0.25  * self.discriminator_acc_previous,\n",
    "            )\n",
    "            \n",
    "            bar = progressbar.ProgressBar(\n",
    "                maxval=self.data_loader.data_length[\"train\"]).start()\n",
    "            \n",
    "            while batch_i + self.batch_size < self.data_loader.data_length[\"train\"] + self.batch_size:\n",
    "\n",
    "                batch_index = self.loaded_data_index[\"train\"][batch_i: batch_i +\n",
    "                                                              self.batch_size]\n",
    "\n",
    "                original_img, masked_img = self.batch_queue_manager.get_batch(\n",
    "                    data_mode=\"train\")\n",
    "                model_masked_img = self.generator.predict_on_batch(\n",
    "                    original_img)\n",
    "                \n",
    "                valid_patch = np.ones(\n",
    "                    (len(model_masked_img), *self.disc_patch), dtype=np.float32)\n",
    "                fake_patch = np.zeros(\n",
    "                    (len(model_masked_img), *self.disc_patch), dtype=np.float32)\n",
    "                \n",
    "                self.original_img = original_img\n",
    "                self.masked_img = masked_img\n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "                # Train Discriminator for valid image if it failed to detect fake image\n",
    "                if discriminator_learning and self.discriminator_acc_previous < np.random.rand():\n",
    "                    discriminator_loss = self.discriminator.train_on_batch([original_img, masked_img], valid_patch)\n",
    "                else:\n",
    "                    discriminator_loss = self.discriminator.test_on_batch([original_img, masked_img], valid_patch)\n",
    "                    \n",
    "                batch_discriminator_acc_previous = np.mean(\n",
    "                    self.discriminator_acces_previous[batch_index])\n",
    "                self.discriminator.trainable = False\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "                \n",
    "#                 if np.mean(self.generator_losses[batch_index]) >= generator_1_10_quantile:\n",
    "#                     generator_loss = self.combined.train_on_batch(\n",
    "#                         original_img,\n",
    "#                         [valid_patch, masked_img]\n",
    "#                     )\n",
    "#                 else:\n",
    "#                     generator_loss = self.combined.test_on_batch(\n",
    "#                         original_img,\n",
    "#                         [valid_patch, masked_img]\n",
    "#                     )\n",
    "                generator_loss = self.combined.train_on_batch(\n",
    "                    original_img,\n",
    "                    [valid_patch, masked_img]     \n",
    "                )\n",
    "                # train discriminator for fake image if it failed to detect fake image\n",
    "                self.discriminator.trainable = True\n",
    "                if (batch_discriminator_acc_previous <= 0.5 or epoch == 0) and discriminator_learning:\n",
    "                    discriminator_loss += self.discriminator.train_on_batch(\n",
    "                        [original_img,model_masked_img], fake_patch)\n",
    "                else:\n",
    "                    discriminator_loss += self.discriminator.test_on_batch(\n",
    "                        [original_img,model_masked_img], fake_patch)\n",
    "\n",
    "                self.discriminator_losses[batch_index] = discriminator_loss[0]\n",
    "                self.discriminator_acces[batch_index] = discriminator_loss[1]\n",
    "                self.generator_losses[batch_index] = generator_loss[0]\n",
    "                self.generator_f1_losses[batch_index] = generator_loss[2]\n",
    "                generator_discriminator_losses = generator_loss[1]\n",
    "                # plot progress\n",
    "                bar.update(batch_i)\n",
    "                \n",
    "                # 한 배치 끝\n",
    "                batch_i += self.batch_size\n",
    "            \n",
    "            # training batch 사이클 끝\n",
    "            \n",
    "            #######################################\n",
    "            # valid_loss, valid score 계산\n",
    "            #######################################\n",
    "            \n",
    "            #if self.generator_loss_min > np.mean(self.generator_losses):\n",
    "            valid_f1_loss_list = []\n",
    "            valid_f1_score_list = []\n",
    "            for index in range(0, self.data_loader.data_length[\"valid\"], self.batch_size):\n",
    "\n",
    "                valid_source_img, valid_masked_img = self.batch_queue_manager.get_batch(\n",
    "                    data_mode=\"valid\")\n",
    "\n",
    "                valid_model_masked_img = self.generator.predict_on_batch(\n",
    "                    valid_source_img)\n",
    "                valid_f1_loss =  weighted_region_loss(valid_masked_img, valid_model_masked_img)\n",
    "                valid_f1_score = dice_score(valid_masked_img, valid_model_masked_img)\n",
    "                \n",
    "                valid_f1_loss_list.append(valid_f1_loss)\n",
    "                valid_f1_score_list.append(valid_f1_score)\n",
    "            \n",
    "            current_valid_f1_loss = np.mean(valid_f1_loss_list)\n",
    "            \n",
    "            # compute valid_f1_loss end    \n",
    "            total_f1_loss = np.mean(self.generator_f1_losses) * 0.75 + current_valid_f1_loss * 0.25\n",
    "                \n",
    "            self.discriminator_acc_previous = np.mean(self.discriminator_acces)\n",
    "            self.discriminator_acces_previous = self.discriminator_acces.copy()\n",
    "            self.generator_losses_previous = self.generator_losses.copy()\n",
    "            # TBD: add epoch bigger than history length\n",
    "            self.history[\"generator_loss\"].append(\n",
    "                np.mean(self.generator_losses))\n",
    "            self.history[\"f1_loss_train\"].append(\n",
    "                np.mean(self.generator_f1_losses))\n",
    "            self.history[\"f1_loss_valid\"].append(\n",
    "                np.mean(valid_f1_loss_list))\n",
    "            \n",
    "\n",
    "            self.image_drawer.sample_images(\n",
    "                self.generator, epoch)\n",
    "\n",
    "            # previous generator_loss 갱신\n",
    "            self.generator_loss_previous = np.mean(self.generator_losses)\n",
    "            self.generator_loss_max_previous = np.max(self.generator_losses)\n",
    "            generator_loss_decrease_ratio = np.mean(self.generator_losses) / self.generator_loss_min\n",
    "            \n",
    "            #######################################\n",
    "            # 학습 상태 및 로그 출력\n",
    "            #######################################\n",
    "            self.train_logger.write_log(\n",
    "                f\"{epoch}/{epochs} ({epoch+self.patience_count})\",\n",
    "                np.mean(self.discriminator_acces),\n",
    "                np.mean(self.generator_losses),\n",
    "                np.max(self.generator_losses),\n",
    "                np.min(self.generator_losses),\n",
    "                f\"{self.generator_loss_min - np.mean(self.generator_losses)}({generator_loss_decrease_ratio})\",\n",
    "                self.generator_loss_min,\n",
    "                generator_current_learning_rate,\n",
    "                datetime.now() - start_time\n",
    "            )\n",
    "            print(f\"valid_loss : {self.generator_valid_loss_min} / {current_valid_f1_loss}\")\n",
    "            print(f\"discriminator_loss : {np.mean(self.discriminator_losses)}\")\n",
    "            print(f\"generator_discriminator_loss : {np.mean(generator_discriminator_losses)}\")\n",
    "            print(f\"train_f1_loss : {np.mean(self.generator_f1_losses)}\")\n",
    "            print(f\"valid_f1_score : {np.mean(valid_f1_score_list)}\")\n",
    "            print(f\"current/min total_f1_loss = {self.total_f1_loss_min} / {total_f1_loss}\")\n",
    "            #######################################\n",
    "            # 학습 상태 관찰 후 저장 여부 선택\n",
    "            #######################################\n",
    "            \n",
    "            if total_f1_loss / self.total_f1_loss_min < 1.1:\n",
    "                \n",
    "                if self.total_f1_loss_min > total_f1_loss:\n",
    "        \n",
    "                    self.generator_valid_loss_min = current_valid_f1_loss\n",
    "                    self.total_f1_loss_min = total_f1_loss\n",
    "                    if self.generator_loss_min > np.mean(self.generator_losses):\n",
    "                        self.generator_loss_min = np.mean(self.generator_losses)\n",
    "                        self.generator_loss_max_min = generator_loss_max_in_epoch\n",
    "                        self.generator_loss_min_min = generator_loss_min_in_epoch\n",
    "                    \n",
    "                    self.save_study_info()\n",
    "                    self.weight_save_stack = True\n",
    "                    print(\"save weights\")    \n",
    "                    if epoch < 20:\n",
    "                        if generator_loss_decrease_ratio < 0.8 and epoch > 0:\n",
    "                            self.patience_count += 0.25\n",
    "                    else:\n",
    "                        self.generator_learning_rate *= generator_loss_decrease_ratio\n",
    "                        self.discriminator_learning_rate  *= generator_loss_decrease_ratio\n",
    "                        \n",
    "                if self.generator_valid_loss_min > current_valid_f1_loss: \n",
    "                    self.generator_valid_loss_min = current_valid_f1_loss\n",
    "                    \n",
    "            else:\n",
    "                print(\"loss decrease.\")\n",
    "                if epoch+self.patience_count < 20:\n",
    "                    self.patience_count -= 1.5\n",
    "                else:\n",
    "                    self.patience_count += 1\n",
    "                self.load_best_weights()\n",
    "            \n",
    "            if epoch >= 10 and self.weight_save_stack:\n",
    "                copy(\n",
    "                    \"generator.h5\",\n",
    "                    \"./generator_weights/generator_\"\n",
    "                    + str(round(self.generator_loss_min, 5))\n",
    "                    + \"_\"\n",
    "                    + str(round(self.generator_loss_max_min, 5))\n",
    "                    + \".h5\",\n",
    "                )\n",
    "                self.weight_save_stack = False\n",
    "            \n",
    "            # 한 epoch의 끝\n",
    "        \n",
    "            \n",
    "    def get_info_folderPath(self):\n",
    "        return (\n",
    "            str(round(self.generator_loss_min, 5))\n",
    "            + \"_\"\n",
    "            + str(round(self.generator_loss_max_min, 5))\n",
    "        )\n",
    "\n",
    "    def save_study_info(self, path=None):\n",
    "\n",
    "        if path is None:\n",
    "            path = self.temp_weights_path\n",
    "\n",
    "        generator_weigth_path = os.path.join(path, \"generator.h5\")\n",
    "        discriminator_weigth_path = os.path.join(path, \"discriminator.h5\")\n",
    "        combined_weigth_path = os.path.join(path, \"combined.h5\")\n",
    "\n",
    "        self.generator.save_weights(generator_weigth_path)\n",
    "        self.discriminator.save_weights(discriminator_weigth_path)\n",
    "        self.combined.save_weights(combined_weigth_path)\n",
    "\n",
    "        study_info = {}\n",
    "        study_info[\"start_epoch\"] = self.start_epoch\n",
    "        study_info[\"train_loaded_data_index\"] = self.loaded_data_index[\"train\"]\n",
    "        study_info[\"generator_loss_min\"] = self.generator_loss_min\n",
    "        study_info[\"generator_loss_max_min\"] = self.generator_loss_max_min\n",
    "        study_info[\"generator_loss_min_min\"] = self.generator_loss_min_min\n",
    "        study_info[\"generator_losses_previous\"] = self.generator_losses_previous\n",
    "        study_info[\"discriminator_acces\"] = self.discriminator_acces\n",
    "        study_info[\"history\"] = self.history\n",
    "        file = open(path + \"/study_info.pkl\", \"wb\")\n",
    "        dump(study_info, file)\n",
    "        file.close()\n",
    "\n",
    "    def load_study_info(self):\n",
    "\n",
    "        self.generator.load_weights(\"generator.h5\")\n",
    "        self.discriminator.load_weights(\"discriminator.h5\")\n",
    "#         self.combined.load_weights(\"combined.h5\")\n",
    "\n",
    "        if os.path.isfile(\"study_info.pkl\"):\n",
    "            file = open(\"study_info.pkl\", \"rb\")\n",
    "            study_info = load(file)\n",
    "            file.close()\n",
    "            self.start_epoch = study_info[\"start_epoch\"]\n",
    "            self.loaded_data_index[\"train\"] = study_info[\"train_loaded_data_index\"]\n",
    "            self.generator_loss_min = study_info[\"generator_loss_min\"]\n",
    "            self.generator_loss_max_min = study_info[\"generator_loss_max_min\"]\n",
    "            self.generator_loss_min_min = study_info[\"generator_loss_min_min\"]\n",
    "            self.generator_losses_previous = study_info[\"generator_losses_previous\"]\n",
    "            self.discriminator_acces = study_info[\"discriminator_acces\"]\n",
    "            self.history = study_info[\"history\"]\n",
    "        else:\n",
    "            print(\"No info pkl file!\")\n",
    "\n",
    "    def load_best_weights(self):\n",
    "        self.generator.load_weights(self.temp_weights_path + \"/generator.h5\")\n",
    "        self.discriminator.load_weights(\n",
    "            self.temp_weights_path + \"/discriminator.h5\")\n",
    "        self.combined.load_weights(self.temp_weights_path + \"/combined.h5\")\n",
    "\n",
    "    def run_pretraining(self, epochs):\n",
    "        if self.on_memory:\n",
    "            self.generator.fit(\n",
    "                x=self.data_loader.loaded_data_object[\"train\"][\"input\"],\n",
    "                y=self.data_loader.loaded_data_object[\"train\"][\"output\"],\n",
    "                validation_data=list(self.data_loader.loaded_data_object[\"valid\"].values()),\n",
    "                batch_size=self.batch_size, epochs=epochs\n",
    "            )\n",
    "        else:\n",
    "            self.generator.fit_generator(\n",
    "                x=self.data_loader.loaded_data_object[\"train\"][\"input\"],\n",
    "                y=self.data_loader.loaded_data_object[\"train\"][\"output\"],\n",
    "                validation_data=list(self.data_loader.loaded_data_object[\"valid\"].values()),\n",
    "                batch_size=self.batch_size, epochs=epochs\n",
    "            )\n",
    "        self.generator.save_weights(\"pretrained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator_lr = 1e-4\n",
    "discriminator_lr = 1e-4\n",
    "batch_size = 4\n",
    "\n",
    "g_lr = generator_lr * batch_size\n",
    "d_lr = discriminator_lr * batch_size\n",
    "gan = Pix2PixSegmentation(generator_power=8, discriminator_power=8, \n",
    "                          generator_depth = 3, discriminator_depth = 3,\n",
    "                          generator_learning_rate=g_lr, discriminator_learning_rate=d_lr,\n",
    "                          on_memory=False, code_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:19:52,778 - train - INFO - \n",
      "Epoch : 0/100 (0)\n",
      "Discriminator_acces : 0.47843017578125\n",
      "Mean generator loss : 415.86602783203125\n",
      "Max generator loss : 457.4815368652344\n",
      "Min generator loss : 311.8016357421875\n",
      "Generator loss decrease : 9584.133972167969(0.04158660278320313)\n",
      "Current lowest generator loss : 10000\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:24.896064\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 10000 / 3.821990489959717\n",
      "discriminator_loss : 3.422738552093506\n",
      "generator_discriminator_loss : 0.009808719158172607\n",
      "train_f1_loss : 4.0028791427612305\n",
      "valid_f1_score : 0.05905028432607651\n",
      "current/min total_f1_loss = 10000 / 3.957656979560852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:19:56,884 - train - INFO - \n",
      "Epoch : 1/100 (1)\n",
      "Discriminator_acces : 0.5326904296875\n",
      "Mean generator loss : 412.44085693359375\n",
      "Max generator loss : 454.4933166503906\n",
      "Min generator loss : 307.62664794921875\n",
      "Generator loss decrease : 3.4251708984375(0.9917637705802917)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 4e-05\n",
      "Elapsed_time : 0:00:29.002296\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : 3.415907621383667\n",
      "generator_discriminator_loss : 0.00899621844291687\n",
      "train_f1_loss : 3.969578504562378\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:00,383 - train - INFO - \n",
      "Epoch : 2/100 (0.5)\n",
      "Discriminator_acces : 0.156494140625\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 3e-05\n",
      "Elapsed_time : 0:00:32.501070\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:04,469 - train - INFO - \n",
      "Epoch : 3/100 (0.0)\n",
      "Discriminator_acces : 0.25135498046875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:36.586754\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:07,838 - train - INFO - \n",
      "Epoch : 4/100 (-0.5)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:39.955633\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:11,438 - train - INFO - \n",
      "Epoch : 5/100 (-1.0)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:43.555843\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:14,982 - train - INFO - \n",
      "Epoch : 6/100 (-1.5)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:47.100081\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:18,525 - train - INFO - \n",
      "Epoch : 7/100 (-2.0)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:50.643325\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:22,058 - train - INFO - \n",
      "Epoch : 8/100 (-2.5)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:54.175332\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:25,593 - train - INFO - \n",
      "Epoch : 9/100 (-3.0)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:00:57.710099\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{80% |#########################################################               |\n",
      "2021-06-02 16:20:29,139 - train - INFO - \n",
      "Epoch : 10/100 (-3.5)\n",
      "Discriminator_acces : 0.09715576171875\n",
      "Mean generator loss : nan\n",
      "Max generator loss : nan\n",
      "Min generator loss : nan\n",
      "Generator loss decrease : nan(nan)\n",
      "Current lowest generator loss : 415.86602783203125\n",
      "Current Learning_rate : 2e-05\n",
      "Elapsed_time : 0:01:01.257100\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss : 3.821990489959717 / nan\n",
      "discriminator_loss : nan\n",
      "generator_discriminator_loss : nan\n",
      "train_f1_loss : nan\n",
      "valid_f1_score : nan\n",
      "current/min total_f1_loss = 3.957656979560852 / nan\n",
      "loss decrease.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './generator_weights/generator_415.86603_0.h5'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-96be58a6b72f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# gan.load_study_info()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# gan.start_epoch = 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_shuffle_term\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-2ad748bb9f2e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, batch_size, epoch_shuffle_term)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_save_stack\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m                 copy(\n\u001b[0m\u001b[0;32m    456\u001b[0m                     \u001b[1;34m\"generator.h5\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                     \u001b[1;34m\"./generator_weights/generator_\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m             \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './generator_weights/generator_415.86603_0.h5'"
     ]
    }
   ],
   "source": [
    "# gan.load_study_info()\n",
    "# gan.start_epoch = 0\n",
    "gan.train(epochs=100, batch_size=batch_size, epoch_shuffle_term=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_masked_img = gan.generator.predict_on_batch(gan.original_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=nan>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_region_loss(gan.masked_img, model_masked_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x207010a6df0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(gan.masked_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20701116b50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MI2RL\\anaconda3\\lib\\site-packages\\matplotlib\\image.py:446: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)\n",
      "C:\\Users\\MI2RL\\anaconda3\\lib\\site-packages\\matplotlib\\image.py:453: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "C:\\Users\\MI2RL\\anaconda3\\lib\\site-packages\\matplotlib\\image.py:458: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(model_masked_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_patch = np.ones(\n",
    "    (gan.batch_size, *gan.disc_patch), dtype=np.float32)\n",
    "\n",
    "generator_loss = gan.combined.train_on_batch(\n",
    "    gan.original_img,\n",
    "    [valid_patch, gan.masked_img],\n",
    "    class_weight={0: 0.1, 1: 0.9}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_i=0\n",
    "batch_index = gan.loaded_data_index[\"train\"][batch_i: batch_i +\n",
    "                                              gan.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean(gan.generator_losses[batch_index]) > np.quantile(gan.generator_losses, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.load_study_info()\n",
    "#gan.start_epoch = 30\n",
    "# gan.start_epoch = 2 \n",
    "gan.train(epochs=325, batch_size=batch_size, epoch_shuffle_term=100)\n",
    "# gan.train(epochs=20, batch_size=batch_size, epoch_shuffle_term=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weight = gan.generator.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in temp_weight:\n",
    "    if \"dense\" in weight.name:\n",
    "        if \"bias\" in weight.name:\n",
    "            print(weight.name)\n",
    "            print(weight.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_weight = gan.discriminator.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for weight in temp_weight:\n",
    "    if \"dense\" in weight.name:\n",
    "        if \"bias\" in weight.name:\n",
    "            print(weight.name)\n",
    "            print(weight.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.original_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(gan.original_img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(gan.original_img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(gan.original_img.numpy() + 1) * 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = gan.original_img.numpy()\n",
    "predicted = gan.generator.predict_on_batch(image)\n",
    "mask = gan.masked_img.numpy()\n",
    "\n",
    "image = ((image + 1) * 127.5).astype('uint8')\n",
    "predicted = ((predicted + 1) * 127.5).astype('uint8')\n",
    "mask = ((mask + 1) * 127.5).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(image[index])\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(predicted[index])\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(mask[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(gan.original_img))\n",
    "print(np.min(gan.original_img))\n",
    "print(np.max(temp))\n",
    "print(np.min(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = gan.data_loader.loaded_data_object[\"train\"].values()\n",
    "\n",
    "for index, (input_img, output_img) in enumerate(zip(*temp)):\n",
    "    print(index)\n",
    "    if index > 40:\n",
    "        break\n",
    "    print(index)\n",
    "    print(input_img.shape)\n",
    "    print(output_img.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "temp_source = gan.original_img\n",
    "temp_mask = gan.masked_img\n",
    "\n",
    "start_time = time.time()\n",
    "gan.generator.train_on_batch(temp_source, temp_mask)\n",
    "print(f\"elapsed time : {time.time() - start_time}\")\n",
    "\n",
    "temp_source = tf.convert_to_tensor(temp_source)\n",
    "temp_mask = tf.convert_to_tensor(temp_mask)\n",
    "\n",
    "start_time = time.time()\n",
    "gan.generator.train_on_batch(temp_source, temp_mask)\n",
    "print(f\"elapsed time : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterator : 260초\n",
    "# Queue Iterator : 200초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "from queue import Queue\n",
    "\n",
    "ITER_NUM = 620\n",
    "batch_size = 10\n",
    "\n",
    "gan.generator.compile(\n",
    "    loss=sm.losses.BinaryFocalLoss(),\n",
    "    optimizer=Nadam(gan.generator_learning_rate),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "def batch_setter(queue):\n",
    "    batch_i = 0\n",
    "    count = 0\n",
    "    while batch_i + gan.batch_size <= gan.data_loader.train_data_length and count < ITER_NUM:\n",
    "        \n",
    "        batch_index = gan.train_loaded_data_index[batch_i: batch_i +\n",
    "                                                   gan.batch_size]        \n",
    "        \n",
    "        batch_tuple = gan.data_loader.get_data(\n",
    "        data_mode=\"train\", index=batch_index)\n",
    "\n",
    "        queue.put(batch_tuple)\n",
    "        queue.join()\n",
    "        count += 1\n",
    "    \n",
    "def batch_getter(queue):\n",
    "    \n",
    "    original_img, masked_img = queue.get()\n",
    "    tensor_original_img = tf.convert_to_tensor(original_img)\n",
    "    tensor_masked_img = tf.convert_to_tensor(masked_img)\n",
    "    queue.task_done()\n",
    "    \n",
    "    return tensor_original_img, tensor_masked_img\n",
    "    \n",
    "def batch_trainer(original_img, masked_img):\n",
    "    \n",
    "    gan.generator.train_on_batch(temp_source, temp_mask)\n",
    "\n",
    "q = Queue()\n",
    "\n",
    "setter = threading.Thread(target=batch_setter, args=(q,),daemon=True)\n",
    "setter.start()\n",
    "start_time = time.time()\n",
    "for i in range(ITER_NUM):\n",
    "    tensor_original_img, tensor_masked_img = batch_getter(q)\n",
    "    \n",
    "    gan.generator.train_on_batch(tensor_original_img, tensor_masked_img)\n",
    "print(f\"elapsed time : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "batch_i = 0\n",
    "count = 0\n",
    "while batch_i + gan.batch_size <= gan.data_loader.train_data_length and count < ITER_NUM:\n",
    "\n",
    "    batch_index = gan.train_loaded_data_index[batch_i: batch_i +\n",
    "                                               gan.batch_size]        \n",
    "    batch_tuple = gan.data_loader.get_data(\n",
    "    data_mode=\"train\", index=batch_index)\n",
    "    \n",
    "    gan.generator.train_on_batch(*batch_tuple)\n",
    "    \n",
    "    count += 1\n",
    "print(f\"elapsed time : {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "temp = tensor_masked_img\n",
    "print(type(temp))\n",
    "print(type(temp.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(temp.numpy(), tf.Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan_module.model.build_model import build_dual_discriminator\n",
    "\n",
    "temp = build_dual_discriminator(\n",
    "            input_img_shape=(512,512,3),\n",
    "            output_img_shape=(512,512,1),\n",
    "            discriminator_power=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "temp.compile(\n",
    "    loss=[\n",
    "        tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1),\n",
    "        tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n",
    "    ],\n",
    "    optimizer=Nadam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "image_mockup = np.ones((1,512,512,3))\n",
    "mask_mockup = np.ones((1,512,512,1))\n",
    "patch_mockup = np.ones((1,8,8,1))\n",
    "\n",
    "temp.test_on_batch([image_mockup, mask_mockup], [patch_mockup, patch_mockup])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
